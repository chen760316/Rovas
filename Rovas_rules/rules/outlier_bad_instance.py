"""
 ğ‘…(ğ‘¡) âˆ§ outlier(ğ·, ğ‘…, ğ‘¡ .ğ´, ğœƒ ) âˆ§ loss(M, D, ğ‘¡) > ğœ† â†’ bad(ğ‘¡)çš„å…·ä½“å®ç°
"""
# unsupervised methods
from deepod.models import REPEN, SLAD, ICL, NeuTraL, DeepSAD
from deepod.models.tabular import GOAD
from deepod.models.tabular import RCA
from deepod.models.tabular import DeepSVDD
import torch
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import matplotlib
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
import numpy as np
from sklearn.metrics import hinge_loss
from sklearn.feature_selection import mutual_info_regression
from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import RFE
from xgboost import XGBClassifier, plot_importance
from sklearn.inspection import permutation_importance
from lime.lime_tabular import LimeTabularExplainer
import shap
from distfit import distfit
from fitter import Fitter
import scipy.stats as stats
import re

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.width', None)
np.set_printoptions(threshold=np.inf)

# section é¢„å¤„ç†æ•°æ®é›†
file_path = "../../UCI_datasets/dry+bean+dataset/DryBeanDataset/Dry_Bean_Dataset.xlsx"
data = pd.read_excel(file_path)
enc = LabelEncoder()
data['Class'] = enc.fit_transform(data['Class'])
X = data.values[:, :-1]
y = data.values[:, -1]
# å¯¹ä¸åŒç»´åº¦è¿›è¡Œæ ‡å‡†åŒ–
X = StandardScaler().fit_transform(X)
# è®°å½•åŸå§‹ç´¢å¼•
original_indices = np.arange(len(X))
X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(X, y, original_indices, test_size=0.5, random_state=1)
class_names = enc.classes_
feature_names = data.columns.values.tolist()
# ä½¿ç”¨å¤„ç†åçš„Xå’Œyç»„åˆæˆæ–°çš„data_copy
column_names = data.columns.tolist()
# å°† X å’Œ y ç»„åˆä¸ºä¸€ä¸ª numpy æ•°ç»„
combined_array = np.hstack((X, y.reshape(-1, 1)))  # å°† y é‡æ–°è°ƒæ•´ä¸ºåˆ—å‘é‡å¹¶åˆå¹¶
# åˆ›å»ºæ–°çš„ DataFrame
data_copy = pd.DataFrame(combined_array, columns=column_names)
# å¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œæ•´æ•°ç¼–ç 
categorical_features = [0, 6]
categorical_names = {}
for feature in categorical_features:
    le = LabelEncoder()
    le.fit(data.iloc[:, feature])
    data.iloc[:, feature] = le.transform(data.iloc[:, feature])
    categorical_names[feature] = le.classes_

# section è°“è¯outlier(ğ·, ğ‘…, ğ‘¡ .ğ´, ğœƒ )çš„å®ç°
threshold = 0.01
col_indices = 3
row_indices = 10
select_feature = feature_names[col_indices]
# è·å¾—æ‰€é€‰åˆ—çš„æ•°æ®
select_column_data = data_copy[select_feature].values
# æ‰¾åˆ°æ‰€é€‰åˆ—çš„æœ€å¤§å€¼å’Œæœ€å°å€¼
max_value = np.max(select_column_data)
min_value = np.min(select_column_data)
# æ‰¾åˆ°t.Aå¯¹åº”çš„å€¼
t_value = data_copy.iloc[row_indices, col_indices]
# å¯¹æ•°æ®è¿›è¡Œæ’åº
# sorted_data = np.sort(select_column_data)
sorted_indices = np.argsort(select_column_data)
sorted_data = select_column_data[sorted_indices]
# æ‰¾åˆ°æœ€æ¥è¿‘çš„æ¯” t_value å¤§çš„å€¼å’Œæ¯” t_value å°çš„å€¼
greater_than_t_value = sorted_data[sorted_data > t_value]
less_than_t_value = sorted_data[sorted_data < t_value]
# æ‰¾åˆ°ä¸t_valueæœ€æ¥è¿‘çš„æ›´å¤§çš„å€¼å’Œæ›´å°çš„å€¼
if greater_than_t_value.size > 0:
    closest_greater = greater_than_t_value[0]  # æœ€è¿‘çš„å¤§äº t_value çš„å€¼
else:
    closest_greater = t_value
if less_than_t_value.size > 0:
    closest_less = less_than_t_value[-1]  # æœ€è¿‘çš„å°äº t_value çš„å€¼
else:
    closest_less = t_value
# åˆ¤æ–­t.Aæ˜¯å¦æ˜¯å¼‚å¸¸å€¼
if max_value == t_value:
    print("å…ƒç»„tåœ¨å±æ€§Aä¸Šçš„æŠ•å½±æ˜¯å¼‚å¸¸å€¼å—:", t_value - closest_less > threshold)
elif min_value == t_value:
    print("å…ƒç»„tåœ¨å±æ€§Aä¸Šçš„æŠ•å½±æ˜¯å¼‚å¸¸å€¼å—:", closest_greater - t_value > threshold)
else:
    print("å…ƒç»„tåœ¨å±æ€§Aä¸Šçš„æŠ•å½±æ˜¯å¼‚å¸¸å€¼å—:", t_value - closest_less > threshold and t_value - closest_less > threshold)
# æ‰¾åˆ°Aå±æ€§ä¸‹çš„æ‰€æœ‰å¼‚å¸¸å€¼
outliers = []
outliers_index = []
# æ£€æŸ¥åˆ—è¡¨é¦–å°¾å…ƒç´ 
if len(sorted_data) > 1:
    if (sorted_data[1] - sorted_data[0] >= threshold):
        outliers.append(sorted_data[0])
        outliers_index.append(sorted_indices[0])
    if (sorted_data[-1] - sorted_data[-2] >= threshold):
        outliers.append(sorted_data[-1])
        outliers_index.append(sorted_indices[-1])
# æ£€æŸ¥ä¸­é—´å…ƒç´ 
for i in range(1, len(sorted_data) - 1):
    current_value = sorted_data[i]
    left_value = sorted_data[i - 1]
    right_value = sorted_data[i + 1]
    if (current_value - left_value >= threshold) and (right_value - current_value >= threshold):
        outliers.append(current_value)
        outliers_index.append(sorted_indices[i])
# åœ¨æ‰€æœ‰æ•°æ®Dä¸Šçš„å¼‚å¸¸å€¼ç´¢å¼•
outliers_index_numpy = np.array(outliers_index)
print("Aå±æ€§ä¸‹æ‰€æœ‰å¼‚å¸¸å€¼çš„ç´¢å¼•ä¸ºï¼š", outliers_index)
print("Aå±æ€§ä¸‹æ‰€æœ‰å¼‚å¸¸å€¼ä¸ºï¼š", outliers)

# SECTION è°“è¯loss(M, D, ğ‘¡)çš„å®ç°

#  SVMæ¨¡å‹è®­ç»ƒå’Œåˆ†ç±»å‡†ç¡®åº¦
svm_model = svm.SVC()
svm_model.fit(X_train, y_train)
train_label_pred = svm_model.predict(X_train)
# è¢«SVMæ¨¡å‹é”™è¯¯åˆ†ç±»çš„æ ·æœ¬
# åœ¨è®­ç»ƒæ•°æ®ä¸Šé”™è¯¯åˆ†ç±»çš„æ ·æœ¬ä¸‹æ ‡
wrong_classified_indices = np.where(y_train != svm_model.predict(X_train))[0]
# SUBSECTION ä½¿ç”¨sklearnåº“ä¸­çš„hingeæŸå¤±å‡½æ•°
decision_values = svm_model.decision_function(X_train)
predicted_labels = np.argmax(decision_values, axis=1)
# è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„hingeæŸå¤±
num_samples = X_train.shape[0]
num_classes = svm_model.classes_.shape[0]
hinge_losses = np.zeros((num_samples, num_classes))
hinge_loss = np.zeros(num_samples)
for i in range(num_samples):
    correct_class = int(y_train[i])
    for j in range(num_classes):
        if j != correct_class:
            loss_j = max(0, 1 - decision_values[i, correct_class] + decision_values[i, j])
            hinge_losses[i, j] = loss_j
    hinge_loss[i] = np.max(hinge_losses[i])
# åˆ¤å®šå¼‚å¸¸ï¼šè®¾ç½®é˜ˆå€¼ä¸º 1ï¼Œè¶…è¿‡æ­¤å€¼å³è®¤ä¸ºæ˜¯å¼‚å¸¸
# è®­ç»ƒæ•°æ®ä¸Šçš„bad outliersçš„ç´¢å¼•ä¸‹æ ‡
bad_samples = np.where(hinge_loss > 1)[0]
print("æŸå¤±å‡½æ•°é«˜äºæŸå¤±é˜ˆå€¼çš„æ ·æœ¬ç´¢å¼•ä¸ºï¼š", bad_samples)

# section ç¡®å®šæ‰€é€‰å±æ€§Aä¸‹å…ƒç»„tæ˜¯å¦ä¸ºbad outliersï¼Œç¡®å®šå±æ€§Aä¸‹çš„æ‰€æœ‰bad outliers
# è®¡ç®—è°“è¯outlier(ğ·, ğ‘…, ğ‘¡ .ğ´, ğœƒ )ä¸ºtrueå’Œloss(M, D, ğ‘¡) â‰¤ ğœ†çš„å…ƒç»„çš„äº¤é›†
intersection = np.intersect1d(outliers_index_numpy, train_indices[bad_samples])

if np.isin(row_indices, intersection):
    print("æ‰€é€‰å…ƒç»„tåœ¨å±æ€§Aä¸‹æ˜¯bad outliers")
else:
    print("æ‰€é€‰å…ƒç»„tåœ¨å±æ€§Aä¸‹ä¸æ˜¯bad outliers")

print("Aå±æ€§ä¸‹æ‰€æœ‰çš„bad outliersçš„è¡Œç´¢å¼•ä¸ºï¼š", intersection)

# section ç¡®å®šæ‰€æœ‰å±æ€§ä¸‹çš„æ‰€æœ‰bad outliers
column_num = len(feature_names) - 1
bad_outlier_list = {}
for column in range(column_num):
    select_feature = feature_names[column]
    # è·å¾—æ‰€é€‰åˆ—çš„æ•°æ®
    select_column_data = data_copy[select_feature].values
    sorted_indices = np.argsort(select_column_data)
    sorted_data = select_column_data[sorted_indices]
    # æ‰¾åˆ°æ‰€é€‰å±æ€§ä¸‹çš„æ‰€æœ‰å¼‚å¸¸å€¼
    outliers = []
    outliers_index = []
    # æ£€æŸ¥åˆ—è¡¨é¦–å°¾å…ƒç´ 
    if len(sorted_data) > 1:
        if (sorted_data[1] - sorted_data[0] >= threshold):
            outliers.append(sorted_data[0])
            outliers_index.append(sorted_indices[0])
        if (sorted_data[-1] - sorted_data[-2] >= threshold):
            outliers.append(sorted_data[-1])
            outliers_index.append(sorted_indices[-1])
    # æ£€æŸ¥ä¸­é—´å…ƒç´ 
    for i in range(1, len(sorted_data) - 1):
        current_value = sorted_data[i]
        left_value = sorted_data[i - 1]
        right_value = sorted_data[i + 1]
        if (current_value - left_value >= threshold) and (right_value - current_value >= threshold):
            outliers.append(current_value)
            outliers_index.append(sorted_indices[i])
    outliers_index_numpy = np.array(outliers_index)
    intersection = np.intersect1d(outliers_index_numpy, bad_samples)
    bad_outlier_list[column] = intersection
# print("æ‰€æœ‰ç‰¹å¾åˆ—çš„bad outliersåˆ—è¡¨ä¸ºï¼š", bad_outlier_list)
# æ‰“å°æ‰€æœ‰ç‰¹å¾åˆ—çš„bad outliersçš„å€¼
for idx, key in enumerate(bad_outlier_list):
    value = bad_outlier_list[key]
    print(f"ç¬¬ {key} åˆ—çš„bad outliersä¸º: {value}")