"""
ugly outliersçš„ä¿®å¤ï¼Œåˆ†ç±»å™¨ä¸ºlinearæ ¸çš„svmåˆ†ç±»å™¨
è¾“å…¥æ•°æ®é›†ä¸ºdeepod.utils.dataä¸­generate_dataæ–¹æ³•ä¸‹çš„åˆæˆæ•°æ®é›†
é€‚ç”¨äºŽäºŒåˆ†ç±»çš„æƒ…å†µ
æ•°æ®é›†è¿‡äºŽç®€å•ï¼ŒSVMæ¨¡åž‹èƒ½æ— é”™è¯¯åœ°è¿›è¡Œåˆ†ç±»
"""
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from deepod.models import REPEN, SLAD, ICL, NeuTraL, DeepSAD
from deepod.models.tabular import GOAD
from deepod.models.tabular import RCA
from deepod.models.tabular import DeepSVDD
import torch
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import matplotlib
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
import numpy as np
from sklearn.metrics import hinge_loss
from sklearn.feature_selection import mutual_info_regression
from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import RFE
from xgboost import XGBClassifier, plot_importance
from sklearn.inspection import permutation_importance
from lime.lime_tabular import LimeTabularExplainer
import shap
from distfit import distfit
from fitter import Fitter
import scipy.stats as stats
import re

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.width', None)
np.set_printoptions(threshold=np.inf)

def one_hot_encode(y, num_classes):
    y = y.astype(int)
    return np.eye(num_classes)[y]

def calculate_made(data):
    median = np.median(data)  # è®¡ç®—ä¸­ä½æ•°
    abs_deviation = np.abs(data - median)  # è®¡ç®—æ¯ä¸ªæ•°æ®ç‚¹ä¸Žä¸­ä½æ•°çš„ç»å¯¹è¯¯å·®
    mad = np.median(abs_deviation)  # è®¡ç®—ç»å¯¹è¯¯å·®å‡å€¼
    made = 1.843 * mad
    return median, made

epochs = 1
device = 'cuda' if torch.cuda.is_available() else 'cpu'
n_trans = 64
random_state = 42

# section æ•°æ®é¢„å¤„ç†

# subsection åˆæˆæ•°æ®é›†
from deepod.utils.data import generate_data
n_train = 500
n_test = 100
n_features = 10
contamination = 0.1
epochs = 1
#      æ­£å¸¸å€¼ç”±å¤šå…ƒé«˜æ–¯åˆ†å¸ƒç”Ÿæˆï¼Œ
#      å¼‚å¸¸å€¼æ˜¯ç”±å‡åŒ€åˆ†å¸ƒç”Ÿæˆçš„ã€‚
X_train, X_test, y_train, y_test = generate_data(
    n_train=n_train, n_test=n_test, n_features=n_features,
    contamination=contamination, random_state=random_state)

# SECTION Mð‘œ (ð‘¡, D)
# subsection é’ˆå¯¹å…ƒç»„å¼‚å¸¸çš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹å™¨GOAD
clf_gold = GOAD(epochs=epochs, device=device, n_trans=n_trans)
clf_gold.fit(X_train, y=None)

# SECTION å€ŸåŠ©å¼‚å¸¸æ£€æµ‹å™¨ï¼Œåœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œå¼‚å¸¸å€¼æ£€æµ‹
clf = clf_gold
train_scores = clf.decision_function(X_train)
train_pred_labels, train_confidence = clf.predict(X_train, return_confidence=True)
print("è®­ç»ƒé›†ä¸­å¼‚å¸¸å€¼åˆ¤å®šé˜ˆå€¼ä¸ºï¼š", clf.threshold_)
train_outliers_index = []
train_outliers_confidence = []
print("è®­ç»ƒé›†æ ·æœ¬æ•°ï¼š", len(X_train))
for i in range(len(X_train)):
    if train_pred_labels[i] == 1:
        train_outliers_index.append(i)
        train_outliers_confidence.append(train_confidence[i])
# è®­ç»ƒæ ·æœ¬ä¸­çš„å¼‚å¸¸å€¼ç´¢å¼•
print("è®­ç»ƒé›†ä¸­å¼‚å¸¸å€¼ç´¢å¼•ï¼š", train_outliers_index)
print("è®­ç»ƒé›†ä¸­çš„å¼‚å¸¸å€¼æ•°é‡ï¼š", len(train_outliers_index))
print("è®­ç»ƒé›†ä¸­çš„å¼‚å¸¸å€¼çš„ç½®ä¿¡åº¦ï¼š", train_outliers_confidence)

# SECTION SVMæ¨¡åž‹çš„å®žçŽ°
svm_model = svm.SVC(kernel='linear', C=1.0, probability=True)
svm_model.fit(X_train, y_train)
train_label_pred = svm_model.predict(X_train)
# è¢«SVMæ¨¡åž‹é”™è¯¯åˆ†ç±»çš„æ ·æœ¬
# è®­ç»ƒæ ·æœ¬ä¸­çš„å¼‚å¸¸å€¼ç´¢å¼•
wrong_classified_indices = np.where(y_train != svm_model.predict(X_train))[0]

# SUBSECTION ä½¿ç”¨sklearnåº“ä¸­çš„hingeæŸå¤±å‡½æ•°
decision_values = svm_model.decision_function(X_train)
# è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„hingeæŸå¤±
num_samples = X_train.shape[0]
num_classes = svm_model.classes_.shape[0]
hinge_loss = np.zeros(num_samples)
for i in range(num_samples):
    hinge_loss[i] = np.maximum(0, 1 - (2 * y_train[i] - 1) * decision_values[i])
# åˆ¤å®šå¼‚å¸¸ï¼šè®¾ç½®é˜ˆå€¼ä¸º 1ï¼Œè¶…è¿‡æ­¤å€¼å³è®¤ä¸ºæ˜¯å¼‚å¸¸
# è®­ç»ƒæ ·æœ¬ä¸­çš„å¼‚å¸¸å€¼ç´¢å¼•
bad_samples = np.where(hinge_loss > 1)[0]
correct_samples = np.where(hinge_loss <= 1)[0]
# print("æŸå¤±å‡½æ•°é«˜äºŽæŸå¤±é˜ˆå€¼çš„æ ·æœ¬ç´¢å¼•ä¸ºï¼š", bad_samples)

# subsection åˆ¤å®šè®­ç»ƒæ•°æ®ä¸­å¼‚å¸¸å€¼å¯èƒ½å¯¼è‡´åˆ†ç±»é”™è¯¯çš„æ ·æœ¬
# è®­ç»ƒæ•°æ®ä¸­çš„å¼‚å¸¸å€¼ï¼Œå¯¼è‡´hingeæŸå¤±å¤§äºŽ1çš„æ ·æœ¬
inter_outliers = list(set(train_outliers_index) & set(bad_samples))
# è®­ç»ƒæ•°æ®ä¸­çš„å¼‚å¸¸å€¼ï¼Œå¯¼è‡´hingeæŸå¤±å°äºŽç­‰äºŽ1çš„æ ·æœ¬
inter_correct_class = list(set(train_outliers_index) & set(correct_samples))
# è®­ç»ƒæ•°æ®ä¸­çš„hingeæŸå¤±å¤§äºŽ1ä¸”è¢«SVMè¯¯åˆ†ç±»çš„æ ·æœ¬
intersection = np.intersect1d(bad_samples, wrong_classified_indices)
# è®­ç»ƒæ•°æ®ä¸­è¢«SVMè¯¯åˆ†ç±»ä¸”hingeæŸå¤±å°äºŽç­‰äºŽ1çš„æ ·æœ¬
diff_elements = np.setdiff1d(wrong_classified_indices, intersection)
print("è®­ç»ƒæ•°æ®ä¸­è¢«SVMè¯¯åˆ†ç±»ä¸”hingeæŸå¤±å°äºŽç­‰äºŽ1çš„æ ·æœ¬ï¼š", diff_elements)
print("è®­ç»ƒé›†ä¸­æ˜¯å¼‚å¸¸å€¼ä¸”hingeæŸå¤±é«˜äºŽé˜ˆå€¼1çš„æ ·æœ¬ç´¢å¼•ï¼š", inter_outliers)
print("è®­ç»ƒé›†ä¸­æ˜¯å¼‚å¸¸å€¼ä¸”hingeæŸå¤±å°äºŽç­‰äºŽ1çš„æ ·æœ¬ç´¢å¼•ï¼š", inter_correct_class)

# SECTION åŽŸå§‹æ•°æ®ä¸­çš„svmåœ¨å„ç±»è¯„ä»·æŒ‡æ ‡ä¸‹çš„è¡¨çŽ°
print("*" * 100)

# subsection è®¡ç®—SVMçš„åˆ†ç±»å‡†ç¡®åº¦
# å‡†ç¡®åº¦æ˜¯æŒ‡æ¨¡åž‹æ­£ç¡®åˆ†ç±»çš„æ ·æœ¬æ•°å æ€»æ ·æœ¬æ•°çš„æ¯”ä¾‹
print("åŽŸå§‹è®­ç»ƒé›†ä¸­SVMåˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train, svm_model.predict(X_train))))
print("åŽŸå§‹æµ‹è¯•é›†ä¸­SVMåˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, svm_model.predict(X_test))))

# subsection è®¡ç®— F1 åˆ†æ•°
f1_train = f1_score(y_train, svm_model.predict(X_train), average='weighted')
f1_test = f1_score(y_test, svm_model.predict(X_test), average='weighted')
print("åŽŸå§‹è®­ç»ƒé›†SVMåˆ†ç±»F1åˆ†æ•°ï¼š" + str(f1_train))
print("åŽŸå§‹æµ‹è¯•é›†SVMåˆ†ç±»F1åˆ†æ•°ï¼š" + str(f1_test))

# SECTION èˆå¼ƒæŽ‰è®­ç»ƒæ•°æ®ä¸­hingeæŸå¤±å‡½æ•°é«˜äºŽ1ä¸”è¢«åˆ¤å®šä¸ºå¼‚å¸¸å€¼çš„æ ·æœ¬ï¼Œé‡æ–°åœ¨å¤„ç†åŽçš„è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒSVM
print("*" * 100)
# subsection è®¡ç®— accuracyåˆ†æ•°
# ç”Ÿæˆå¸ƒå°”ç´¢å¼•ï¼Œä¸ºè¦åˆ é™¤çš„è¡Œåˆ›å»ºå¸ƒå°”å€¼æ•°ç»„
mask = np.ones(len(X_train), dtype=bool)
mask[inter_outliers] = False
# ä½¿ç”¨å¸ƒå°”ç´¢å¼•åˆ é™¤é‚£äº›æ—¢è¢«åˆ¤å®šä¸ºå¼‚å¸¸å€¼ï¼Œåˆä½¿å¾—hingeæŸå¤±é«˜äºŽ1çš„æ ·æœ¬
X_train_split = X_train[mask]
y_train_split = y_train[mask]
# é‡æ–°è®­ç»ƒSVMæ¨¡åž‹
svm_model_split = svm.SVC(kernel='linear', C=1.0, probability=True)
svm_model_split.fit(X_train_split, y_train_split)
print("åŽ»é™¤å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬åŽçš„è®­ç»ƒé›†SVMåˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train_split, svm_model_split.predict(X_train_split))))
print("åŽ»é™¤å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬åŽçš„æµ‹è¯•é›†SVMåˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, svm_model_split.predict(X_test))))

# subsection è®¡ç®— F1 åˆ†æ•°
f1_train_split = f1_score(y_train_split, svm_model_split.predict(X_train_split), average='weighted')
f1_test_split = f1_score(y_test, svm_model_split.predict(X_test), average='weighted')
print("åŽ»é™¤å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬åŽçš„è®­ç»ƒé›†SVMåˆ†ç±»F1åˆ†æ•°ï¼š" + str(f1_train_split))
print("åŽ»é™¤å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬åŽçš„æµ‹è¯•é›†SVMåˆ†ç±»F1åˆ†æ•°ï¼š" + str(f1_test_split))

# SECTION èˆå¼ƒæŽ‰SVMè®­ç»ƒæ•°æ®ä¸­hingeæŸå¤±å‡½æ•°é«˜äºŽ1çš„æ ·æœ¬ï¼Œé‡æ–°åœ¨å¤„ç†åŽçš„è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒSVM
print("*" * 100)

# subsection è®¡ç®— accuracyåˆ†æ•°
mask_h = np.ones(len(X_train), dtype=bool)
mask_h[bad_samples] = False
X_train_h = X_train[mask_h]
y_train_h = y_train[mask_h]
svm_model_h = svm.SVC(kernel='linear', C=1.0, probability=True)
svm_model_h.fit(X_train_h, y_train_h)
print("åŽ»é™¤æŸå¤±é«˜äºŽé˜ˆå€¼çš„æ ·æœ¬åŽçš„è®­ç»ƒé›†SVMåˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train_h, svm_model_h.predict(X_train_h))))
print("åŽ»é™¤æŸå¤±é«˜äºŽé˜ˆå€¼çš„æ ·æœ¬åŽçš„æµ‹è¯•é›†SVMåˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, svm_model_h.predict(X_test))))

# subsection è®¡ç®— F1 åˆ†æ•°
f1_train_h = f1_score(y_train_h, svm_model_h.predict(X_train_h), average='weighted')
f1_test_h = f1_score(y_test, svm_model_h.predict(X_test), average='weighted')
print("åŽ»é™¤å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬åŽçš„è®­ç»ƒé›†SVMåˆ†ç±»F1åˆ†æ•°ï¼š" + str(f1_train_h))
print("åŽ»é™¤å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬åŽçš„æµ‹è¯•é›†SVMåˆ†ç±»F1åˆ†æ•°ï¼š" + str(f1_test_h))

# SECTION èˆå¼ƒæŽ‰SVMè®­ç»ƒæ•°æ®ä¸­è¢«åˆ¤å®šä¸ºå¼‚å¸¸å€¼çš„æ ·æœ¬ï¼Œé‡æ–°åœ¨å¤„ç†åŽçš„è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒSVM
print("*" * 100)

# subsection è®¡ç®— accuracyåˆ†æ•°
mask_o = np.ones(len(X_train), dtype=bool)
mask_o[train_outliers_index] = False
X_train_o = X_train[mask_o]
y_train_o = y_train[mask_o]
svm_model_o = svm.SVC(kernel='linear', C=1.0, probability=True)
svm_model_o.fit(X_train_o, y_train_o)
print("åŽ»é™¤åˆ¤å®šä¸ºå¼‚å¸¸çš„æ ·æœ¬åŽçš„è®­ç»ƒé›†SVMåˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train_o, svm_model_o.predict(X_train_o))))
print("åŽ»é™¤åˆ¤å®šä¸ºå¼‚å¸¸çš„æ ·æœ¬åŽçš„æµ‹è¯•é›†SVMåˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, svm_model_o.predict(X_test))))

# subsection è®¡ç®— F1 åˆ†æ•°
f1_train_o = f1_score(y_train_o, svm_model_o.predict(X_train_o), average='weighted')
f1_test_o = f1_score(y_test, svm_model_o.predict(X_test), average='weighted')
print("åŽ»é™¤å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬åŽçš„è®­ç»ƒé›†SVMåˆ†ç±»F1åˆ†æ•°ï¼š" + str(f1_train_o))
print("åŽ»é™¤å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬åŽçš„æµ‹è¯•é›†SVMåˆ†ç±»F1åˆ†æ•°ï¼š" + str(f1_test_o))