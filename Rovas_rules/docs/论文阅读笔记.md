## 一、《ADBench: Anomaly Detection Benchmark》

### 1、主要贡献

1、**最全面的AD基准**。ADBench在57个基准数据集上测试了30种检测算法的性能

2、**研究和应用驱动的基准角度**。监督的可用性，异常类型，以及算法在噪声和数据损坏下的鲁棒性。

3、**研究人员和从业人员的见解和未来方向**。通过大量的结果，我们说明了算法选择的必要性，以及监督和先验知识的价值。

4、**公平和可访问的AD评估**。https://github.com/Minqi824/ADBench上以BSD-2许可证开源了ADBench

### 2、实验过程中的主要发现

1、没有一个基准无监督算法在统计学上优于其他算法

2、只有1%的标记异常，大多数半监督方法可以胜过最好的无监督方法

3、在受控环境中，我们观察到，对于特定类型的异常，最好的无监督方法甚至优于半监督和全监督方法

4、半监督方法显示出在噪声和损坏数据中实现鲁棒性的潜力

### 3、异常检测算法

1、**通过假设异常数据分布的无监督方法**。在过去的几十年中，已经提出了许多无监督方法[3，15，129，150，198]，这些方法可以大致分为**浅层和深层（神经网络）方法**。前者通常具有更好的可解释性，而后者更好地处理大型、高维数据。

2、**将异常检测视为二进制分类的监督方法**。没有专门的监督异常检测算法，人们经常为此使用现有的分类器[3，170]，如随机森林[21]和神经网络[89]。这些方法仅限于检测未知类型的异常[3]。最近的机器学习书籍[4，54]和scikit-learn [133]可以作为监督ML方法的良好来源。

3、**有效使用标签的半监督方法**。半监督AD算法可以利用部分标签的监督，同时保持检测不可见类型异常的能力。一些近期的研究探讨了使用部分标记数据来提高检测性能，以及利用未标记数据来促进表示学习。例如，一些半监督模型仅在正态样本上训练，并且检测偏离在训练过程中学习到的正态表示的异常[7，8，188]。在ADBench中，半监督主要指弱监督下的不完全标签学习

### 4、现有的表格异常检测数据集和基准

1、现有基准主要评估来自**ODDS库[145]、DAMI库[25]、ADRepository [129]和异常检测荟萃分析基准[42]**的部分数据集。在ADBench中，我们包含了几乎所有公开可用的数据集，并添加了**从CV和NLP领域改编的更大的数据集**，以获得更全面的视图。现有的基准包括[25, 38, 42, 150, 166]

### 5、与其他领域的联系

1、虽然ADBench专注于AD任务，但我们注意到存在一些密切相关的问题，包括分布外（OOD）检测[182，183]，**新奇检测[116，137]**和开集识别（OSR）[51，112]。未来的基准可以考虑包括：（i）OOD方法：MSP [65]，基于能量的EBO [104]和基于Mahalanobis距离的MDS [92];**（ii）新奇检测方法：OCGAN [135]和对抗性一类分类器[154]**;以及（iii）OSR方法：OpenGAN [79]和PROSER [204]。

### 6、ADBench：由研究和应用需求驱动的AD基准测试

1、无监督，半监督和监督异常检测的定义，以及相应的算法概述

2、最大的AD基准测试，包含30种算法和57个数据集。算法类别包括（i）最新的无监督AD算法，（ii）SOTA半监督算法，（iii）最新的网络架构，（iv）集成学习方法。公共AD数据集。在ADBench中，我们收集了40多个基准测试数据集[25、42、129、145]，用于模型评估，为了进行尽职调查，我们保留异常率低于40%的数据集。数据集涵盖了医疗保健，音频和语言处理，图像处理和金融等领域。**由于大多数数据集相对较小，因此我们在ADBench中引入了CV和NLP域的10个更复杂的数据集**。预训练模型用于从CV和NLP数据集中提取数据嵌入，以访问更复杂的表示，这已在AD文献中广泛使用[33，115，152]，并显示出比使用原始特征更好的结果。这些最初的非表格数据集有助于了解在进行必要的预处理后，表格AD方法是否可用于CV/NLP数据。

### 7、ADBench中的基准角度

#### 7.1 地面实况标签的可用性（监督）

1、现有的基准仅关注于无监督的设置，即，没有一个标记的异常是可用的。我们首先对现有的无监督异常检测方法进行了基准测试，然后根据[127，131，205]中的设置，使用不同的监督级别评估了半监督和全监督方法。

#### 7.2 异常类型

1、动机：广泛的公共数据集可用于基准测试，但它们通常由不同类型异常的混合物组成，这使得理解AD算法在特定类型异常方面的优缺点具有挑战性。为了更好地理解异常类型的影响，我们在公共数据集的基础上，通过注入特定类型的异常来创建合成数据集，以分析AD算法的响应。

2、ADBench的设计：在ADBench中，我们通过注入特定类型的异常，从基准数据集创建逼真的合成数据集。我们遵循并丰富了[166]中的方法来生成“真实”的合成数据;我们的方法支持更多类型的异常生成。

3、ADBench中四种常见异常的定义和生成过程：

**局部异常是指偏离其局部邻域的异常[22]**。我们遵循GMM过程[118，166]来生成合成正态样本，然后通过缩放参数α = 5来缩放协方差矩阵= α以生成局部异常。

**全局异常与正态数据[68]有更大的不同，由均匀分布生成**。

**依赖异常是指不遵循正常数据遵循的依赖结构的样本[117]**，即，依赖性异常的输入特征被假定为彼此独立。我们使用核密度估计（KDE）[61]来估计特征的概率密度函数并生成正常样本。Vine Copula [1]方法用于生成异常样本

**异常群，也称为群异常[93]，表现出类似的特征**

局部异常（图3a）与正常样本有很好的重叠。全局异常（图3b）更偏离正常样本，并且位于正常聚类的边缘。其他两种类型的异常如预期的那样，在图3c中没有明确的依赖性结构，并且在图3d中具有异常集群。

#### 7.3 噪声和损坏数据的模型鲁棒性

我们试图通过在三种噪声和腐败设置下评估AD算法来评估异常检测模型的鲁棒性：
**1、重复异常**。在许多应用中，由于记录错误等原因，某些异常可能会在数据中重复多次[83]。重复异常的存在也被称为“异常屏蔽”[55、60、100]，这对许多AD算法[25]提出了挑战，例如，基于密度的KNN [11，144]

**2、不相关的特征**。表格数据可能包含由测量噪声或不一致的测量单位[28，55]引起的不相关特征，其中这些噪声维度可能隐藏异常数据的特征，并因此使检测过程更加困难[128，150]。

**3、注释错误**。虽然现有研究[131，152]探讨了未标记样本中的异常污染，但我们进一步讨论了标记污染对算法性能的更普遍影响，其中考虑了正常样本和异常之间的标记翻转[122，202]（高达总标记的50%）。此设置不影响未受监督的方法，因为它们不使用任何标签。

### 8、实验结果与分析

#### 8.1 实验设置

我们进行了98，436个实验（Appx.C）回答Q1（§4.2）：AD算法如何在不同的监督级别下执行？Q2（§4.3）：AD算法如何响应不同类型的异常？问题3（§4.4）：AD算法对噪声和损坏数据的鲁棒性如何？

1、训练集与测试集比例。7比3的比例，流行的AD库包括PyOD [198]，TODS [84]和PyGOD [102]

2、超参数设置。我们使用了它们在原始论文中的默认超参数（HP）设置

**3、评价指标和统计检验。我们通过两个广泛使用的指标来评价不同的AD方法：AUCROC（受试者操作特征曲线下的面积）和AUCPR（精确度-回忆曲线下的面积）值1。此外，基于Wilcoxon-Holm方法的临界差异图（CD图）[34，70]用于统计学比较AD方法组（p ≤ 0.05）**

#### 8.2 具有不同监督程度的数据集上的整体模型性能

1、没有一种无监督的方法在统计学上比其他方法更好

2、当标签信息有限时，半监督方法优于监督方法

3、最新的网络架构（如Transformer）和新兴的集成方法在AD中具有竞争力的性能

4、HBOS、COPOD、ECOD和NB是最快的，因为它们独立处理每个功能。XGBOD、ResNet和FTTransformer的计算量很大

5、未来方向。注意算法选择，超参数优化和半监督AD方法

#### 8.3 不同类型异常下的算法性能

**1、无监督算法的性能高度依赖于其假设和潜在异常类型的对齐**。**局部异常因子（LOF）在统计上优于局部异常的其他无监督方法**（图5a），并且使用第k个（全局）最近邻的距离作为异常分数的**KNN是全局异常的统计最佳检测器**（图5 b）。同样，没有算法在所有类型的异常上都表现良好，LOF在局部异常上实现了最佳AUCROC（图5a），在依赖性异常上实现了第二好的AUCROC排名（图5c），但在聚类异常上表现不佳（图5d）

2、**关于异常类型的先验知识的“力量”可能超过部分标签的使用**。对于局部、全局和依赖异常，大多数标签通知方法的性能都比每种类型的最佳无监督方法（对应于LOF、KNN和KNN）差。

3、未来方向：利用异常类型作为有价值的先验知识。即使在没有标签的情况下，了解异常类型在实现高检测性能方面的重要性。在理想情况下，可以通过动态模型选择和组合等框架，基于异常类型的组成来组合联合收割机多个AD算法[197]。

#### 8.4 算法在噪声和破坏数据下的鲁棒性

**1、无监督方法更容易受到重复异常的影响**。一种解释是，无监督方法通常假设基础数据是不平衡的，只有一小部分异常它们依赖于这个假设来检测异常。显然，在标签的帮助下，更平衡的数据集不会显着影响半监督和全监督方法的性能。

**2、由于特征选择，不相关的特征对监督方法的影响很小**。例如，像XGBoost这样的集成树可以过滤不相关的特征，此外，监督方法（和一些半监督方法，如DevNet）的鲁棒性能表明，标签信息可以有利于特征选择。

**3、半监督和全监督方法都对轻微的注释错误表现出很大的弹性**。尽管当注释错误严重时这些方法的检测性能显著降级（如图7 g和7 h所示），但是它们关于较小注释错误的降级是可接受的。

4、未来研究方向：抗噪声AD算法。一个直接的补救措施是采用无监督特征选择[30，125，126]来对抗不相关的特征。此外，标签信息可以作为模型训练的有效指导，以对抗数据噪声，并且它有助于半监督和全监督方法更加鲁棒。鉴于获取完整标签的困难，我们建议使用半监督方法作为设计更强大的AD算法的骨干。

## 二、《Generalized Out-of-Distribution Detection: A Survey》

### 1、摘要和引言

OOD检测一词于2017年首次出现，此后受到研究界越来越多的关注，导致开发了大量方法，从基于分类的方法到基于密度的方法，再到基于距离的方法。与此同时，异常检测（AD）、新奇检测（ND）、开集识别（OSR）、离群点检测（OD）等问题也与OOD检测有着密切的联系。尽管有着共同的目标，但这些主题都是孤立发展的，它们在定义和问题设置上的细微差异常常会让读者和实践者感到困惑。**在本综述中，我们首先提出了一个称为广义OOD检测的统一框架，它包含了前面提到的五个问题，即，AD、ND、OSR、OOD检测和OD**。在我们的框架下，这五个问题可以被看作是特例或子任务，并且更容易区分。

1、OOD检测的全面调查：注意到近年来存在对AD，ND，OSR和**OD方法的全面调查[16，17，18，19，25]**，该调查提供了OOD检测方法的全面概述，从而补充了现有的调查。我们注意到协变量移位更常用于评估模型泛化和鲁棒性性能，其中标签空间Y在测试期间保持不变。另一方面，语义分布偏移的检测（例如，由于新类的出现）是在该框架中考虑的许多检测任务的焦点。

2、注意，不同的子任务可以很容易地用以下四种二分法来识别：**1）协变量/语义转移二分法; 2）单类/多类二分法; 3）ID分类需要/不需要二分法; 4）归纳/转导二分法**。

#### 1.1 Anomaly Detection

1、背景：“异常”的概念与预先定义的“正常”形成对比。“正常”的概念要明确，要反映真实的任务。当前的异常检测设置通常会将感兴趣的环境限制在某些特定场景。综上所述，异常检测的关键是明确定义正常（通常没有子类），并在某些特定场景下检测所有可能的异常样本。AD可划分为**sensory AD** 和 **semantic AD**。

2、**sensory AD** 和 **semantic AD**的形式定义

3、感官/语义二分法。尽管大多数感觉和语义AD方法由于P（X）的共同移位而被证明是相互包含的，但一些方法专门用于其中一个子任务（参考第4.2节）

4、评估。不同的阈值将产生一系列真阳性率（TPR）和假阳性率（FPR）-我们可以从中计算受试者操作特征曲线下面积（AUROC）[49]。类似地，精确度和召回率值可以用于计算F分数和精确度-召回率曲线下面积（AUPR）的度量[50]。注意，AUPR值可以有两种变体：一种将“正常”视为阳性类别，另一种将“异常”视为阳性类别。对于AUROC和AUPR，较高的值表示更好的检测性能。

5、前的文献认为异常类型有三种：点异常，条件或背景异常，以及群体或集体异常[16，17，19]。在这项调查中，我们主要集中在点异常检测的普及。在**时间序列任务中经常出现的上下文异常**以及**在数据挖掘领域中常见的集体异常**不在本调查范围内

6、**我们使用感觉/语义二分法在任务层面对AD进行细分。从方法论的角度来看，一些文献将AD技术分为无监督和（半）监督环境。请注意，这两个分类法是正交的，因为它们分别关注任务和方法。**

#### 1.2 Novelty Detection

1、在动机方面，新奇检测通常不会像AD那样将“新奇”测试样本视为错误，欺诈或恶意，而是以积极的学习态度将其作为未来潜在使用的学习资源[16，17]

2、根据训练类的数量，ND包含两种不同的设置：1）**单类新奇检测**（oneclass ND）：训练集中只存在一个类; 2）**多类新奇检测**（multi-class ND）：训练集中存在多个类。

3、ND的评价与AD相同，均基于**AUROC、AUPR或F评分**。

4、语义AD可以进一步分为单类语义AD和匹配ND的多类语义AD，**因为语义AD等同于ND**。

5、AD和ND之间的细微差别除了对语义的特殊兴趣之外，一些文献[54，55]还指出**ND应该是完全无监督的（训练中没有新数据），而AD可能有一些异常的训练样本**。

#### 1.3 Open Set Recognition

1、动机方面，在封闭世界环境中训练的机器学习模型可能会错误地将来自未知类别的测试样本分类为具有高置信度的已知类别之一[56]。开集识别（OSR）被提出来解决这个问题。

2、定义：开集识别要求多类分类器同时：1)从已知类中准确地分类测试样本；2)从未知类中检测测试样本。OSR的目标在很大程度上与多类ND的目标相同-唯一的区别是OSR还需要对来自P（Y）的ID样本进行准确分类。

3、评价：与AD和ND类似，**OSR的指标包括F评分、AUROC和AUPR****。除此之外，分类性能还通过标准ID准确度进行评估。**

#### 1.4 Out-of-Distribution Detection

1、背景方面，分布外检测领域，要求模型拒绝与训练分布语义不同的输入，因此不应该被模型预测。

2、定义：对于大多数机器学习任务，分布应该指的是“标签分布”，这意味着OOD样本不应该有重叠的标签w. r. t.训练数据。在常见的机器学习任务（如多类分类）中，分布外检测可以规范为OSR-保持对来自ID类空间y的测试样本的分类性能，并拒绝具有y支持之外的语义的OOD测试样本。

3、评估：除了F-Score、AUROC和aupr之外，另一个常用的度量是fpr@TPRx，它在TPR为x(例如，0.95)时测量FPR。有些作品还使用替代度量TNR@TPRx，相当于1-fpr@TPRx。

4、OSR和OOD检测任务之间的差异有三个方面：

1)不同的基准设置：OSR基准通常将一个多类分类数据集按类拆分为ID和OOD两部分，而OOD检测则以一个数据集为ID，在保证ID/OOD数据集之间类别不重叠的前提下，找到多个数据集作为OOD。

2)OSR中无额外数据：由于理论开放风险约束保证的要求，OSR不鼓励在设计训练期间使用额外数据[24]。

3)OOD检测的广泛性：与OSR相比，OOD检测包含更广泛的学习任务（例如，多标签分类[66]），更宽的解决方案空间

5、虽然当前社区中的大多数作品将关键字“out-of-distribution”解释为“out-of-label/semantic-distribution”，但一些OOD检测作品也考虑检测协变量偏移[67]，声称协变量偏移通常会导致模型性能显着下降，因此需要识别和拒绝

6、我们从泛化的角度提供了另一个定义：分布外检测，或OOD检测，旨在检测模型不能或不想泛化的测试样本[68]。

#### 1.5 Outlier Detection

1、背景：AD、ND、OSR和OOD中的问题设置检测与训练数据分布不同的未见过的测试样本。相比之下，离群值检测直接处理所有观测值，旨在从污染数据集中选择离群值[12，13，14]。由于离群值检测不遵循训练测试程序，但可以访问所有观察结果，因此解决这个问题的方法通常是转导而不是归纳[75]。

2、定义：离群点检测的目的是检测**由于协变量或语义变化而与给定观测集中其他样本显著不同的样本**

3、与所有先前的子任务不同，其内分布是在训练期间定义的，离群值检测的“内分布”是指大多数观察值。由于P（Y）上的语义移位或P（X）上的协变量移位，可能存在离群值。

4、对于数据集清理的应用，离群值检测通常用作主要任务的预处理步骤，例如从开集噪声标签中学习[83]，网络监督学习[84]和开集半监督学习[85]。**要在MNIST上构建离群值检测基准，应选择一个类，以便将属于该类的所有样本视为内点。一小部分来自其他类别的样本被引入作为待检测的离群值。**

5、评价方案：除了**F-scores，AUROC和AUPR**之外，离群检测器的评估还可以通过其支持的主要任务的性能来评估。例如，**如果使用离群值检测器来净化具有噪声标签的数据集，则在经净化的数据集上训练的分类器的性能可以指示离群值检测器的质量**。

6、离群值检测任务可以被认为是广义OOD检测框架中的离群值，因为离群值检测器是在所有观察都给出的情况下操作的，而不是遵循训练测试方案。

### 2、AD、ND、OSR、OOD和OD检测的方法

#### 2.1 Anomaly Detection & Novelty Detection

**1、基于密度的方法：**

基于密度的方法对正态数据（ID）分布进行建模，假设异常测试数据具有较低的可能性，而正常数据具有较高的可能性。**技术包括经典的密度估计、使用深度生成模型的密度估计、基于能量的模型和基于频率的方法。

**参数密度估计假设预定义的分布**[272]。方法涉及多元高斯分布[273，274]、混合高斯分布[275，276]和泊松分布[277]。

**非参数密度估计使用直方图**[279，280，281，282]和核密度估计（KDE）[283，284，285]处理更复杂的场景[278]。

**神经网络**生成高质量的特征，以增强经典的密度估计。自动编码器（AE）[286]和变分自动编码器（VAE）[287]的模型、生成对抗网络（GAN）[288]、基于流的模型[195，289]和表示增强策略

EBM使用标量能量分数来表达概率密度[290]并为AD提供解决方案[291]。

**2、基于重建的方法：**

这些AD方法利用特征空间中的正常和异常数据或重建误差的模型性能差异。

**稀疏重建**假设正常样本可以使用有限的基函数集精确重建，而异常具有更大的重建成本和密集表示[297，298，299]。技术包括基于L1范数的内核PCA [300]和低秩嵌入式网络[301]。

**重建误差方法**假设在正常数据上训练的模型将为正常测试样本产生比异常更好的重建。深度模型包括AE [302]，VAE [303]，GAN [304]和U-Net [305]。基于AE/VAE的模型将联合收割机重建误差与AE/VAE模型[302，303]相结合，并使用诸如通过记忆的常态重建[306，307]，适应模型架构[308]和部分/条件重建[192，309，310]等策略。在半监督AD中，CoRA [311]使用重建误差进行异常检测，在内点和离群点上训练两个AE。使用GAN的重建误差方法利用GAN来计算异常检测的重建误差[304]。去噪GAN [194]，类条件GAN [54]和集成[312]等变体进一步提高了性能。基于梯度的方法在重建任务中观察训练梯度和异常之间的不同模式，使用基于梯度的表示来表征异常[313]。

**3、基于距离的方法：**

**基于距离的方法**通过计算样本和原型之间的距离来检测异常[314]，需要内存中的训练数据。方法包括**K-最近邻[315]和基于原型的方法[316，317]**。

**4、基于分类的方法：**

**基于分类的方法**：AD和单类ND通常被表述为无监督学习问题，但也有一些**监督和半监督方法**。单类分类（OCC）直接学习与正态数据分布的期望密度水平集相对应的决策边界[318]。DeepSVDD [319]将经典OCC引入深度学习社区。PU学习[320，321，322，323]被提出用于半监督AD设置。自监督学习方法使用借口任务，如对比学习[139]，图像变换预测[324，325]和未来帧预测[326]，其中异常更有可能在设计的任务中出错。

理论分析除了算法的发展，一些工作中也提供了对AD和一类ND的理论分析。例如，**[58]构建了一个干净的ID集和一个具有相同样本量的ID/OOD混合集，实现了一个PAC式的有限样本保证，用于以最小的虚警数量检测特定部分的异常**。这些工作对OOD检测的理论研究具有一定的参考价值。

#### 2.2 Outlier Detection

离群值检测（OD）观察所有样本，以识别与多数分布的显著偏差。

**1、基于密度的OD方法：**

包括**高斯分布[327，328]，马氏距离[273]，高斯混合[329]和局部离群值因子（LOF）**[330]。**RANSAC [331]估计数学模型的参数。还可以应用经典密度方法和基于KNN的密度方法**。

**2、基于距离的方法：**

离群值可以通过**邻居计数**[332，333]，**DBSCAN聚类**[334]和**基于图形的方法**[335，336，337，338，339，340，341，342，343]来检测。

**3、基于分类的方法：**

AD方法，如**隔离森林[344]和OC-SVM** [318，319]可以应用于OD。**深度学习模型**可以识别离群值[345]。鲁棒性和特征泛化的技术包括**集成[346]，协同训练[347]和蒸馏[345，348]**。

### 3、实验评估

#### 3.1 实验设置

骨干网采用ResNet18 [357]。如果所实现的方法需要训练，则使用SGD优化器广泛接受的设置，即学习速率为0.1，动量为0.9，权重衰减为0.0005，持续100个时期。

## 三、《Empirical study of outlier impact in classification context》

### 1、摘要和引言

1、本文主要研究在数据点是否为离群点的情况下，离群点对大规模数据集学习模型性能的影响。在该方法中，应用了模糊c-均值聚类算法，并将离群点定义为那些在聚类中具有较大隶属度值且距离聚类质心较远的离群点。**强离群值预计将被检测和进一步分析，而弱离群值被视为噪声**，这可能对数据分析产生不利影响，例如聚类。无论存在强离群值还是弱离群值，都必须进行处理。

2、离群点检测技术可以大致分为以下几类：**基于统计/基于分布的算法、基于距离的算法、基于密度的算法和基于聚类的算法**

(1) 在**基于统计的算法**中，离群值是与标准分布有很大偏差的观测值。**统计方法具有明显的缺点，即不适用于统计分布未知的数据集**。

(2) 还可以使用**基于距离的方法来检测离群值，这是最常用和最简单的检测方法**。在这些方法中，离群点被识别为远离其相邻点的点。注意到，**当处理高维数据集时，基于距离的方法计算量大，并且难以检测正常对象边界内的离群值**。

(3) 此外，还有**基于密度的方法，其中离群值被假设为具有比它们的邻居更低的密度**。与基于距离的方法不同，基于密度的方法（Bai等人，2016; Breunig等人，2000; Tang & He，2017; Xie et al.，2020）比较对象的密度与其邻居的密度。存在许多经典的基于密度的方法，包括**局部离群值因子（LOF）**（Breunig等人，2000）和**低密度模式（COF）**的离群值检测（Tang等人，2002），尽管给定的数据集可能具有不同程度的聚类密度，但其功能良好。Campos等人（2016）发现，**LOF检测器是使用KNN技术的12个检测器组中最精确的**。**当使用基于密度的方法时，必须选择最佳邻居参数k以获得必要的邻居信息**，因为该过程高度依赖于用于计算区域中邻居数量的参数。此外，当特定项目的邻居分布在密度变化的两个集群之间时，精确地测量它们的密度变得困难。

(4) **有许多众所周知的基于集群的方法**（Chen等人，2024; Kang，2022; Li等人，2022）首先对数据集进行聚类，然后计算每个聚类而不是每个单独对象的离群值程度。**基于聚类的方法的有效性在很大程度上取决于正常对象的聚类效果。如果聚类结果是不利的，则检测离群点的结果是无效的**。**ROCF聚类算法**是专门设计来检测离群聚类，以提高基于聚类方法的效率。在Yu和Kang（2023）中，提出了一种基于聚类集成的新奇得分算法，其中将随机子空间和随机k集成方法生成的多个聚类解决方案相结合以计算新奇得分。在基于聚类的集成方法中，为了实现个体分类器的多样性，创建尽可能多的聚类是很重要的。**由于大量的聚类，每个聚类都有少量的观察结果，导致单个分类器的效率低下**。

3、**我们设计了一种FCM驱动的无噪声数据模式识别策略，其中AdaBoostdriven方法将一些数据点设置为潜在离群点，在分类器的训练中较少关注它们，以避免它们对学习性能的负面影响。我们还研究了三种不同的加权损失函数对分类精度的影响**。本文的贡献如下：

（1）当不使用离群值的先验信息时，离群值对大规模数据集的影响得到了证实。

（2）应用模糊c-均值聚类算法，离群点样本定义为在聚类中具有较大隶属度值且距离聚类质心较远的那些点

（3）此外，还详细讨论了不同加权损失函数在不同情况下的影响

（4）仿真实验结果证明了本文方法的有效性

### 2、相关工作

（1）Qin et al.（2019）提出了**使用核密度估计估计局部离群值，称为KELOS**，以高效检测窗口化数据流中的top-n局部离群值。它是一种基于聚类的剪枝算法，对数据点进行聚类，并利用聚类中心估计核密度。为了减少搜索空间，KELOS对每个聚类的局部密度和局部离群值进行了限制，以剪除一些不太可能成为离群值的数据点。

（2）另一方面，**Yoon et al.（2020）采用了不同的剪枝策略来检测窗口数据流中的前n个局部离群值**。核密度估计用于识别局部离群值和识别数据分布受局部因素影响较小的区域。

（3）近年来提出了一种**基于二元分类器集合的一类分类器（BCE-OC）（Kang，2022）。BCE-OC算法将训练数据划分为若干个簇，将每个簇和剩余的簇分别作为伪离群类和目标类**。通过利用伪离群值类，BCE-OC算法能够利用任何传统的分类算法（例如，逻辑模型、随机森林和多层感知器）。此外，由于伪离群值类是通过对来自目标类的数据点进行聚类而生成的，因此保证了它们是互斥的，从而增强了各个离群值检测模型之间的多样性。

（4）此外，Chen et al.（2024）还描述了一种基于密度的空间聚类方法（DBSCAN）。

（5）为了克服参数敏感性问题以及现有离群值算法难以同时检测聚类和局部离群值的问题，Huang et al.（2023）首先基于样本间距离计算了转弯密度。然后，根据k-最近邻和逆k-最近邻的计数，计算样本的转弯比。最后，使用每个样本的转向密度和转向比来计算离群转向因子（OTF）。当OTF值较高时，更有可能出现离群值。

（6）Zhou et al.（2024）提出了一种用于检测离群值的高密度迭代方法。与其他基于k-近邻的方法相比，该方法更适合于各种复杂的数据分布。

（7）Tran et al.（2020）使用“核心点”数据结构实施了一种新的离群值检测系统，该数据结构通过多个距离进行索引。

（8）为了克服基于密度的离群点检测方法的局限性，熊等（2022）提出了邻域加权离群点检测算法（NWOD）

（9）此外，Li等人（2022）使用了一个扩展的近邻集，其中包括k-最近近邻以及反向k-最近近邻，以适应复杂的数据分布。

（10）Yuan et al.（2018）提出了一种混合数据驱动的离群值检测方法。

（11）对于异常值的检测，Zhang等人（2023）提出了一种多源信息融合方法。

（12）此外，在Xie et al.（2020）中，提出了LGOD检测模型来检测异常值，该模型同时考虑了对象的质量和由其邻居产生的局部合力（LRF）。

（13）在Wang和Mao（2019）中，为了监测工业过程，提出了一种基于单类分类的动态集成离群值检测方法。他们生成伪离群值，然后将基础分类器的所有输出转换为概率模型

（14）此外，Baldomero-Naranjo等人（2021）提出了一种基于支持向量机（SVM）的鲁棒分类模型，该模型同时检测离群值并从输入数据中选择特征。

（15）Wang和Mao（2020）中检测和去除离群值的标准基于两个几何标准，即局部密度和与局部拟合平面的偏差。作为Yang等人（2021）提出的均值漂移离群值检测（MOD）方法的一部分，计算样本最近邻的均值，以均值漂移方法执行数据集，并计算样本的偏移距离，以估计离群值的程度。

（16）除了上面提到的离群值检测方法之外，Yang等人（2023 b）提出了基于邻域一致性的搜索方法（KFC），以确定最佳参数k。**作为基于k-近邻的离群点检测方法的一部分，该方法试图解决最优参数的选择问题**

（17）此外，还提出了不同的**基于图的离群值检测方法**，例如Wang和Li（2021），Wang等人（2019）提出的工作，首先构建一个图，然后采用定制的马尔可夫随机游走方法来检测图中的离群值。在Huang et al.（2017）中，基于相互邻居图的概念，提出了一种称为ROCF的方法，其中通过设置聚类大小间隙来分离正常聚类和离群值。在Li et al.（2022）中，提出了一种密度距离决策图，它通过结合全局和局部离群值来同时检测全局、局部和聚类离群值。利用样本与最近邻样本的密度比来判断局部离群点，利用密度提升距离来识别全局离群点。**基于图的方法特别强大，因为它具有强大的表达能力和捕捉一组数据中的长期相关性的卓越能力。尽管这些方法是有用和有效的，但缺点是它们需要大量的时间**。Wang et al.（2018）提出了一种新的离群点检测模型，该模型将图表示与每个对象周围的局部邻域信息相结合，以构建局部信息图。在该模型中，使用随机游走过程计算离群值评分。此外，Pourhabibi et al.（2020）还概述了基于图的异常检测技术。

### 3、本文的方法论

使用交叉熵损失函数，其余略

### 4、实验部分

本节介绍了具体的信息，包括数据集，实验设置，模型分析，以及在12个公开可用的UCI存储库（Dua & Graff，2017）数据集上对10个最先进的分类器进行的方法验证。**它还演示了离群值如何影响结果的情况下，这些样本被删除的情况下，随机样本从现有的数据集生成。此外，我们评估所提出的方法与三个不同的加权损失函数，并证明其对分类精度的影响**。

#### 4.1 数据集设置

这些数据集选自公开可用的UCI机器学习存储库。**在这些数据集中，最初关于样本是否是离群值的基本事实是未知的。本研究旨在识别这些数据集中的离群值样本，并观察它们在存在和不存在离群值的情况下对模型性能的影响。一开始，所有数据集都被视为正常数据，然后根据它们的行为将离群值识别为集群的一部分**。

#### 4.2 实验设置

训练中使用了6层的神经网络，其包括作为输入激活函数ReLU和作为输出激活函数的softmax。此外，使用Adam优化器在500个epochs上以1 e −4的学习速率训练网络。在AdaBoost中，利用了三种决策树算法及其默认参数设置。准确性度量和F1评分测量用于评估存在离群值时的模型性能。其中，准确度是指数据集中正确预测实例（真阳性和真阴性）占实例总数的比例。**特别是，F1分数在处理不平衡数据集时非常有用，因为它同时考虑了假阳性和假阴性。与仅使用准确性相比，此度量提供了对模型性能的更全面的评估。**此外，有10种不同的分类器被训练用于数据分类，包括**线性支持向量机（SVM）、K-最近邻（KNN）、随机森林（RF）、决策树（DT）、线性判别分析（LDA）和逻辑回归（LR）。此外，还使用基于集成的分类算法，诸如梯度提升（GB）、Bagging、AdaBoost和直方图提升梯度分类器（HBGB）**。我们使用所有上述的分类器及其默认参数，除了在逻辑回归的情况下，我们将迭代次数设置为1000。**最后，在所有数据集上执行5重交叉验证**。

#### 4.3 实验结果

在所有数据集上的实验结果表明，所提出的FCM-AD方法能有效提高分类准确率，但需要消耗更多计算资源。

所提出的方法也有一些局限性。例如，在所提出的方法中，指定要使用的聚类的数目是至关重要的。此外，所选数据集可能包含离群值，并且所有被视为正常的样本都可能是离群值，因为我们没有关于每个样本是否为离群值的真实依据。在这种情况下，如果在离群数据上训练模型，则输入数据中的离群值可能导致机器学习算法被不正确地训练，从而导致训练时间更长、模型更不准确，并且最终结果更不令人满意。

## 四、《An outliers detection and elimination framework in classification task of data mining》

本文提出了一种**基于四分位距（IQR）统计方法的离群点检测框架，并利用Winsorizing方法对离群点进行了处理**。在此框架下，利用预处理后的数据集，通过基于学习的优化模型训练径向基函数网络。采用几个标准的加州大学欧文分校（UCI）数据集来衡量该框架的有效性。

### 1、异常值处理

使用不同的方法来检测异常值[44，45]。方法之一是可视化，类似于箱形图，直方图，散点图，IQR方法。有两种方法可以处理离群值：

**(i)处理错误离群值**：在这种方法中，每个错误都应该被删除或纠正。如果存在有效值范围内的数据，则原始输入的数据点，以避免通过删除而丢失重要信息。如果数据会有一些错误，那么最好的方法就是简单地删除条目。

**(ii)处理非错误离群值**：有三种方法用于处理非错误离群值：保留，删除，记录。(i)保留-保留离群值时，请注意它们可能会扭曲实际任务的结果。(ii)删除-最直接的选项是删除任何离群观测。(iii)重新编码-使用winsorizing方法处理离群值，避免大量数据丢失。winsorizing的用法在第4节中介绍。

### 2、总结

本文提出一种被称为四分位距（IQR）的流行统计方法用于识别数据中的离群值。随后，**使用Winsorizing技术对离群值数据进行归一化**。

## 五、《Influence of the Applied Outlier Detection Methods on the Quality of Classification》

无

## 六、《Machine Learning for Anomaly Detection: A Systematic Review》

### 1、摘要和引言

1、在这篇研究论文中，我们进行了一项系统文献综述（SLR），分析了在应用中检测异常的ML模型。本文从**异常检测的应用、ML技术、ML模型的性能度量和异常检测的分类**四个方面对模型进行了分析。我们发现了290篇研究文章，写于2000-2020年，讨论了ML技术的异常检测。此外，我们识别了**29个不同的ML模型，用于识别异常**。最后，我们给出了**22个不同的数据集，并将它们应用于异常检测的实验中**，同时也给出了许多其他的通用数据集。

2、异常检测是指“在数据中发现不符合预期行为的模式的问题”[1]，[2]。异常在抽象的层面上被定义为一种模式，不符合通常的预期行为。异常分为三大类[1]、[9]、[10]：

> **点异常**：如果一个数据实例可以被认为是其余数据的异常，则该实例被称为点异常，并被认为是最简单的异常形式。
>
> **上下文异常**：如果在特定上下文中数据实例异常，但在另一个上下文中不异常，则称为上下文异常。在某些情况下，识别上下文很容易，因此应用上下文检测技术是有意义的。
>
> **集体异常**：如果一组关联的数据实例对于整个数据集是异常的，则称为集体异常。

3、**统计异常检测技术是用于检测异常的一些最古老的算法**[10]。统计方法为所提供的数据的普通行为建立统计模型。然后可以执行统计推断测试以检测实例是否属于该模型。有几种方法用于进行统计异常检测[11]。这包括**基于邻近度的方法、参数方法、非参数方法和半参数方法**。

4、**机器学习（ML）技术越来越多地被用作检测异常的方法之一。**ML是“自动化从示例中获取知识的过程”的努力[12]。**该技术被用来建立一个模型，区分普通和异常类**。因此，异常检测可以根据用于构建模型的训练数据函数分为三大类。

> **监督异常检测：**在这个类中，正常和异常训练数据集都包含标记的实例。在这个模型中，**方法是建立一个预测模型的异常和正常的类，然后比较这两个模型**。然而，在这种模式下，会出现两个问题。**首先，与正常实例相比，训练集中异常的数量要低得多。其次，精确和代表性的标签是具有挑战性的识别，特别是对于异常类**。
>
> **半监督异常检测**：这里的训练仅包括普通类案例。因此，**任何不能被归类为普通的东西都被标记为异常**。半监督技术假定训练数据仅具有正常类的标记实例。**由于它们不需要异常类标签，因此它们比监督方法更常见**。
>
> **无监督异常检测**：在这种情况下，**该方法不需要训练数据集**。因此，**这些方法意味着在测试数据集中，正常实例比异常实例更常见**。然而，如果该假设失败，则导致该技术的高虚警率。
>
> **许多半监督技术可以适于通过使用未标记的数据集样本作为训练数据而在无监督模式下操作**。这种自适应假设测试数据中存在非常少的异常，并且这些异常对于训练期间的模型学习是鲁棒的。

5、本文的组织结构：

> （i）在异常检测中所做的主要预测研究工作
>
> （ii）异常检测中使用的ML算法
>
> （iii）提出的ML模型的估计和准确性
>
> （iv）使用的ML技术的优势和劣势。

### 2、相关工作

1、**Albertola等人[1]提供了异常检测技术和应用的广泛调查。详细讨论了机器学习和非机器学习的不同技术**，如统计和光谱检测方法。同一作者介绍了**另一项关于离散序列异常检测主题的调查[10]**。作者提供了一个全面的和结构化的概述现有的研究在离散/符号序列中检测异常的问题。此外，**Hodge和Austin [15]还对机器学习和统计异常检测方法进行了全面研究**。文中对各方法的优缺点进行了比较。另一方面，**Agrawal和Agrawal [8]提出了使用数据挖掘技术进行异常检测的综述**。

2、几项调查主要侧重于检测特定领域和应用中的异常情况

3、异常入侵检测是当前研究的热点

4、网络异常检测一直是网络安全研究的重要领域

本文的研究与相关的工作有不同之处，如：

> 1.包括机器学习技术，并且技术的模型类型包括监督的、半监督的或无监督的异常检测。
>
> 2.每种技术的精度比较
>
> 3.一个全面的方法，其中包括每种技术的优点和缺点。
>
> 4.涵盖2000年至2020年，这是最近的一段时间。

![image-20240903195831062](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903195831062.png)

![image-20240903195752246](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903195752246.png)

### 3、异常检测应用

异常检测可分为两大类：**基于机器学习的异常检测和基于非机器学习的异常检测**。基于**非机器学习的技术可以分为统计的和基于知识的**。综述表明，**入侵检测、网络异常检测、一般异常检测和数据应用是异常检测领域应用最多的研究**。

### 4、机器学习技术类型

我们确定了28种ML技术，这些技术已被研究人员用于开发模型，以检测其应用中的异常。这些技术可分为六类：**分类、集成、优化、规则系统、聚类和回归**。这些ML技术以两种形式使用：**独立模型或混合模型**。通过组合两种或多种ML技术来获得混合模型。表4显示了所收集的研究文章中ML技术的频率。**很多研究者过去常常将一种以上的ML技术结合起来。**这包括A2（具有一类SVM的DBN）、A23（具有GA的SVM）和A14（具有K-Medoids聚类的SVM）。此外，**支持向量机是最常用的技术，无论是独立的还是在混合模型中**。

![image-20240903200952961](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903200952961.png)

**特征选择/提取**已经在文献中被广泛发现，并且它是朝着丢弃不相关数据的重要举措，这**有助于增强和提高所建议的模型的精度和计算效率**。图4展示了正在应用的21种不同的特征选择/提取技术。此外，我们注意到PCA和CFS是异常检测中最常用的特征选择技术。

![image-20240903201010569](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903201010569.png)

### 5、机器学习模型的总体估计和准确度

估计精度是机器学习模型的主要性能指标。本题重点关注以下四个方面的估计精度：**性能指标、精度值、用于构建的数据集和模型验证方法**。

由于构建ML模型依赖于数据集，因此我们回顾了所选研究文章中用于异常检测的ML模型的数据源。此外，我们确定了22个不同的数据集，这些数据集已用于相关文章的实验和许多其他一般数据集。**数据集可以被分类为合成数据、真实的生活数据和虚拟化数据**。此外，48篇研究论文使用**KDDCup 1999**虚拟数据集，**38篇研究论文采用基准数据集**。

![image-20240903201920698](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903201920698.png)

图6显示，**使用最多的性能指标是真阳性率（TPR）**，也称为检测日期、灵敏度和召回率。**它测量被正确分类的异常**。此外，**116篇论文使用假阳性率（FPR）作为性能指标。该指标测量被错误分类的异常，也可以称为误报率**。此外，**准确度（Acc），精度和F-分数经常被研究人员作为性能指标**。**Acc是正确分类的异常百分比。此外，AUC测量整个ROC曲线下的整个二维面积**。**ROC曲线是用于有效评估入侵检测系统性能的最强指标之一，它是一种说明FPS准确性的图形工具**。另一方面，**精确度通常与F分数和召回率相关，它测量被正确分类为攻击的异常的比率**。此外，我们发现290篇论文中有64篇只使用了一个性能指标，**其中大多数论文只使用了准确性或AUC，这不足以确定ML模型的质量性能**。另一方面，像A10和A69这样的论文使用7到9个性能指标来表示其ML模型的性能。此外，**除了性能指标之外，许多论文还提出了计算性能指标，例如CPU利用率、执行时间、训练时间、测试时间和计算时间**。

![image-20240903202553328](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903202553328.png)

### 6、无监督、半监督或监督的异常检测技术的百分比

根据图7，**27%的选定论文应用了无监督异常检测类型，使其成为研究文章中使用最多的技术**。另一方面，18%的人应用了监督异常检测，而7%的人同时应用了监督和非监督异常检测分类。相比之下，5%的研究文章采用了半监督学习。此外，1%的人应用半监督与非监督异常检测。令人惊讶的是，42%的研究文章没有提到他们应用的异常检测的分类类型。

### 7、总结

这篇系统的文献综述研究了通过机器学习技术（ML）进行的异常检测。从异常检测类型的应用、ML技术的类型、ML模型精度估计和异常检测类型（监督、半监督和无监督）四个方面对ML模型进行了综述。该综述调查了2000-2020年发表的相关研究。我们查询了290篇回答了本综述中提出的四个研究问题（RQ）的研究文章。

我们在所选论文中确定了43种不同的异常检测应用。我们观察到，**入侵检测，网络异常检测，一般异常检测和数据应用是最经常应用在异常检测领域的研究**。此外，在2011年至2019年期间，研究人员开始采用更多的异常检测应用程序。至于RQ 2，我们展示了研究人员应用的2**9种不同的ML模型，其中最常用的是SVM。此外，我们注意到对构建混合模型的兴趣**。此外，我们发现**PCA和CFS是21种特征选择/提取技术中最常用的**。在RQ 3中，我们介绍了每篇研究论文应用的性能指标，我们发现**290篇论文中有64篇使用准确性或AUC作为主要性能指标，这是不够有效的**。此外，**我们确定了22个不同的数据集，已被用于相关文章的实验以及许多其他一般的数据集**，和大多数实验使用真实的生活数据集作为训练或测试数据集的模型。最后，在RQ 4中，我们统计了所选研究文章中使用的异常检测分类类型。**我们发现27%的选定论文应用了无监督异常检测类型，使其成为研究文章中最常用的方法。其次使用最多的方法是应用监督异常检测，占18%，其次是7%的论文同时应用监督和非监督异常检测分类**

## 七、《Deep Learning for Anomaly Detection: A Review》

近年来，深度学习实现了异常检测，即深度异常检测已经成为一个重要的方向。本文对深度异常检测方法的研究进行了全面的分类，包括**3个高级分类和11个细粒度分类**。我们回顾了它们的**关键直觉、目标函数、基本假设、优缺点**，并讨论了它们如何应对上述挑战。

### 1、本文的贡献点：

> 1、问题的性质和挑战。我们讨论了**一些独特的问题的复杂性异常检测和由此产生的很大程度上未解决的挑战**
>
> 2、分类和制定。我们将当前的深度异常检测方法制定为三个原则框架：**用于通用特征提取的深度学习，正常性的学习表示，以及端到端的异常得分学习**。一个层次分类法的基础上提出了**11个不同的建模角度的方法**进行分类。
>
> 3、综合文献综述。我们回顾了机器学习，数据挖掘，计算机视觉和人工智能，以全面的文献综述研究进展。为了提供深入的介绍，我们描述了**基本假设，目标函数，关键的直觉和它们的能力**，在解决上述一些挑战的所有类别的方法。
>
> 4、未来的机会。我们将进一步讨论一系列未来可能的机遇及其对应对相关挑战的影响。
>
> 5、源代码和数据集。**我们征集了几乎所有类别的方法的公开源代码和大量具有真实的异常的真实数据集**，以提供一些经验比较基准。

### 2、问题复杂性

与大多数、规则或明显模式的问题和任务不同，异常检测解决少数、不可预测/不确定和罕见事件，导致所有（深度和浅层）检测方法都存在一些独特的问题复杂性：

> **不可知**。**异常与许多未知因素有关，突发行为、数据结构和分布未知的实例**。它们在实际发生之前是未知的，例如新的恐怖袭击、欺诈和网络入侵。
>
> **异常类。异常是不规则的**，因此，**一类异常可能表现出与另一类异常完全不同的异常特征**。例如，在视频监控中，异常事件抢劫、交通事故和入室盗窃在视觉上有很大的差异。
>
> **稀有和类不平衡**。异常通常是罕见的数据实例，与通常占数据绝大多数的正常实例形成对比。这导致在大多数应用程序中无法获得大规模标记数据。
>
> **各种类型的异常**。**点异常**是指相对于温度异常的个别情况。**条件异常**，又名上下文异常也指在特定上下文中的个别异常实例，即，数据实例在特定上下文中是异常的，否则是正常的。**群体异常，**又名集体异常是作为整个w.r. t异常的数据实例的子集。其他数据实例;集体异常的各个成员可能不是异常

### 3、现有的深度异常检测方法面临的挑战

> 1、**异常检测召回率低**。由于异常非常罕见且异质，因此很难识别所有异常。许多正常情况被错误地报告为异常，而真正复杂的异常却被遗漏了。尽管多年来已经引入了过多的异常检测方法，但是当前最先进的方法，特别是无监督方法（例如，[17，84]），仍然经常在真实世界的数据集上产生高误报[20，115]。**如何减少误报和提高检测召回率是最重要但也是最困难的挑战之一，特别是未能发现异常的巨大代价**。
>
> 2、**高维和/或非独立数据中的异常检测**。异常通常在低维空间中表现出明显的异常特征，而在高维空间中变得隐藏和不可察觉。**在由原始特征或新构造的特征的小子集所跨越的降低的低维空间中执行异常检测是直接的解决方案**，例如，在基于子空间[70，77，84，123]和基于特征选择的方法[12，109，111]中。
>
> 3、**正常/异常的数据有效学习**。由于收集大规模标记异常数据的难度和成本，完全监督的异常检测通常是不切实际的，因为它假设具有正常和异常类别的标记训练数据的可用性。**在过去的十年中，主要的研究工作一直集中在无监督的异常检测，不需要任何标记的训练数据**。然而，**无监督方法不具有任何真实异常的先验知识。他们在很大程度上依赖于他们对异常分布的假设。另一方面，通常不难收集标记的正常数据和一些标记的异常数据。在实践中，经常建议尽可能利用这些易于访问的标记数据[2]**。因此，利用这些标记的数据来学习正常/异常的表达表示对于准确的异常检测至关重要。另一个研究方向是弱监督异常检测，假设我们有一些异常类别的标签，但类别标签是部分/不完整的（即，它们不跨越异常类的整个集合），不精确（即，粗粒度标签），或不准确的（即，某些给定的标签可能是不正确的）。两个主要的挑战是**如何学习表达正常/异常表示与少量的标记异常数据，以及如何学习检测模型**，被推广到新的异常发现的给定的标记异常数据。
>
> 4、**抗噪声异常检测**。许多弱/半监督异常检测方法假设标记的训练数据是干净的，这可能容易受到错误地标记为相反类别标签的噪声实例的影响。在这种情况下，我们可以使用无监督的方法，但这无法利用真正的标记数据。主要的挑战是，噪声的数量可能与数据集有很大的不同，并且噪声实例可能不规则地分布在数据空间中。
>
> 5、**检测复杂异常**。现有的大多数方法都是针对点异常的，不能用于条件异常和群异常，因为它们表现出与点异常完全不同的行为。这里的一个主要挑战是**将条件/组异常的概念纳入异常测量/模型**。另一个主要的挑战是，**一些异常只有在考虑两个或更多数据源时才能检测到**。
>
> 6、**异常现象解释**。在许多安全关键领域中，如果将异常检测模型直接用作黑盒模型，则可能存在一些重大风险。缓解此类风险的一种有效方法是使用异常解释算法，提供有关特定数据实例被标识为异常的原因的直接线索。然后，人类专家可以调查并纠正这种偏见。在一些应用中，提供这样的解释可能与检测准确性同样重要。**大多数异常检测研究只关注检测的准确性，而忽略了对已识别异常的解释能力**。

**深度方法可以实现整个异常检测管道的端到端优化，并且还可以学习专门为异常检测定制的表示。这两种能力对于应对上述六大挑战至关重要，但传统方法不具备。**特别是，它们有助于在很大程度上提高标记的正常数据或一些标记的异常数据的利用率，而不管数据类型如何，减少了对大规模标记数据的需求，如在完全监督的设置中（CH2，CH3，CH4，CH5）。这随后产生了更有信息的模型，从而获得了更好的召回率（CH1）。对于异常解释的挑战，尽管深度方法通常是黑箱模型，但它们提供了将异常检测和解释统一到单个框架中的选项，从而对特定模型发现的异常进行更真实的解释（见8.5节）。深度方法还擅长从各种类型的数据（如高维数据、图像数据、视频数据、图形数据等）中学习复杂的结构和关系，这种能力对于解决各种挑战（如CH1、CH2、CH3和CH5）非常重要。此外，它们还提供了许多有效且易于使用的网络架构和原则性框架，以无缝地学习异构数据源的统一表示。这使得深度模型能够应对一些关键挑战，如CH3和CH5。虽然有浅层方法来处理这些复杂的数据，但它们通常比深层方法弱得多，适应性也差。

### 4、应对深度异常探测的挑战

深度神经网络利用可由计算图表示的线性/非线性函数的复杂组合来学习表达性表示[49]。深度学习的两个基本构件是激活函数和层。

#### 4.1 形式化定义

![image-20240903211615805](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903211615805.png)

![image-20240903211629349](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903211629349.png)

#### 4.2 深度异常检测的分类

从建模的角度将深度异常检测方法分为三个主要类别和11个细粒度类别。方法分类的概述如图1所示。具体来说，深度异常检测由三个概念范式组成-**用于特征提取的深度学习，学习常态的特征表示和端到端异常得分学习**。

![image-20240903211755055](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903211755055.png)

### 5、用于特征提取的深度学习

#### 5.1 定义

这类方法旨在利用深度学习从高维和/或非线性可分离的数据中提取低维特征表示，用于下游异常检测。特征提取和异常评分是完全脱节的，彼此独立。因此，深度学习组件仅作为降维工作。方法形式如下：
![image-20240903212228603](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903212228603.png)

与异常检测中流行的降维方法（如主成分分析（PCA）[21，140，180]和随机投影[80，112，123]）相比，**深度学习技术在提取语义丰富的特征和非线性特征关系方面表现出更好的能力**[14，49]。深度学习模型提取的特征表示保留了有助于将异常与正常实例区分开的区分信息。

#### 5.2 两种研究路线

**一条研究路线是直接使用流行的预训练深度学习模型，如AlexNet [75]，VGG [143]和ResNet [58]来提取低维特征**。此外，与许多其他任务类似，**从在源数据集上预训练的深度模型中提取的特征表示可以被转移到目标数据集上微调异常检测器**。如[6]所示，一类支持向量机（SVM）可以首先使用在ILSVRC上预训练的VGG模型进行初始化，然后进行微调以改善MNIST数据的异常分类[78]。类似地，在MNIST上预先训练的ResNet模型可以在各种视频监控数据集中进行异常事件检测[117，176]。

这一类别中的**另一个研究方向是明确地训练深度特征提取模型，而不是用于下游异常评分的预先训练的模型**[44，65，163，168]。

#### 5.3 优缺点

优势：(i)大量最先进的（预先训练的）深度模型和现成的异常检测器是现成的。(ii)深度特征提取比常用的线性方法具有更强的降维能力。(iii)由于深层模型和检测方法的公开可用性，该方法易于实现。

缺点：(i)特征提取和异常评分完全脱节，往往导致异常评分不理想。(ii)预先训练的深度模型通常限于特定类型的数据。

#### 5.4 针对的挑战

**这类方法将高维/非独立的数据投影到基本上较低维的空间上，使得现有的异常检测方法能够在更简单的数据空间上工作**。低维空间通常有助于揭示隐藏的异常并减少假阳性（CH2）。然而，应当注意，由于数据投影与异常检测完全解耦，因此这些方法可能不为异常检测保留足够的信息。此外，该方法允许我们利用多种类型的特征，并学习语义丰富的检测模型（例如，[65、66、163]中的各种预定义图像/视频特征），这也有助于减少假阳性（CH1）

### 6、学习正态性的特征表征

这类方法在某种程度上将特征学习与异常评分相结合，而不是像上一节那样完全解耦这两个模块。这些方法通常分为两类：**通用特征学习和异常度量相关特征学习**。

#### 6.1 通用特征学习

这类方法通过优化并非主要针对异常检测设计的通用特征学习目标函数来学习数据实例的表示，但学习的表示仍然可以增强异常检测，因为它们被迫捕获一些关键的底层数据。

![image-20240905094047531](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905094047531.png)

##### 6.1.1 自动编码器

这种方法的目的是学习一些**低维的特征表示空间**，在这些空间上可以很好地重构给定的数据实例。这是一种广泛用于数据压缩或降维的技术[61，69，150]。在异常检测中使用该技术的启发是，**强制学习特征表示以学习数据的重要规则性，从而最小化重构误差;异常难以从结果表示中重构，因此具有较大的重构误差**。该方案的假设是**正常实例可以比异常更好地从压缩空间重构**。AE由编码网络和解码网络组成。**编码器将原始数据映射到低维特征空间，而解码器尝试从投影的低维空间恢复数据**。这两个网络的参数通过重构损失函数来学习。

![image-20240905094413244](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905094413244.png)

已经引入了几种类型的正则化自动编码器来学习更丰富和更具表达力的特征表示[38，95，128，153]。特别地，**稀疏AE**以鼓励隐藏层的激活单元中的稀疏性的方式训练，例如，保持最活跃的单位[95]。**𝐾去噪AE** [153]旨在通过学习从一些预定义的损坏数据实例而不是原始数据重建数据来学习对小变化具有鲁棒性的表示。**收缩AE** [128]进一步学习特征表示，这些特征表示对相邻实例的微小变化具有鲁棒性。这是通过基于编码器的激活的雅可比矩阵的Frobenius范数添加惩罚项来实现的。**变分AE** [38]通过使用潜在空间上的先验分布对数据实例进行编码，将正则化引入表示空间，防止过拟合并确保学习空间的一些良好属性，以便生成有意义的数据实例。

AE易于实现，并且在检测异常时具有直观性。**复制器神经网络**[57]是探索数据重构以检测异常的想法的第一件工作，实验集中在静态多维/表格数据上。**RandNet** [29]通过学习AE的集合来进一步增强基本AE。在RandNet中，训练了一组独立的AE，每个AE都有一些随机选择的常量dropout连接

AE还被广泛用于检测表格数据以外的数据中的异常，例如序列数据[91]、图形数据[37]和图像/视频数据[163]

优势基于数据重构的方法的**优点**如下。

> (i)不良事件的概念是直接的，对不同类型的数据是通用的。
>
> (ii)可以利用不同类型的强大AE变体来执行异常检测。

它们的**缺点**如下。

> (i)所学习的特征表示可能由于训练数据中的不频繁的规则性和离群值或异常的存在而有偏差。
>
> (ii)数据重构的目标函数是针对降维或数据压缩而设计的，而不是异常检测。结果，所得到的表示是底层规则性的一般概括，其对于检测不规则性不是最佳的。

针对的挑战。在AE框架下，可以使用不同类型的神经网络层和架构，从而允许我们检测高维数据以及非独立数据（如属性图数据[37]和多元序列数据[91，97]）中的异常（CH2）。**如果所学习的表示更有表达力，则这些方法可以比基于手工特征构建的传统方法减少假阳性**（CH1）。**AE通常易受训练数据中存在的数据噪声的影响，因为它们可以被训练以记住这些噪声，从而导致异常的严重过拟合和小的重建误差**。**RPCA的思想可用于AE，以训练更稳健的检测模型**[175]（CH4）。

##### 6.1.2 生成性对抗网络

基于GAN的异常检测在[138]中的早期使用之后，作为一种流行的深部异常检测方法迅速出现。这种方法通常旨在学习生成网络的潜在特征空间，以使潜在空间很好地捕捉给定数据的正态性。然后将真实的实例和生成的实例之间的某种形式的残差定义为异常分数。在GAN中，从生成网络的潜在特征空间生成正常数据实例比生成异常数据实例更好。

早期的方法之一是**Anogan**。**AnoGAN的一个主要问题是在z的迭代搜索中的计算效率低**。解决该问题的一种方式是添加额外的网络，该网络学习从数据实例到潜在空间的映射，即，生成器的逆，产生类似**EBGAN** [170]和**快速AnogAN** [137]的方法。**GANomaly** [3]通过将生成器网络改为编码器-解码器-编码器网络并添加两个额外的损失函数，进一步改进了生成器。近年来，已经引入了许多其他GAN，如**Wasserstein GAN [10]和Cycle GAN [177]**。

这些方法的**优点**如下。

> (i)GAN已经证明了在**生成真实实例方面的上级能力，特别是在图像数据上**，使得能够检测到从潜在空间重构较差的异常实例。
>
> (ii)大量现有的基于GAN的模型和理论[32]可适用于异常检测。

**缺点**。

> (i)遗传神经网络的训练可能会遇到多种问题，例如**无法收敛和模式崩溃**[99]，这导致了在训练基于遗传神经网络的异常检测模型时存在很大的困难。
>
> (ii)**生成器网络可能会被误导，并生成正态实例流形之外的数据实例**，特别是当给定数据集的真实分布是复杂的或者训练数据包含意外的离群值时。
>
> (iii)基于GAN的异常评分可能是次优的，因为它们是建立在生成式网络上的，其目的是为数据合成而不是异常检测而设计。

针对的挑战。与AE相似，**基于GAN的异常检测能够通过检查从学习的低维潜在空间（CH2）的重建来检测高维异常**。当潜在空间保留了重要的异常判别信息时，它有助于比原始数据空间（CH1）中的检测精度提高。

##### 6.1.3 自监督分类

该方法通过构建自监督分类模型来学习正常性的表示，并将与分类模型不一致的实例识别为异常。这种方法植根于基于交叉特征分析或特征模型的传统方法[64，105，149]。假设是**正常实例比异常实例更符合自监督分类器**。

![image-20240905102959559](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905102959559.png)

![image-20240905103008883](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905103008883.png)

**基于深度一致性方法的优点**如下。

> (i)它们在无监督设置与半监督设置下都能很好地工作。
>
> (ii)异常评分的基础是梯度幅度及其更新的一些固有特性。

**它们的缺点如下**。

> (i)特征变换操作通常与数据相关。**上述变换操作仅适用于图像数据**。
>
> (ii)虽然分类模型是以端到端的方式训练的，但是基于一致性的异常分数是基于分类分数而不是优化中的集成模块导出的，因此它们可能是次优的。

**针对的挑战**。

> 该方法学习的正态性的表达性低维表示有助于比在原始高维空间（CH1和CH2）中更好地检测异常。由于自监督分类器中异常和正常实例之间存在一些固有差异，该方法也能够在**无监督设置中工作**[157]，证明了**对训练数据中异常污染的良好鲁棒性**（CH4）。

#### 6.2 异常度量相关特征学习

异常度量相关特征学习的目的是**学习针对一个特定的现有异常度量进行专门优化的特征表示**。形式上，这组方法的框架可以表示为

![image-20240905103727717](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905103727717.png)

![image-20240905103741633](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905103741633.png)

##### 6.2.1 基于距离的度量

基于深度距离的异常检测旨在学习针对特定类型的基于距离的异常度量而专门优化的特征表示。基于距离的方法简单明了且易于实现。已实现**DB outliers [72, 73], 𝑘-nearest neighbor distance [125, 126], average 𝑘-nearest neighbor distance [9], relative distance [173], and random nearest neighbor distance [116, 144]**。这些**传统的基于距离的异常度量方法**的一个主要缺陷是，由于维数灾难，**它们不能有效地在高维数据中工作**。该方案的假设是**异常分布在远离其最近邻居的地方，而正常实例则位于密集的邻域中**。新型的基于距离的方案包括**[112]中探索**，其中利用基于随机邻居距离的异常度量[116，144]来驱动从超高维数据中学习低维表示；以及**[155]中探索的更简单的想法**使用相同实例的优化表示和随机投影表示之间的距离来指导表示学习。

**这类方法的优点如下**。

> (i)基于距离的异常是简单明了的，**并且在文献中有丰富的理论支持**。因此，基于深度距离的异常检测方法可以在已有的相关工作中打下坚实的基础。
>
> (ii)**该方法工作在低维表示空间，能够有效地处理传统的基于距离的异常测度所不能处理的高维数据**。
>
> (iii)他们能够学习专门为自己量身定制的表征。

**它们的缺点如下**。

> (i)大多数基于距离的异常度量**所涉及的大量计算**可能是将基于距离的异常度量结合到表示学习过程中的障碍。
>
> (ii)它们的能力可能受到**基于距离的异常测量的固有弱点**的限制。

**针对的挑战**。

> **该方法能够学习为现有的基于距离的异常测量量身定制的低维表示，解决了基于距离的检测中臭名昭著的维数灾难**[178]（CH1 & CH2）。如[112]中所示，可以设计适应的三重态损失，以利用一些标记的异常示例来学习更有效的正态表示（CH3）。得益于伪异常标记，方法[112，155]对于潜在的异常污染也是鲁棒的，并且在完全无监督的设置（CH4）中有效地工作。

##### 6.2.2 基于单类分类的度量

这类方法的目的是学习为后续基于一类分类的异常检测定制的特征表示。**单类分类是指学习一组数据实例的描述以检测新实例是否符合训练数据的问题**。它是用于异常检测的最流行的方法之一[101，131，139，148]。大多数单类分类模型都是**受支持向量机（SVM）[31]的启发**而产生的，例如两个广泛使用的单类模型：**单类SVM（v-SVC）[139]和支持向量数据描述（SVDD）**[148]。该方案的假设是**所有的正常实例都来自一个单一的（抽象的）类，可以用一个紧凑的模型来概括，而异常并不符合这个模型**。

有许多研究致力于**将单类SVM与神经网络结合**[27，104，161]。深度单类SVM的关键思想是从神经网络支持的低维表示空间而不是原始输入空间学习单类超平面。

![image-20240905105126719](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905105126719.png)![image-20240905105239725](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905105239725.png)

**该公式带来两个主要好处：（i）它可以利用（预先训练的）深度网络来学习用于下游异常检测的更有表达性的特征，以及（iii）它还有助于去除核函数中计算昂贵的成对距离计算。**

与深度单类SVM类似，**深度SVDD [132]也旨在利用神经网络将数据实例映射到最小体积的球体中，然后采用铰链损失函数来保证球体中心和投影实例之间的余量**。

**这类方法的优点如下**。

> (i)**基于一类分类的异常在文献中有很好的研究**，并且为基于一类分类的深异常方法提供了坚实的基础。
>
> (ii)表示学习和单类分类模型可以被统一以学习定制的和更优的表示。
>
> (iii)在传统的一类模型中，它们将用户从手动选择合适的核函数中解放出来。

**它们的缺点如下**。

> (i)在正态类内具有复杂分布的数据集中，一类模型可能无效。
>
> (ii)检测性能取决于基于单类分类的异常度量。

**针对的挑战**。

> 这类方法通过学习针对一类分类模型（CH1和CH2）优化的低维表示空间来提高检测精度。这些方法[133]可以利用少量标记的正常和异常数据来学习更有效的一类描述模型，该模型不仅可以检测已知的异常，还可以检测新的异常类（CH3）。

##### 6.2.3 基于聚类的措施

基于深度聚类的异常检测旨在学习表示，使得异常在新学习的表示空间中明显偏离聚类。聚类和异常检测的任务自然地彼此联系在一起，因此**已经有大量的研究致力于使用聚类结果来定义异常，聚类大小[67]、到聚类中心的距离[59]、聚类中心之间的距离[68]和聚类成员资格[141]**。基于高斯混合模型的异常检测[43，94]也被包括在这一类别中，因为它与聚类的一些内在关系，例如，高斯混合模型（GMM）中的似然性拟合对应于数据实例到高斯聚类/分量的中心的距离的集合[2]。假设**正常实例比异常实例对群集的附着性更强**。

一般来说，这里有两个关键的直觉：**（i）好的表示可以实现更好的聚类，并且好的聚类结果可以为表示学习提供有效的监督信号;（ii）由于聚类算法所做的基本假设的差异，针对一种聚类算法优化的表示不一定对其他聚类算法有用**。它的损失函数通常是最关键的部分，一般可以用公式表示为：

![image-20240905151212089](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905151212089.png)

![image-20240905151227287](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905151227287.png)

基于深度聚类的方法的**优点**如下。

> (i)**大量的深度聚类方法和理论**可以用来支持异常检测的有效性和理论基础。
>
> (ii)与传统的基于聚类的方法相比，**基于深度聚类的方法学习特别优化的表示，这有助于比在原始数据上更容易地发现异常，特别是在处理复杂数据集时**。

它们的**缺点**如下。

> (i)异常检测的性能在很大程度上依赖于聚类结果。
>
> (ii)聚类过程可能由于训练数据中的污染异常而有偏差，这又导致较低效的表示。

针对的**挑战**。

> 将基于聚类的异常度量应用于新学习的数据输入的低维表示空间，当新的表示空间保留了足够的判别信息时，深度方法可以获得比原始数据空间（CH1和CH2）更好的检测精度。一些聚类算法对离群点敏感，当给定数据被异常污染时，很大程度上会误导深度聚类和后续的异常检测。使用来自自动编码器重建误差的手工特征的深度聚类[179]可以帮助学习更鲁棒的模型w.r.t.污染物（CH4）。

### 7、端到端异常评分学习

该研究线旨在**以端到端的方式学习标量异常分数。与依赖于异常度量的特征学习相比，这种方法中的异常评分不依赖于现有的异常度量;它具有直接学习异常评分的神经网络**。通常需要新的损失函数来驱动异常评分网络。形式上，该方法旨在学习端到端异常分数学习网络：

![image-20240905152012190](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905152012190.png)

下面我们回顾这一类别中的四种主要方法：**排序模型、先验驱动模型、软最大似然模型和端到端一类分类模型**。该框架的关键是将顺序或判别信息纳入异常评分网络。

#### 7.1 排序模型

**这组方法旨在直接学习排名模型**，以便可以根据与异常的绝对/相对排序关系相关的可观察有序变量对数据实例进行排序。异常评分神经网络是由可观察的有序变量驱动的。假设是**存在一个可观察到的有序变量，可以捕捉到某些数据异常**。

**基于模型的深度排序方法的优点如下。**

> (i)异常分数可以直接用适应的损失函数来优化。
>
> (ii)它们通常不受异常定义的限制，因为它们对异常和正常实例之间的有序顺序施加了一个弱假设。
>
> (iii)这种方法可以建立在诸如学习排名等领域的成熟的排名技术和理论的基础上[85，87，158]。

**它们的缺点如下。**

> (i)在这些方法中**至少需要某种形式的标记异常**，这可能不适用于这样的标记异常不可用的应用。[117]中的方法是完全无监督的，并且获得了一些有前途的性能，但是与半监督方法相比仍然存在很大的差距。
>
> (ii)由于模型被专门地拟合以检测少数标记的异常，因此它们可能**不能推广到表现出与标记的异常不同的异常特征的看不见的异常**。

#### 7.2 先验驱动模型

该方法使用先验分布来编码和驱动异常分数学习。由于以端到端的方式学习异常分数，因此先验可以施加在内部模块或学习输出（即，异常分数）的分数学习函数。

将先验知识纳入内部异常评分函数的最新研究是基于**贝叶斯逆强化学习（IRL）的方法**[107]。关键的直觉是，给定一个接受一组序列数据作为输入的智能体，智能体的正常行为可以通过其潜在奖励函数来理解，因此，**如果智能体给测试序列分配了低奖励，则该序列被识别为异常**。IRL方法[102]用于推断奖励函数

**在[115]中探索了对异常分数强制执行先验的想法**。受[74]中广泛的经验结果的启发，这些结果显示各种真实世界数据集中的异常分数非常符合高斯分布，该工作使用高斯先验对异常分数进行编码并实现分数的直接优化。

**优势先验驱动模型的优点如下。**

> (i)异常分数可直接通过相关系数进行优化。一个给定先验。
>
> (ii)它提供了一个灵活的框架，用于将不同的先验分布结合到异常分数学习中。不同的贝叶斯深度学习技术[156]可适用于异常检测。
>
> (iii)先验还可以产生比其他方法更可解释的异常分数。

**它们的缺点如下。**

> (i)针对不同的异常检测应用场景，设计一个通用有效的先验知识是非常困难的。
>
> (ii)如果先验不很好地拟合底层分布，则模型可能工作得不那么有效。

**目标挑战：**

> 先验知识使模型能够学习不同复杂数据（如高维数据和顺序数据（CH1和CH2））的低维表示。通过对异常分数施加先验，偏差网络方法[115]在利用有限数量的标记异常数据来增强正常和异常的表示方面表现出有希望的性能，从而大大提高了检测召回率（CH1和CH3）。

#### 7.3 Softmax Likelihood Models

这种方法旨在通过最大化训练数据中事件的可能性来学习异常分数。**由于异常和正常实例分别对应于罕见和频繁模式，因此从概率的角度来看，正常实例被假定为高概率事件，而异常倾向于低概率事件**。因此，事件可能性的负值可以自然地被定义为异常分数。Softmax似然模型通过噪声对比估计（NCE）等工具有效且高效地实现了这一目标[54]。假设**异常和正常情况分别是低概率和高概率事件**。

**该方法主要用于检测分类数据中的异常[30]**。受此应用的启发，采用类似的目标函数来检测异质属性二部图中的异常事件[45]。

**softmax模型的方法的优点如下。**

> (i)可以将不同类型的交互结合到异常分数学习过程中。
>
> (ii)异常分数是相对于t忠实地优化的。我们要捕捉的特定异常交互作用。

**它们的缺点如下。**

> (i)当每个数据实例中的特征/元素的数量很大时，交互的计算可能非常昂贵，即，对于个特征/元素的-阶交互，每个实例的时间复杂度高
>
> (ii)异常分数学习严重依赖于负样本生成的质量。

#### 7.4 端到端单类分类

这类方法旨在**训练一个单类分类器，该分类器学习以端到端的方式区分给定实例是否正常**。与5.2.2节中的方法不同，该方法**不依赖于任何现有的单类分类度量，例如单类SVM或SVDD**。**该方法的核心思想是学习一个正常实例的单类判别器，以便很好地将这些实例与不利地生成的伪异常区分开**。**假设是(i)可以有效地合成近似于异常的数据实例。(ii)所有的正常实例都可以用一个有区别的一类模型来概括**。

**在[103]中，引入了Fence GAN**，其目标是生成紧密位于训练数据分布边界的数据实例。这是通过在生成器中引入两个损失函数来实现的，这两个损失函数强制生成的实例沿着训练数据的球体边界沿着均匀分布。

**这类方法的优点如下。**

> (i)其异常分类模型是以端到端的方式逆向优化的。
>
> (ii)它可以得到对抗学习和一类分类的丰富技术和理论的发展和支持。

**它们的缺点如下。**

> (i)很难保证生成的参考实例很好地类似于未知异常。
>
> (ii)GAN的不稳定性可能导致生成的实例具有不同的质量，从而导致不稳定的异常分类性能。最近在[169]中研究了这个问题，其表明这种类型的异常检测器的性能在不同的训练步骤中可能剧烈波动。
>
> (iii)它的应用局限于半监督异常检测场景。

**目标挑战：**

> 逆向学习的一类分类器学习生成真实的边缘/边界实例，从而能够学习表达性低维正态表示（CH 1和CH 2）。

### 8 算法和数据集

#### 8.1 代表性算法

一些主要的模型设计总结如下：

> （i）大多数方法在**无监督或半监督模式下运行**;
>
> （ii）深度学习技巧，如数据增强，dropout和预训练未被充分探索;
>
> （iii）使用的**网络架构不是那么深**，大多数方法的网络层不超过五层;
>
> （iv）**(leaky) ReLU**是最流行的激活函数;
>
> 以及（v）可以使用不同的骨干网络来处理不同类型的输入数据。

这些算法中的大多数的源代码是公开的。我们在附录A的表A1中总结了这些源代码，以便于访问。

![image-20240905154608876](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154608876.png)

![image-20240905154706461](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154706461.png)

#### 8.2 具有真实异常值的数据集

**异常检测发展的一个主要障碍是缺乏具有真实的异常的真实世界数据集**。许多研究（例如，[3，48，103，132，157，170，175]）因此评估了他们提出的方法在从流行分类数据转换的数据集上的性能。这种方式可能无法反映在现实世界中的异常检测应用的方法的性能。

我们在表3中总结了**21个公开可用的具有真实的异常的真实世界数据集的集合**，以促进对这些数据集的性能评估。这些数据集涵盖了以各种数据类型呈现的广泛的流行应用领域。这里**只包括大规模和/或高维复杂数据集**，为深度异常检测提供具有挑战性的测试平台。此外，**在https://git.io/JTs93上提供了广泛使用的异常检测数据集**（包括表3中的一些预处理数据集）的持续更新集合。

![image-20240905154951383](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154951383.png)

### 9 总结和展望

#### 9.1 深度弱监督异常检测

**深度弱监督异常检测[114]旨在利用深度神经网络来学习具有一些弱监督异常信号的异常通知检测模型，例如，部分/不准确/不准确标记的异常数据**。这些标记的数据提供了重要的异常信息，可以成为提高检测召回率的主要驱动力[112，114，115，145，147]。由于**异常可能是高度异质的**，因此可能存在超出给定异常示例的跨度集的未知/新颖异常。因此，这里的一个重要方向是未知的异常检测，我们的目标是建立检测模型，从有限的标记异常推广到未知的异常。

**为了检测属于给定异常示例的相同类别的异常，可能与检测新的/未知的异常一样重要**。因此，另一个重要的方向是开发数据有效的异常检测或少数异常检测，其中我们的目标是学习已知异常类别的高度表达性表示，仅给出有限的异常示例[112，114，115，152]。应

#### 9.2 复杂异常的深度检测

大多数深度异常检测方法都**集中在点异常上，表现出比传统方法更好的性能**。然而，条**件/群体异常的深层模型却很少被探索**。可能需要**新的神经网络层或目标函数**。与传统方法类似，目前的深度异常检测主**要集中在单一数据源上**。多模态异常检测是一个很大程度上未开发的研究领域。

#### 9.3 可解释和可操作的深度异常检测

可解释的深度异常检测和可操作的深度异常检测对于理解模型决策和结果、减轻对人类用户的任何潜在偏见/风险以及实现决策操作至关重要。

## 八、《Outlier Detection: Methods, Models, and Classification》

### 1 摘要

在过去的十年中，我们见证了大量的研究工作，致力于设计高效的离群值检测技术，同时考虑**效率、准确性、高维数据和分布式环境**等因素。在这篇文章中，我们提出并研究了这些特征，当前的解决方案，以及在识别新的离群值检测策略方面面临的挑战和未来的研究方向。我们提出了一个分类的最近设计的离群值检测策略，而其基本特征和属性。我们还介绍了几种新的趋势离群点检测方法，设计用于**高维数据，数据流，大数据和最小标记数据**。最后，我们回顾了它们的优点和局限性，然后讨论了未来和新的挑战性问题。

### 2 引言

在早期，检测离群值的动机是数据清理：**从数据集中删除离群值，以便参数统计模型能够更平滑地拟合训练数据**。**很快，更多的注意力转向异常值本身，因为异常值通常代表有趣且关键的信息。**

异常值检测具有挑战性。“一个重要的原因是由于**离群值实例的罕见性而缺乏标记数据**。因此，许多方法本质上是无监督的。一种典型的离群点检测任务如下：给定一组数据实例，识别那些显著偏离其余数据的实例（可以是固定数量）。然而，很**难提出一种适用于所有数据集和场景的偏差的通用数学度量**。**此外，由于无监督的性质，在统计上偏心的实例和用户在真实的生活中感兴趣的实例之间存在差距**。因此，离群点检测面临着新的挑战：**识别高维数据、无界海量数据流、大规模分布式数据中的离群点等**。

#### 2.1 异常值定义和分类

1、离群值通常基于以下假设定义[21]：**（1）离群值在其特征方面不同于正常值;（2）与正常实例相比，离群值在数据集中是罕见的**。

2、**Outliers 和 anomalies**是离群值检测中最常用的两个术语。事实上，它们经常互换使用[14，22]。存在着一些细微的差异。一般来说，**anomalies表明了一种不同的潜在生成机制。相比之下，Outliers往往强调统计稀有性和偏差，而它们是否由不同的机制产生并没有直接说明**。在统计学和机器学习的某些情况下，**Outliers是指那些使模型更难拟合的数据实例（有时是错误的数据点）**在这种情况下，人们要么**移除Outliers，要么使用稳健模型**（例如，鲁棒的深度自动编码器[18]），以最大限度地减少离群值的影响。从另一个角度来看，**在监督学习中，异常是更好的术语，因为有可靠的指导来建模异常的生成机制**。相比之下，由于缺乏可靠的指导，**无监督学习方法通常依赖于数据的内在分布或结构，以测量偏离规范的程度，希望发现的离群值代表感兴趣的异常**。

3、有不同的方法来分类离群值。

首先，**基于构成异常模式所涉及的数据实例的数量**，**存在（1）点离群值和（2）集体离群值[14]。点异常值是指与数据集的其余部分有很大偏差的单个数据实例。**这是最容易识别的离群值类型，也是离群值检测研究的主要重点[14]。**集体离群值是相对于整个数据集的其余部分出现异常的数据实例的集合**。**根据比较的范围，点异常值可进一步分为（1）局部异常值和（2）全局异常值**。局部离群值的概念首先在局部离群值因子（LOF）中引入[23]。**局部离群值的检测依赖于特征差异（例如，邻域密度的差异），而全局离群值解决整个数据集的差异**。

**根据输入数据的类型，离群值可以分为（1）矢量离群值和（2）图形离群值[24]。**向**量离群点是指向量类多维数据，而图离群点存在于图数据中**。**类向量数据点有多个属性，每个属性都有一个数值或一个分类值**。离群值检测方法依赖于两个矢量状数据点之间的距离定义（例如，Euclidean distance和Cosine distance）。图数据由节点和边组成，它们很好地表示了数据对象之间的相互依赖关系。**图形数据中的异常值可以是点异常值（例如，节点离群值和边缘离群值）或集体离群值（例如，子图异常值）**[24]。本调查的重点是解决向量多维数据中的离群点检测问题的方法。

#### 2.2 方法分类和讨论范围

1、基于输入数据标签的可用性，离群值检测方法可以分为三种类型：**（1）监督离群值检测，（2）半监督离群值检测和（3）无监督离群值检测。**监督离群值检测依赖于标记的训练数据来构建预测模型。**监督离群值检测可以被视为一个二元分类问题，通常具有不平衡的训练数据：正常类中的实例比离群类中的实例多得多**。**半监督离群值检测使用仅具有正常标签的训练数据**（例如，**单类随机森林**[26]）或**使用大多数未标记数据和少量标记数据**（例如，Das等人[27]）。**无监督离群值检测使用未标记的数据来构建用于离群值得分计算的模型**（例如，**隔离森林**[28]）**或直接计算输入数据的离群值分数而不构建模型**（例如，**LOF** [23]）。

2、**本文主要对无监督离群检测进行了综述**。无监督离群点检测是目前研究最广泛的一类离群点检测技术。这是由于当我们的目的是发现以前从未遇到过的异常模式时，**用于离群点检测的标记数据通常很难获得，甚至是不期望的。然而，近年来，许多研究探索了如何将人的反馈融入到无监督模型中，并展示了相对于纯无监督技术的非常有前途的改进。**

3、本调查中讨论的方法的分类如图1所示。在更高的层次上，我们将方法分为**基本方法和高级方法**，这是基于高级方法是在基本方法的基础上发展起来的，以应对新的挑战。这些挑战包括**高维数据（“维数灾难”）、无界和动态数据流、分布式环境中的大数据以及有效使用非常有限的标记数据**。根据这些方法所使用的基本技术，**基本方法进一步分为基于邻近的方法和基于投影的方法**。基于邻近度的方法依赖于基于最近邻的技术或聚类算法来量化离群值与附近数据点的邻近度，基于该邻近度来定义离群值分数。基于投影的方法采用LSH [29]和空间填充曲线[30]等技术，将原始数据转换为复杂度降低的新空间/结构，其中离群值分数基于新空间的特征定义（例如，与LSH相同的bin中的数据点数量[29]）

![image-20240905162152003](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905162152003.png)

4、为了避免复杂性和混乱，**我们统一了“基于距离”和“基于密度”类别的方法，并将它们置于“基于最近邻”的保护伞下**。这是因为它们都涉及最近邻的概念。然而，**本文中讨论的基于密度的数据流方法都是在LOF [23]之上开发的**。

### 3 基于邻近度的方法

**基于邻近度的方法基于离群值与附近数据点的关系来识别离群值。一种常见的情况是离群值位于稀疏区域，在给定距离内只有很少的数据点，或者最近的数据点非常远。**

#### 3.1 最近邻方法

基于最近邻的离群点检测方法基于数据点与其最近邻的关系来测量异常程度。有两种主要的方法来定义邻域：**k最近邻（k-NN）和以数据点为中心的预定半径内的邻域**。基本假设是正常数据实例更接近它们的邻居，从而形成密集的邻域，而离群数据实例远离它们的邻居，从而稀疏地填充。表1总结了本节介绍的基于最近邻的方法。

![image-20240905162832856](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905162832856.png)

一些原始的基于最近邻的方法非常直接和直观。例如，Ramaswamy等人[41]的方法使用与第k个最近邻居的距离作为离群值得分。Angiulli等人[41]的方法使用到k-NN的距离之和[42]。Knorr等人[31]依赖于数据点的预定半径内的相邻点的数量。由于异常程度是在整个数据集的上下文中进行比较的，因**此这些方法检测全局离群值**。他们假设数据集不同区域的密度是均匀的。

因此，在检测精度方面，**考虑到不同密度的方法往往优于它们[22]。后一种方法侧重于局部离群值**。**LOF [23]是一种著名的方法，它首先引入了局部离群值的概念**，并启发了许多关于局部离群值的后续工作。**离群值的LOF分数高于正常值，并且较高的分数指示实例更可能是离群值**。**基于连通性的离群因子（COF）[36]解决了LOF的缺点，它假设离群模式仅在基于欧氏距离的球形邻域中是低密度的**。然而，这种异常值的观点过于简单化，并且可能无法成功识别其他邻里关系模式中的异常值。Papadimitriou等人[37]基于局部密度的定义提出了**局部相关积分（LOCI）**，局部密度是围绕数据点（rneighborhood）的半径r内的相邻点的计数。他们设计了一种相关的度量，称为多粒度偏差因子（MDEF）。**受影响的离群值（INFLO）**[38]使用反向最近邻集（k-RNN）与k-NN相结合来计算离群值得分。**[39]提出了局部离群值概率（Loop）**，它输出一个概率，表明数据点是离群值的可能性。Loop试图解决其他方法面临的困境：**如何选择合适的离群值阈值来区分离群值和内点**。公式化的循环范围从0到1，具有可解释的含义，因此在实际场景中更有用。最后，为了将PLOF转换为概率，使用偏差标准化和高斯误差函数。**Ting等人[43]在他们的工作中指出**，基于最近邻的离群值检测方法与传统的信念相反，即更多的训练数据会产生更好的结果。**对于单个数据集，存在一个最佳样本量。当实际使用的样本小于最佳大小时，数据分布不能很好地表示。但是当实际样本量增加到最佳样本量以上时，由于正常数据点和异常值之间的分离减小，因此所得的准确度往往会降低**。

基于子采样，使用**最近邻包络（iNNE）[40]**的隔离创建隔离区域以确定离群值分数。**LeSiNN [16]**是另一种离群值检测方法，也可以使用子采样构建模型。**iNNE和LeSiNN都具有线性时间复杂度**，因为对数据点的k-NN搜索限于样本集内，并且**样本大小是恒定的**。此外，**iNNE和LeSiNN都使用集成来确保离群检测器的稳定性**。总体的最终离群值得分是多组样本的平均得分。

**与基于聚类的方法相比，基于最近邻的方法在离群点分析上具有更精细的粒度的优点。这使得基于最近邻的方法能够区分强离群值和弱离群值，而弱离群值更有可能被视为噪声[22]。由于成对距离的昂贵计算，高的计算复杂度通常作为代价而出现。此外，k的选择对整体性能有着巨大的影响。**但是，对于不同的方法和数据集，k的最佳选择是不同的。过大的k导致异常值和正常点之间的差别很小。过小的k导致邻近密度的不可靠估计。

**使用二次采样是将时间复杂度降低到线性的好方法。二次采样还有助于实现上述掩蔽效应。**与集成相结合，基于子采样的方法也可以提供有前途的可靠性能。然而，**新的问题是如何确定合适的样本大小和集合大小。**通常，在处理大型数据集时，需要较大的系综大小以获得良好的性能。但是，这可能会导致执行时间显著增加。

#### 3.2 基于聚类的方法

聚类是一种被广泛研究的数据挖掘技术，它将数据分组到多个聚类中，相似的数据实例最终在同一个聚类中。**基于聚类的离群点检测算法通常分为两步：首先用聚类算法对数据进行分组，然后根据聚类结果分析数据的偏离程度。**正如Aggarwal [22]所指出的那样，聚类和离群值之间存在互补关系，可以简单地说，**不属于任何聚类的数据点被认为是离群值**。除了聚类成员（无论是否在聚类中），还有两个其他常用的聚类相关量来构建离群值。**第一个是到聚类中心的距离，假设正常数据点靠近聚类中心，而异常值远离它们。第二个是簇的基数，假设正常数据点的簇是密集和大的，而离群数据点的簇是稀疏和小的。**

**与基于最近邻的离群点检测方法相比，基于聚类的离群点检测方法的一个主要优点是检测效率高**。k均值聚类的时间复杂度为O（Nkt），具有N个数据实例、k个聚类中心和t次迭代。相比之下，**基于最近邻的方法通常由于成对距离的计算而导致二次时间复杂度**。聚类算法在表2中总结。

![image-20240905164918032](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905164918032.png)

**Jiang等人[44]提出了一种离群点检测方法，该方法基于改进的k均值聚类和从聚类中心构建的最小生成树**。改进的kmeans聚类具有初始值和聚类数目的上限。如果遇到的数据点远离所有现有的聚类中心，则该数据点将被指定为新聚类的中心，这意味着聚类的数量增加一个

**基于聚类的局部离群值因子（CBLOF）[46]是一种基于聚类的离群值检测方法，通过定量测量区分小聚类和大聚类**。在Amer等人的后期工作中。**[47]，证明了简单地去除CBLOF的簇基数可以产生更好的结果**，称为未加权CBLOF。注意，**CBLOF和LDCOF都具有独立于框架的合并的聚类算法。但正如[47]所建议的，具有固定数量的聚类（如k-means）的算法在性能上是有利的，并且由于潜在的非球形分布，建议高估聚类数量**。

Du等人。**[17]设计了一种基于密度峰值聚类算法的局部离群值检测方法[48]**，这是一种简单但有效的基于密度的方法，可以检测任意形状的聚类。密度峰值聚类依赖于两个假设：（1）聚类中心具有比周围数据点更高的局部密度，以及（2）聚类中心与具有更高局部密度的其他数据点具有相对较大的距离。第一个假设代表了一个集群的集中效应，而第二个假设区分了一个集群中心和一个邻近的成员在同一个集群。

#### 3.3 基于预测的方法

在本节中，我们介绍了使用各种投影技术的方法（例如，随机投影[50]、LSH [29]等）为了**将原始数据转换到具有降低的维度或复杂度的新空间中，同时仍然保留邻近信息**（例如，成对欧几里德距离、最近邻关系等）在一定程度上是原始数据集。**然后可以在投影空间中执行离群点检测，从而大大改善了执行时间**。

**表3是本节介绍的各种方法的摘要。它们中的许多非常有效，也适用于高维数据**。值得注意的是，**子空间技术也是一种直接投影**。它们已被广泛用于解决高维数据的挑战。

![image-20240905165736586](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905165736586.png)

**投影索引最近邻（PINN）[51]基于随机投影方案来降低数据维度**，从而降低确定k-NN关系的计算成本。**随机投影优于其他降维技术（如PCA [57]）的优点是其效率**。PINN的作者进一步证明了所采用的随机投影也可以保持数据点的k距离以及随后的邻域。这些属性为它们在投影空间中的k-NN搜索提供了理由。k-NN搜索是许多基于kNN的离群点检测算法中最耗时的部分。随着维数的降低，不仅计算中涉及的数据更少，而且索引结构也更高效（例如，参考文献[58，59]）**可以用来将k-NN搜索的时间复杂度从O（N2）降低到O（NlogN）**。这些索引结构不适用于高维数据的情况。**在确定近似k-NN关系之后，将数据点映射回原始空间，在原始空间中进行LOF的其余计算。为了提高结果的质量，它们在投影空间中保持k个以上的最近邻，在原始空间中将其截断为k**。

**局部敏感离群值检测（LSOD）[52]利用局部敏感哈希（LSH）[29，53]来创建离群值的初始排名**。局部敏感哈希（LSH）首先由Indyk等人提出。[53]用于欧几里德空间中的近似最近邻问题。**LSH函数的属性是，它们将相似的数据点映射到相同的哈希桶，与那些彼此不太相似的数据点相比，它们的概率更高**。**LSOD仅基于映射到同一桶中的点的数量来生成数据点的离群值排名**。背后的假设是，**离群值往往具有较少的相似数据点，因此最终会出现在具有少量数据点的桶中**。为了有效地识别顶级离群值，L**SOD集成了许多基于距离的离群值检测的修剪策略，包括PPSN [41]，ANNS [41]和PPSO [61]**。具有较高排名的数据点被首先处理，这导致这些修剪策略的高阈值，从而大大提高了效率。最终的离群值得分是到第k个NN的距离。

**Schubert等人提出了另一种基于投影的离群值检测算法**。[54]。**为了解决近似最近邻搜索问题，他们采用了空间填充曲线的集合[30]。空间填充曲线将多维空间映射到一维空间**。它已被广泛用于开发多维数据的索引方案[62]和在多维空间中执行相似性搜索[63]等。此外，**他们提供了一个分布式框架来扩展算法**，其中工作节点执行空间填充曲线投影并将样本发送到主节点进行分布估计。

**Loda [55]采用稀疏随机投影线**。每个投影将数据点映射到一维空间，基于该一维空间生成直方图以估计每个数据点的概率。重要的是要知道，**Loda遵循了集合的精神，并演示了如何将多个弱离群值检测器组合在一起，从而产生非常好的结果**。

#### 3.4 基于树的方法

在本节的最后，我们将介绍一些基于树的方法。**从广义上讲，树模型的构建也可以被视为一种投影，其中原始数据点被映射到特定的树节点，并且这些树节点包含关于原始数据的邻近信息**。

**柳塔尔。[28]开发了Isolation Forest，它是一种无监督的树集成**，直观上类似于用于分类问题的随机森林。隔离森林由多棵隔离树（iTree）组成，可以看作是决策树的无监督对应物。其背后的直觉是，**离群值在较早阶段被隔离的可能性比正常数据实例更高**。因此，预计离群值在隔离树中具有较短的高度。**隔离森林应该是用数据集中的小样本而不是整个数据集来构建的。子采样增加了树集成的多样性，这有利于结果的准确性。子采样还有助于缓解或避免淹没（错误地将正常实例识别为离群值）和掩蔽（紧密聚集的离群值使其难以被检测到）问题**。**二次采样的另一个好处是效率的提高，因为只有一小部分数据被处理来构建模型。毕竟，在不需要处理成对距离的情况下，隔离森林是非常有效的，具有线性时间复杂度**。**此外，隔离森林在各种数据集上也表现出很高的检测精度**。

**Hariri等人[56]提出了扩展隔离森林来解决隔离森林的缺点**。他们深入讨论了原始隔离森林中使用的轴平行切割的局限性，以及为什么随机超平面有利于算法。**扩展隔离森林与隔离森林的不同之处在于，它使用随机生成的涉及多个属性的超平面来分割数据并构造二叉树节点，而不是每次分割只使用一个特征**。

### 4 高维离群点检测

正如Zimek等人所总结的那样。[34]，高维数据中离群值检测的挑战是双重的：**效率方面和有效性方面**。高维数据实现效率的困难主要归因于两个原因。首先，**由于增加的维度，相似性搜索（诸如k-NN搜索）在计算成本方面变得更昂贵**。其次，**一些用于加速离群值检测的技术，如采样[66，67]，修剪[68]，排名策略[38，69]和有效的索引结构（R树[58]，X树[59]等）。显著降低或甚至几乎不引入高维数据的改进**。

与这个问题相关的一个常用术语是**“维数灾难”[34，70-72]。它指的是在高维空间中，基于偏差的离群点检测往往会受到一种称为“距离集中”的现象的干扰：所有数据点对的距离趋于一致。因此，数据集中的所有区域变得几乎同样稀疏，并且很难捕捉异常值和正常实例之间的区别。这种现象是由大量“正常噪声”不相关维度/属性的稀释效应引起的[22]。**换句话说，这些不相关的维度隐藏了可用于识别离群值的信息。本节重点介绍旨在解决高维数据中离群值检测的一个或两个挑战性方面的方法。

**为了提高高维数据离群点检测的效率，Ghoting等人。[73]提出了递归分箱和重投影（RBRP）**。RBRP受到ORCA [68]的启发，ORCA是一种嵌套循环离群值检测方法，其离群值得分基于到第k个最近邻居的距离。

![image-20240905173128567](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905173128567.png)

请注意，第3节中提到的**投影索引最近邻（PINN）[51]算法也旨在提高高维离群值检测的效率**。PINN利用随机投影进行降维，并使用近似k-NN来提供有效的性能。

更多的工作在文献中**集中在高维离群检测问题的有效性方面**。Kriegel等人。**[74]引入了一种基于角度的离群值检测方法（ABOD），以解决基于欧几里得距离的算法在面对高维数据集时遇到的质量恶化的问题**。因此这会导致昂贵的**O（n3）时间复杂度**。为了降低时间复杂度，引入了两个近似变体：**FastABOD和LB-ABOD**。FastABOD将离群值得分计算的数据点对的选择限制在数据点的k-NN。LB-ABOD是ABOD的一个下界近似，其目的是有效地获得具有最高分数的顶级离群值。

此外，许多作品探索**子空间的解决方案，以处理“维数灾难”的影响，假设只有一个子集的属性是相关的发现有意义离群值，其余的属性是噪音**。**Kriegel等人。[75]开发了一种离群值检测模式**，该模式基于单个数据点与由一组参考点跨越的轴平行超平面的偏差来评估离群值。**[76]提出了一种测量子空间对比度的方法，并相应地提出了一种称为高对比度子空间（HiCS）的子空间搜索方法**。**Sathe等人。[77]提出了RS-Hash，这是一种基于随机散列的非常有效和准确的子空间离群值检测方法**。

**高维数据的离群点检测由于效率和有效性的问题而一直是一个具有挑战性的问题。大量的方法通过诸如近似k-NN、子空间和集成等技术来解决这两个方面中的一个或两个。基于子空间的方法最近在研究界受到了很大的关注.一个不可避免要考虑的问题是如何识别最有意义和最有用的子空间，同时最小化相关的计算成本，假定不同属性的可能组合的数量可以是巨大的。**

**除了上述方法，近年来其他有趣的工作包括：HighDOD [80]，使用动态子空间搜索方法和基于样本的学习过程; LODES [81]，依赖于一种新的基于局部密度的谱嵌入来识别非线性子空间中的离群值; RAMODO [82]使用表示学习来降低维度，并将其与基于随机距离的方法相结合[16]。**

### 5 数据流中的异常检测

### 6 分布式异常检测

传统的集中式数据挖掘和机器学习方法由于一些原因而显得力不从心。**首先，由于磁盘存储、内存、CPU等方面的限制，单个计算机的资源可能不足以执行计算任务**;**其次，集中式算法可能无法满足许多现代应用所要求的严格的时间约束，例如，实时大数据分析应用**。**此外，数据集本身也变得越来越分散**。

**将离群值检测扩展到分布式环境的一个具有挑战性的任务是在保证准确性的同时最大限度地减少通信开销。这个任务对于需要计算数据点之间的成对距离的方法来说尤其困难**。值得注意的是，除了随后介绍的算法之外，一些专注于分布式k-NN搜索的工作[105-109]可以为基于分布式k-NN的离群点检测算法的开发提供启发。

![image-20240905175602124](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905175602124.png)

**Bhaduri等人。[110]开发了DOoR，这是ORCA方法[68]的分布式解决方案**，它使用第k个最近邻距离作为离群值得分，并具有简单的修剪规则。

**Angiulli等人。[111]将SolvingSet算法[112]扩展到分布式环境**。求解集是一个迭代扩展的样本集，基于该样本集之外的每个数据实例，在每次迭代中估计它们的近似k-NN。

**Bai等人[115]提出了LOF的分布式解决方案**。采用了基于网格的划分方法，试图平衡工作负载并将相邻的网格分配给同一台机器。

**分布式Top-N LOF（DTOLF）[114]**为参考文献[116]中提出的Top-N LOF方法提供了分布式解决方案。

依赖于基于网格的数据分区的方法的一个主要限制是它们不能很好地随数据的维度而扩展。

此外，**Tsou等人。[12]提出了一种分布式无监督异常检测框架**，以解决无线传感器网络设备异常行为检测的挑战。

### 7 基于深度学习的异常检测

**通过假设离群值实例更难以由训练的自动编码器重建，利用自动编码器进行离群值检测的一种简单方法是使用重建误差作为离群值得分[124]**。然而，由于在**无监督设置中训练数据可能被离群值污染**，由于其对离群值的敏感性和可能的过拟合，模型的有效性可能会显着减弱。

**为了解决当训练数据包含离群值时自动编码器对过拟合的敏感性，Chen等人。[121]提出了一种基于集合的离群值检测方法，该方法将一组自动编码器的结果与连接架构中的多样性相结合**。

**鲁棒深度自动编码器（RDA）[18]通过将输入数据分为两个矩阵来解决受污染的训练数据问题，一个包含离群值，另一个由自动编码器有效重建。这个想法受到鲁棒主成分分析的启发[125]**

![image-20240905180638307](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905180638307.png)

**一个典型的/标准的生成对抗网络（GAN）[127]有两个对抗组件，一个生成器神经网络和一个递归神经网络**。生成器被训练以从潜在空间学习映射（例如，从均匀分布采样）到数据空间。换句话说，生成器生成假数据实例，这些假数据实例用作训练器的负训练实例。然而，鉴别器经过训练可以区分生成器生成的假数据和真实的数据实例。**GAN可以用于离群点检测，因为它具有强大的建模复杂数据分布的能力**。

**Schlegl等人[122]设计了AnoGAN，旨在检测图像数据中的异常作为疾病标记**，这是一种学习正常数据实例的代表性模型的GAN，伴随着异常评分方案。

**另一种基于GAN的异常检测方法是逆向学习异常检测（ALAD）[123]**。类似于AnoGAN [122]的想法，ALAD也依赖于GAN来对正常实例的分布进行建模，并且由此产生的异常分数基于重建误差，即，原始输入数据和它们的重构之间的不相似性。

**[82]提出了一种基于深度神经网络的框架，称为RAMODO**，用于学习由与目标离群值检测器相关的损失函数指导的离群值检测表示。对表示学习的定制导致更有效的表示，并相应地提高检测精度。

**将深度神经网络应用于离群值检测的主要优势是能够从复杂和高维数据中提取代表性特征，与传统方法相比，它可以提供更准确的结果。然而，通常需要大的数据量才能让深度神经网络避免过拟合。但在许多情况下，数据的可用性是有限的。此外，许多基于深度学习的方法对超参数非常敏感。调整超参数以获得最佳性能可能是一项具有挑战性且耗时的任务。**

### 8 有反馈的异常检测

无监督离群点检测技术在文献和实践中都很受欢迎，**因为通常标记的数据通常是稀缺或不可用的**。此外，有时这样的标记数据甚至是不期望的，因为**意图发现以前从未遇到过的异常模式**。然而，**当有标记的数据可用时，即使很少，如果标记的数据被适当地利用来调整现有的模型，则原始无监督技术的准确性可以显著提高**。这种范式福尔斯半监督学习的范围[134]。获取和利用标记实例的**一种典型方法是通过主动学习**[135]：**初始模型建立在未标记数据上，基于此，一些数据实例通过一些查询策略被领域专家标记。然后用新获取的标签信息更新模型。这种类型的反馈循环可以迭代地进行，直到满足某些标准**。

**在Görnitz等人的工作中。[136]，异常检测被认为是一个名为支持向量数据描述（SVDD）的优化问题[137]**。SVDD计算一个超球体来包围数据，半径为r，中心为c。超球面代表常态。异常分数基于到中心c的距离：在超球体之外发现的数据点被认为是离群值，而在超球体内部的数据点被认为是内点。他

**Das等人。[27]提出了一种半监督方法，该方法将专家反馈迭代地结合到称为Loda [55]的集成异常检测方法的模型中**。它们旨在向专家呈现最大数量的异常。

**Vercruyssen等人[11]描述了一种半监督异常检测方法**，该方法采用约束k均值聚类[141]来执行初始无监督评分，并通过结合专家标记来迭代更新异常评分。

**Siddiqui等人。[139]提出了一种用于异常检测的通用算法，旨在通过结合专家反馈将异常分数与应用程序特定的兴趣度对齐**。他们使用在线凸优化[140]来构建这个异常检测问题，并提供了对应于两种不同方法的两个损失函数。损失函数与人类专家反馈相关联，并提升与反馈一致的异常分数。一种用基于树的异常检测方法（例如，描述了隔离森林[28]），它是通过根据反馈调整树中边的权重来实现的。

### 9 公开的挑战

## 九、《Evaluation of Machine Learning Algorithms for Anomaly Detection》

1、在本文中，**我们评估了12种机器学习（ML）算法在网络实践中检测异常行为的能力。该评估是在三个公开的数据集上进行的：CICIDS-2017，UNSW-NB 15和工业控制系统（ICS）网络攻击数据集**。实验工作是通过莱斯特大学的ALICE高性能计算设施进行的。在这些实验的基础上，对ML算法进行了全面的分析。**评价结果表明，随机森林（RF）算法在所有数据集上的准确度、精确度、召回率、F1评分和受试者工作特征（ROC）曲线方面均达到最佳性能**。值得指出的是，其他算法的性能接近RF，并且关于选择哪种ML算法的决定取决于应用系统产生的数据。

2、目前，通过使用人工智能（AI）技术，研究人员可以将从网络活动，物联网（IoT）设备，SCADA系统[4]，移动的电话[5]，智能电网[6]收集的数据或**来自任何机器的日志数据分类为正常或异常行为的二进制分类，或与特定攻击相关联的正常或不同类型的异常行为的多类攻击分类**。**异常检测（Anomaly Detection），也称为离群值检测（Outlier Detection），是一种用于从大多数数据中区分看起来不寻常的罕见事件的方法**。

3、然而，由于深度学习算法需要大数据集进行训练，**Parampottupadam和Moldovann [10]得出结论，在某些应用中，深度学习模型的性能不一定优于其他传统ML模型**。ML算法使用统计模型，为系统提供在没有人为干预的情况下生成预测的能力，访问样本数据（称为训练数据），以学习和改善人类体验。可用的ML算法可以分析大量数据，包括：**监督ML算法，无监督ML算法，半监督ML算法和强化ML算法**。

4、**在本研究中，我们评估了六个经典的监督ML算法和六个深度学习算法**。这些方法的选择是基于先前研究中算法的使用和性能。**所选的经典ML算法有Logistic回归、朴素贝叶斯、K邻近（KNN）、决策树（Decision Tree）、自适应增强（Adaptive Boosting）和随机森林（RF）**。**我们选择的深度学习算法包括卷积神经网络（CNN）、卷积神经网络和长短时记忆（CNN-LSTM）、长短时记忆（LSTM）、门控递归单元（Gated Recurrent Units，GRU）、简单递归神经网络（Simple Recurrent Neural Network，RNN）和深度神经网络（Deep Neural Network，DNN）**。

![image-20240905193120233](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905193120233.png)

5、在我们的研究中使用了两种类型的标签分类方法，即**二进制攻击分类和多类攻击分类**。图1所示的方法的一般结构分为四个阶段，如下所示：

> 数据集处理阶段，我们为模型选择正确的数据集。
>
> 数据集再处理阶段，在应用特征缩放或归一化之前对数据进行整合和过滤，然后进行二进制或多分类标记。
>
> 下一阶段是ML算法分析，使用选定的算法之一来训练和测试数据。
>
> 在最后阶段，我们应用一些性能指标来测量和评估所使用的算法的性能。

6、数据集设置

> 我们首先研究了最广泛的IDS数据集，称为KDD CUP 99 [26]，其中包括20种攻击场景的500多万个数据点。后来，Tavallaee等人[27]通过删除冗余记录来增强KDD CUP 99，即NSL-KDD 2009。我们认为这个数据集已经过时，因为网络流量是在1998年生成的，不能反映新的网络结构和攻击动态。
>
> **CICIDS2017 [29]和UNSWNB 15 [30]被用来评估我们当前论文中的12种ML算法。这是因为这些数据集包含了广泛的当前攻击场景，符合现实世界的标准。**

7、性能指标

使用七个评估矩阵来衡量所选ML算法的性能，即**准确度**，**精确度**，**真阳性率**（TPR），也称为召回率，**假阳性率**（FPR），**F1分数**，**受试者操作特征（ROC）曲线**和**混淆矩阵**。准确率、精确率、召回率、F1评分和AUC越高，机器学习模型越好。反之，FPR越低，模型越好

![image-20240905194109674](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905194109674.png)

该阶段应用了12种ML算法，其中6种使用经典ML算法，其余使用深度学习算法。这些内容已在前面的章节中介绍过。将三个数据集分开，以便将70%的数据用作训练数据集，用于训练ML模型。其余30%的数据形成测试数据集，用于评价训练的ML模型[32]。在我们的案例中，**将数据集分割为70：30的比率证明了比其他测试比率更好的结果**。使用两种分类评价数据集。第一种是二元分类，其中标签只有两种结果：正常或攻击;第二种是多类分类标签，其中的值范围可以根据攻击类型进行分配。

## 十、《A critical overview of outlier detection methods》

本文报道了异常值检测方法的研究现状。**我们简要地讨论了噪声和离群值之间的区别**。在此基础上，对离群点检测技术及其对数据分析的影响进行了概述。我们根据每种技术所采用的基本方法将现有方法分为不同的类别。此外，对于每个类别，我们都提供了对每种方法的优缺点的讨论。

### 1、噪声和离群值区分

1、在数据分析中，当谈论噪声数据时，我们谈论的是我们没有从中受益的数据，即，只携带无意义信息的数据。由于机器无法正确理解或解释噪声数据，因此会出现各种问题，因此数据分析的结果将不够精确，并且将使用不必要的存储空间。噪声数据可归因于各种原因：

> 数据类型不正确（为数值属性输入了字符串类型）
>
> 错误的数据值（“age "属性为999而不是99）
>
> 缺失值（属性的未记录数据）

例如，威斯康星州乳腺癌（原始）数据集1包含缺失值，即未记录的属性。噪声数据阻碍数据分析获得令人满意的结果，因此最好将其删除

2、离群值与噪声数据有很大的不同，而噪声是无用的，必须被去除，**离群值可以提供无用和有趣的（例外）信息**。换句话说，**离群值是极端偏离数据集的定义良好的规范或预期行为的给定概念的数据实例**。在某些情况下，我们宁愿删除它们，因为它们会误导我们的分析，而在其他情况下，它们可能非常有用，保留它们将是最好的解决方案。数据中存在异常值可归因于：

> 测量或记录错误
>
> 异常但真实的值
>
> 误报
>
> 抽样错误

### 2、离群值类型

在本节中，定义了不同类型的离群值。**离群值可分为三种类型：全局离群值、上下文离群值和集体离群值[2]**。

> **全局离群值**。当异常值与数据集的明确定义的标准或给定的预期行为概念极度偏离时，则认为该异常值是全局异常值，也称为点异常值（见图2）。
>
> **上下文异常值**。当一个数据对象在特定的上下文中（不是在每个上下文中）非常不同时，它被称为上下文离群值。例如，在突尼斯，30摄氏度的温度在夏天是正常的，但在冬天，这是一个异常值，这一切都取决于上下文。每个数据对象可以由两个属性定义：上下文属性（温度示例中的日期和位置）行为属性（温度示例中的温度，湿度和压力）
>
> **集体离群值**。当一组数据对象与数据集的良好定义的规范或预期行为的给定概念相距甚远时，该集合被称为集体离群值。例如，对于每天处理数千个订单的公司来说，单个延迟订单是正常情况，但是100个延迟订单可能看起来可疑，并且这些订单的集合形成异常值。

### 3、离群值检测算法

离群值检测方法可以根据不同的标准进行分类，在我们的工作中，它们将根据它们使用的不同技术进行分组。因此，我们可以将其分为四种主要的方法：**基于统计的，基于距离的，基于聚类的和基于密度的**

#### 3.1 基于统计的检测算法

提出了**参数和非参数方法**，这些方法需要两个阶段来完成离群点检测过程，即**训练阶段和测试阶段**。在训练阶段，数据集中的所有数据实例都基于给定的统计模型进行训练。然而，测试阶段涉及检测数据实例是否适合模型，即离群值检测。**参数方法在我们已经知道数据分布的情况下使用**，在参数方法中，我们可以提到**基于高斯和基于回归的方法**。

##### 3.1.1 基于高斯的方法

**箱形图[3]和均值-方差**是基于高斯的方法中最常用的技术。

**乔马湖，加-地等人[4]提出了一种使用箱形图识别单变量和多变量离群值的方法**。

##### 3.1.2 基于回归的方法

对于未知的数据分布，回归用于构建模型。回归模型在训练阶段构建，而测试阶段涉及针对回归模型测试数据对象。**数据在简单回归中是双变量的，并且可以可视化为散点图**，在这种情况下，可以通过目视检查轻松识别离群值。当数据变成多变量时，异常值检测就变得非常困难，因此引入了几种回归方法。

为了处理大数据集，Rumseeuw和Driessen [5]提出了一种新的回归方法，称为**LTS回归算法**。**FAST-LTS的开发就是为了弥补这一缺陷**。FAST-LTS方法使用不同的节省时间的方法：集中步骤（C-步骤），选择性迭代和嵌套扩展。

##### 3.1.3 无参数的方法

**直方图和基于核的方法**是最著名的非参数离群点检测方法。

###### 3.1.3.1 基于直方图的方法

直方图是一种简单的方法，但也是最常用的可视化统计数据的方法。**直方图的一个特点是它显示连续数据的频率，但它不能显示分类数据**。在直方图中，每个数据类将落在不同的范围内。因此，要决定是否使用直方图，我们必须问自己，“我们的数据是连续的还是可以分组到范围内？”**为了构建直方图，数据必须分成间隔，也称为箱**，必须正确选择间隔（不要选择小桶，也不要太大）

Markus G.和Andreas D.[7]叫做**HBOS算法**。在他们提出的算法中，计算每个数据实例的离群值得分。真实的数据集由具有非常不同的分布的特征组成，因此它们使用两种类型的直方图。**为每个单个元素构建单变量直方图，然而对于数值元素，可以构建两种类型的直方图：静态箱宽度直方图和动态箱宽度直方图**。

> **静态箱宽度直方图**。这种类型的直方图构建具有**相似宽度的k个箱**。在这种情况下，为了估计密度，对落入该箱中的对象的频率进行计数。
>
> **动态箱宽度直方图**。为了确定动态箱宽度值，必须首先排序，并且**每个箱包含N/k个连续值**。设N为数据对象的总数，k为bin的数量。

###### 3.1.3.2 基于核的方法

我们将描述由**Longin J.L.等[8]提出的方法**。他们的方法可以被认为是一种统计检测方法，也可以被认为是一种基于密度的检测方法，因为它使用非参数核来估计数据实例的密度（也称为地面真值密度）

##### 3.1.4 统计方法的局限性

**箱形图方法中的离群值去除并未对所有数据集显示出良好的性能**，这使得该方法依赖于数据集。**基于回归的方法**减少了现有LTS方法的计算时间，即使在大数据集，但它**遭受的灾难的维数**。**在直方图的情况下，值得注意的是，它对箱大小非常敏感**，太小的箱大小可能导致假阳性，太大的箱大小将产生假阴性。**基于核的方法显示用于高维目的的高计算成本**。然而，**非参数方法对数据流表现出可接受的性能**，因为它们可以很容易地处理连续到达的数据。

简而言之，**统计检测方法**在给出概率分布模型时显示出有效的实验结果，但**在应用于大数据集时具有高计算成本和维数灾难**。因此，这些方法不能应用于大型和高维数据集。这些技术的**另一个缺点是它们不适用于分布未知的数据集**。

#### 3.2 基于距离的检测算法

通过基于各种距离相关度量计算所有数据对象之间的距离来检测离群值。**之后，没有足够邻居的对象最有可能是离群值。最近邻方法是最常用的方法。**

##### 3.2.1 解集方法

这种方法是**由Fabrizio A.等[9]提出**。其核心思想是利用一个求解集来求解异常点预测问题OPP和异常点检测问题ODP。**为了计算ODP求解集，已经开发了三种算法，SolvingSet算法，RobustSolvingSet算法和MinimalRobustSolvingSet算法**。该方法的主要优点是它显示出低计算时间，因为仅计算朝向求解集合对象的邻域距离而不是整个数据集。

##### 3.2.2 ABOD方法

数据维度的增加导致了所谓的“维度诅咒”，这意味着比较距离变得毫无意义。因此，许多基于距离的方法变得不合适。**[10]提出了一种称为基于角度的离群值检测ABOD方法的新方法，该方法仍然使用距离，但也考虑所有数据对象的角度方差**。**实验结果表明，该方法能够有效地对离群点进行排序，并获得较高的查准率和查全率**。

##### 3.2.3 LDOF方法

**另一种基于距离的算法LDOF由[11]引入**。该算法在数据实例上计算LDOF因子，该因子指示数据实例偏离其邻域的程度。获得高分的数据实例更可能被视为离群值。

##### 3.2.4 基于距离的检测方法的局限性

**基于距离的方法似乎是有效的，因为它们独立于数据分布，易于实现**。然而，它们**在高维数据集中仍然表现不佳**。**ABOD是唯一讨论过的克服这个问题的技术**。因此，由于难以计算流中数据的距离，它们**无法处理数据流**。另一个缺点在于**这些方法在多变量数据集中使用时计算昂贵的事实**。当数据分布复杂时，求解集合法和LDOF可能面临困难。**ABOD不能适当地识别低密度周围区域中的离群值**。

#### 3.3 基于密度的检测算法

在基于密度的技术中，测量密度以检测离群值，当离群值的局部密度不同于其邻域时，检测到离群值。我们可以提到**LOF和INFLO作为基于这种技术的众所周知的方法**。

##### 3.3.1 LOF方法

**[12]当他们提出LOF局部离群因子时，反对将离群值视为二元属性的想法**。LOF的目标是为多维数据集中的每个数据对象分配一个离群值的程度（见图10）。LOF通过识别比其他离群值检测方法更有意义的局部离群值来证明其重要性和质量。

##### 3.3.2 INFLO方法

LOF方法需要良好分离的聚类以便良好地执行，否则它会遭受错误的离群值得分。[13]提出了另一种基于对称邻域关系的离群点检测方法。换句话说，在估计其密度时，邻居和反向邻居都被考虑。数据集中的每个数据对象都会影响INFLO（INFLuenced Outlierness）程度。**高INFLO度表示对象可能是有希望的异常候选，而低分数（INFLO> 1）意味着对象属于聚类的核心**。

##### 3.3.3 基于密度检测方法的局限性

通常，基于密度的检测方法比基于距离的检测方法表现出更好的性能。然而，**当它们计算物体及其邻居的局部密度时，它们变得非常昂贵**。因此，它们**不适合大型数据集，并且它们不能有效地处理数据流**。特别是**低密度地区LOF实验效果不佳。INFLO对参数k很敏感**，必须适当选择。

#### 3.4 基于聚类的检测算法

基于聚类的技术取决于寻找不同聚类的过程，其中不适合任何聚类的对象被视为离群值。

##### 3.4.1 DBSCAN算法

DBSCAN算法的主要目标是有效地对分散的数据进行聚类，即它可以**清楚地分离任意形式的簇**。因此，DBSCAN可以**识别低密度区域中的噪声**，即，噪声数据的密度必须低于簇的密度。**DBSCAN的有效性依赖于Martin E.等人，直接密度可达性概念（见定义1）、密度可达性概念（见定义2）以及最后密度连通性概念（见定义3）**。

##### 3.4.2 ODC算法

**[17]提出了一种新的无监督离群点检测和聚类改进的方法，通过发展ODC算法**。该算法通过使用众所周知的K均值的修改版本来检测离群值（参见算法1）。**将该算法与FindCBLOF和ORC离群点检测方法进行了比较，以确认其质量。ODC在离群点检测和聚类精度方面表现出更好的性能。**

##### 3.4.3 OF算法

**[20]提出了一种基于离群点比内点（正常对象）更难识别的思想的异常检测精确排序方法**。因此，他们的方法是基于计算每个数据实例的可观测性因子OF，即数据集中的不相关程度。该方法对数据集的一部分进行迭代检测，不符合检测部分的对象在相应的迭代中被视为离群点。重复该过程，并且该方法影响每个对象的OF分数。

##### 3.4.4 CLOPD算法

**[21]提出了基于聚类的离群点检测（CLOPD）算法**，该算法也是为了检测医学数据中的异常。他们从预处理原始数据开始，使用z分数归一化方法（参见等式2）对数据集中的所有值进行归一化和清理。（10））。对于离群值检测，他们使用了基于距离的方法，欧几里得距离度量（见等式10）。(11))这有助于他们找到一个点的k个最近邻。离群值是前M个观测值，它们与第k个最近邻的距离最大

##### 3.4.5 ROCF算法

[22]**在现有的离群点检测算法中，几乎都存在top-n参数问题**，这意味着算法需要一个参数n来指定离群点的个数。他们开发了**ROCF算法，在算法6中描述，它不需要这个参数**。所介绍的方法是基于这样的想法，即比正常聚类小的聚类被认为是离群值。因此，**ROCF使用互邻图（MUNG）来划分数据集，然后计算RFOC分数以构建决策图。决策图不仅帮助ROCF检测离群值，还帮助ROCF检测离群值集群，具有高ROCF分数的那些（参见定义1）是离群值**。

##### 3.4.6 基于聚类检测算法的局限性

DBSCAN、ODC、OF、CLOPD和RFOC的实验结果证明了这些方法检测离群值的有效性。**DBSCAN有三个主要缺点，它不能处理高维数据，也不能处理密度变化的数据**。**DBSCAN的输入参数必须仔细选择**，这使得它的参数设置敏感。虽然**ODC明显提高了聚类的准确性，但在运行时间和整体准确性方面，它劣于其他技术**。**CLOPD显示出更少的计算时间和低错误率。将RFOC与基于密度的LOF和基于聚类的CBOF进行了比较，获得了最高的查全率和查准率**。通常，**基于聚类的检测方法不需要关于数据分布的任何先验知识，并且可以适合于增量方法或换句话说流数据**。

然而，**基于聚类的技术需要太多的参数，因此这些参数很难被适当地选择**。**RFOC对此进行了研究，只需要k参数来指示邻居的数量**。除了ODC之外，CLOPD和RFOC使用扩展版本的K-means算法，该算法本身对噪声数据和离群值敏感，而其他聚类算法，例如DBSCAN，可能会显示出更好的性能。

#### 3.5 总结

**基于统计的方法对于给定的分布模型可能是有效的，但当该分布未知时，它们不能应用。基于距离的方法克服了这个缺点，并且不依赖于数据分布，但是它们在多变量和高维数据中可能非常昂贵。基于密度的方法更有效，但它们仍然不适合大型数据集和数据流。此外，基于聚类的方法虽然可以处理数据流，但仍然需要太多的参数。**虽然在孤立点检测领域已经有了很多研究，但是每种方法都存在一些不足。可以提出新的离群值检测方法或改进现有方法。

## 十一、《A comprehensive survey of anomaly detection techniques for high dimensional big data》

### 1、引言

1、高维度给异常检测带来了困难，因为当属性或特征的数量增加时，需要准确概括的数据量也会增加，导致数据稀疏，其中数据点更加分散和孤立。**这种数据稀疏是由于不必要的变量，或多个不相关属性的高噪声水平，隐藏了真正的异常。这个问题被广泛认为是“维数灾难”[6，7]**。这是许多解决高维问题的异常检测技术的一个障碍，这些技术**无法保持传统方法的有效性，例如基于距离、基于密度和基于聚类的技术[8]**。

2、本调查旨在通过使用顶点的三角形表示来识别独特的挑战来记录高维大数据中异常检测的状态：**问题（大维度），技术/算法（异常检测）和工具（大数据应用程序/框架）**。

3、本文**重点介绍了与异常检测有关的技术**，以及**涵盖其他密切相关的机器学习领域，如模式识别，离群点检测，垃圾邮件检测，可疑检测，欺诈检测，深度学习和新奇识别**。

### 2、相关工作

1、A**grawal和Agrawal [9]提供了各种异常检测技术的综述，目的是对各种异常检测方法进行基本了解**。**Albertola等人[11]介绍了用于各种应用的几种异常检测技术的调查。Hodge和Austin [7]通过比较技术的优点和缺点，对离群值检测技术进行了调查**。Patcha和Park [12]通过识别开放的问题和挑战，对异常检测系统和混合入侵检测系统进行了全面的调查。Sorzano等人[14]将降维技术沿着基础数学见解进行了分类。也可以观察到各种其他调查，例如Gama等人[15]，Gupta等人[16]，Heydari等人[17]，Jindal和Liu [18]，Pathasarathy [19]，Phua等人[20]，Tamboli等人[21]和Spirin等人[22]，这些调查进一步突出了异常检测或高维数据中的问题。

![image-20240906153027280](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906153027280.png)

2、有限的工作将异常检测和高维问题联系在一起。**Zimek等人。[23]详细介绍了高维数值数据中异常检测的专用算法;他们还强调了维数灾难的重要方面。Parsons等人。[24]对高维数据的各种子空间聚类算法进行了调查，并讨论了可以使用这些算法的一些潜在应用**。目前，**还没有一项调查直接强调了大数据中的异常检测和高维性问题**。在本次调查中，我们从大数据的角度对这两个问题进行了综合概述。

### 3、高维问题

高维度是指在可用于分析的数据中具有大量独立变量、组件、特征或属性的数据集[41]。**如果一个数据集有n个样本和m个维度（或特征），那么这个数据可以被称为m维数据。一般来说，当维数m导致“维数灾难”的影响时，数据集可以被称为高维数据集。**高维数据集的主要来源之一是具有巨大事务和相关数据库的组织。

### 4、高维问题的可视化

1、多维数据集的可视化具有挑战性，许多研究工作都集中在解决日益增加的维度[45]。**散点图矩阵是一种简单的技术，它采用成对散点图作为矩阵元素来表示多维数据集;然而，重要细节的丢失将这种技术限制在双变量投影上**。**平行坐标图（PCP）[46]被提出作为克服散点图的两变量限制的多变量可视化技术;它通过将多维空间的数据点映射到二维平面来实现这一点，通过将特征放置为以均匀间距平行的垂直轴[47，48]**。

2、将大量输入特征转换为较小的目标特征集的简化是解决该问题的常用方法。**主成分分析（PCA）[50]和多维缩放（MDS）[51]等技术基于降维，旨在在目标低维映射中保留尽可能多的重要信息**。Fastmap算法通过计算相异度将实例空间投影到最大可变性的方向上，明显快于MDS [53]。**已经提出了各种其他方法，例如ISOMAP，Landmarks MDS和Pivot MDS [54，55]，它们可以在线性时间内计算观测数量的投影**。

在其他情况下，**维数非常高，成对观测之间的距离看起来相似，因此，准确地保持这样的距离是无效的。相反，在投影中保留邻域在推理高维数据中的模式（异常）方面是有利和有效的[52]。****在这种情况下使用的最有效的技术是t-随机邻居嵌入（t-SNE）**，它被广泛应用于许多领域，如模式识别，机器学习和数据挖掘。**t-SNE旨在捕获高维数据中的大部分局部结构，同时详细描述全局结构，例如可用聚类的数量[56]**。然而，当降维的投影失败时，不可能详细地可视化数据，只能从数学上理解[57]。例如，二维空间中的线性分隔符是一条线。

### 5、维度灾难

**1、维度灾难影响异常检测技术，因为相对于增加的维度的异常性质的水平可以被不必要的属性模糊甚至隐藏[27]**。由于离群值被定义为稀疏区域中的数据实例，因此在高维空间的几乎同样稀疏的位置中观察到不充分的区分区域[28]。**维数的增加使得数据点分散和孤立，并且使得难以找到数据集的全局最优解**。添加到数据集的维度越多，它就变得越复杂，因为每个添加的维度都会带来大量的误报[42]。这些事件的本质是，**每当维度增加时，空间的体积就成比例地增加，使得所有其他数据点变得稀疏。这种稀疏性对于任何需要统计值的技术都是具有挑战性的**。**随着维数的增加，统计方法（如距离测量）变得不那么有用，因为由于维数灾难，点彼此几乎等距**。

2、**高维数据需要大量的计算内存，带来了巨大的计算负担**。对于高维数据，识别有用的见解或模式变得复杂而具有挑战性。**处理高维问题最简单的方法是最小化特征，并且可以通过研究数据集的内在或嵌入维数来更好地理解。理解内在维度和嵌入维度之间的微妙差异是至关重要的**。内在维度是覆盖数据完整表示的最小特征种类;嵌入维度是整个数据空间的特征或列的数量的表示。此外，了解统计模型如何解决高维问题也很重要

### 6、解决高维问题的传统模型

**许多算法建立在接近度的概念上**，以发现基于数据点之间关系的异常。然而，这样的算法遭受巨大的计算增长在高维空间，因此，未能保持其有效性。这是因为**算法的计算复杂度与数据m的增加的维度和样本的数量n成正比**。数据分布模型以完全不同的方式解释稀疏性;它意味着每个数据实例与其他数据实例等距，这使得很难区分近距离和远距离的数据实例对。维数的增加分散了数据实例的分布，使它们的密度降低。**Aggarwal [28]提出，几乎任何主要基于邻近概念的技术都会在高维空间中质量下降，因此需要以更有意义的方式重新定义**。

#### 6.1 基于距离的技术

**1、Angiulli和Pizzuti [30]提出了一种基于距离的异常检测技术，称为“HilOut”，用于检测大型和高维数据集的前n个离群值**。HilOut使用空间填充曲线的概念来线性化数据集;它通过检查第一阶段之后剩余的候选离群值来计算精确解之前提供近似解。Angiulli和Pizzuti提出了他们提出的HilOut算法的内存和基于磁盘的版本，以及对该方法的深入分析，**该方法扩展性良好**。

2、虽然欧几里得距离适用于低维数据集，但它在高维数据中并不有效[60]。为了解决这个问题，**Koufakou和Georgiopoulos [61]提出了一种异常检测策略，其中通过非常接近线性的分布式版本来实现加速**。他们称这种方法为“快速分布式”，旨在用于处理稀疏高维数据的混合属性数据集。他们的方法考虑了数据集的稀疏性，具有极高的可扩展性，因为它在数据集中有几个点和许多属性。

#### 6.2 基于聚类的技术

**[63]引入了一种共享最近邻聚类算法，用于识别形状、大小和密度波动的聚类，以及沿着的异常**。他们的方法，处理多维性和不断变化的密度，自动计算集群的数量。作者确定了一些优化，使他们的技术能够有效地处理大型数据集。

#### 6.3 基于密度的技术

**[62]介绍了一种用于估计高维数据中的度量的密度估计器，并将其应用于识别数据分布变化的问题**。他们近似了数据μ的概率，旨在通过利用μ位于嵌入高维空间的低维子集周围的假设来绕过维数灾难。[62]证明了各种模型和目标概率测度的强有限样本性能边界，这些模型和目标概率测度仅基于数据的内在复杂性。实现这种构造的技术是快速的和可并行的，并且在识别异常值时显示出高精度。

#### 6.4 基于分类的技术

**维数的增加会导致错误分类。变量之间的关系通常会建立一个更好地理解数据的模型**;然而，太多的维度会使解释模型复杂化[64]。一些机器学习技术是基于这样的假设，**即可以通过将数据投影到较低维空间上来实现维度缩减，在该较低维投影之后，学习可能更容易[65，66]**。基于降维策略的技术将数据投影到较低维度的子空间[8]或PCA [7，67，68]上，如在以下部分中所讨论的。

![image-20240906172326849](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906172326849.png)

#### 6.5 解决高维问题的策略

解决高维问题的一种方法是降低维度，将整个数据集投影到低维空间中，通过将维度组合成属性的线性组合[69]或选择称为子空间的局部相关和低维属性的子集。**如上所述，已经提出了许多降维方法，例如PCA，MDS，Karhunen-Loeve变换，局部线性嵌入，拉普拉斯特征映射和扩散映射，以实现降维[51，70-74]**。在许多应用领域中，数据表示由相互依赖的维度组成，并且可以注意到相关性和冗余性。**这些数据表示的内在维度小于可用的相关维度。已经提出了许多技术来测量内在维度[75-80]**。

##### 6.5.1 主成分分析

1、PCA可以通过估计数据集特征的相关结构来用于任何数据集。它有三个主要目标：（1）投影数据集的最重要维度，（2）联合所选维度，从而减小数据集的大小，以及（3）通过分析观测和关联维度的结构来简化数据集。

2、**Wang等人。[86]提出了一种PCA以及可分离压缩感知**，以识别不同的矩阵。**压缩感知（或压缩采样[CSG]）理论由Candes和Wakin [87]提出**，该理论使用随机测量矩阵将高维信号转换为低维信号，直到信号可压缩，之后从低维信号的数据重构原始信号。在Wang等人[86]的模型中，与压缩矩阵相比，未压缩矩阵中的异常更明显。因此，他们的模型可以在体积异常检测中获得同等的性能，因为它使用原始未压缩数据并显着最小化计算成本。**使用基于PCA的降维方法的主要缺点是它们可能导致显著的信息损失，PCA识别属性之间的隐藏线性相关性[73]。如果数据集的属性是非线性的或不相关的，PCA可能会导致复杂的，并且可能无法解释的假阳性**。

##### 6.5.2 子空间方法

1、子空间方法是特征选择的一种扩展，旨在识别局部相关子空间，而不是整个数据空间。**子空间是数据集维度的子集，其使用的维度空间小于完整的维度空间**。Aggarwal [89]得出结论，通过评估数据的性质，建议特定于特定子空间的更有意义的聚类是可行的。这是因为**异常只能在数据的低维子空间或具有缺失属性的数据集中识别[8]**。每一个子空间都有自己的模式。

2、**基于子空间方法的异常检测技术是复杂的，它们假设异常是罕见的，并且只能在维度的某些子集（局部相关子集）中找到。挑战在于识别相关的子空间，因为可能的子空间的数量与数据维数的增加成正比。同时找到相关的子空间和低维空间。同时发现起着至关重要的作用，因为不同的维度子集与不同的异常相关。多个子空间的发现是重要的，因为选择单个或仅几个相关子空间可能导致不可预测的结果[28]。因此，子空间异常检测是一个以集合为中心的问题[89]。**

3、**Lazervic和Kumar [92]提出了一种模型，该模型使用称为“特征装袋”的评分系统来检测异常**，该评分系统随机选择子空间。然而，由于随机子空间选择，**这导致不相关维度的增加。为了解决这个问题，Kriegel等人。[23]采用了一种技术来选择信息或相关维度**。Müller等人。[93]提出了一种名为**“OUTERS”的子空间方法**，这是一种通过引入一种新的评分算法来对异质高维数据中的异常进行排名的方法，该算法使用子空间聚类分析来检测任何维度的异常。Zhang等人。**[94]提出了一种基于角度的子空间离群点检测方法**，该方法选择子空间的有意义特征并在所选子空间投影中执行异常检测，以保持在高维数据集中检测异常的准确性。它们还包括子空间检测方法，并说明了适合于分析的相关子空间选择的步骤。**Thudumu等人。[41]提出了一种检测离群值的方法，通过使用Pearson相关系数（PCC）和PCA将高维空间分叉为局部相关和低维子空间**。他们导出了可能隐藏异常的候选子空间，并开发了一种自适应聚类方法来过滤异常[5]。**Koufakou和Georgiopoulos [61]提出的另一种算法称为混合属性数据集的离群值检测（ODMAD）**，它首先基于其分类属性检测异常，然后通过利用基于这些分类属性的子集信息来关注连续空间中的数据子集。**他们的结果表明，分布式版本的ODMAD的速度接近线性加速与计算中使用的节点数量**。**混合属性由Ye等人提出。[95]**，他们提出了一种离群点检测算法，通过计算异常子空间结合信息熵来检测高维混合属性数据集中的异常。他们使用自底向上的方法来检测有趣的异常子空间，并计算高维混合属性数据集中异常的离群度。

#### 6.6 高维大数据异常检测带来的独特挑战

**1、解决高维问题的最常见策略是定位最重要的维度（即，特征子集），称为变量选择方法，或者将结合维度组合成一组较小的新变量，称为降维方法[73]。****许多异常检测技术假设数据集只有少数特征**，并且大多数都旨在识别低维数据中的异常。当数据量增加时，解决高维问题的技术由于一系列因素而面临异常检测的挑战，如表3所示。

![image-20240906174436695](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906174436695.png)

异常被掩盖在高维空间中，并隐藏在多个高对比度的子空间投影。子空间的选择是至关重要和复杂的，特别是当数据增加。**Fabien和Kelloer [100]提出通过计算在真实的数据集上评估的高对比度投影的分数来提高传统异常排名的质量，从而估计子空间的对比度**。影响高维空间中距离性质的因素，阻碍异常检测过程，是距离集中：所有数据点基本上等距[101]。**Tomasev等人。[102]通过评估频繁出现的点（称为枢纽）来解决高维数据中的聚类问题**。他们开发了一种算法，证明了枢纽是在高维数据集群中定义点中心性的最佳方式。**Radovanović等人[103]使用数据点提供了有用的见解，称为反枢纽**;虽然它们很少出现，但它们清楚地区分了异常值之间的联系。

2、当数据量很大时，由于有限的计算能力和相关因素，异常检测技术可能会出现问题。为了克服这个问题，研究人员提出了使用**并行和分布式计算模型**。**[106]提出了一种称为D-cube的技术，这是一种基于磁盘的检测技术**，用于在大规模多方面数据中发现欺诈性锁步行为，并以分布式方式在多台机器上运行。**Hung和Cheung [107]基于Knox和Ng [108]提出的NL算法**，介绍了嵌套循环（NL）算法的高效并行版本，可降低计算和磁盘I/O成本。[109]提出了一种基于距离的异常构造模型，该模型建立在一个点与其相邻点的距离上，并且还开发了一种有效的基于分区的算法来提取巨大数据集中的异常模式。**Angiulli和Fassetti [110]提出了一种基于距离的异常检测方法**，称为“海豚”（用于检测OutLiers PusHing数据到INdex中），该方法适用于大型数据集中的磁盘驻留数据集。

一些研究旨在通过使用集成策略来提高异常检测技术的效率。**Arning等人。[111]提出了一种使用相异度函数来捕获数据点相似率的线性算法。More和Hall [112]提出了一种算法来对大规模数据集进行分组，而无需在单个实例中对整个数据进行聚类。Erfani等人[6]介绍了一种用于高维大规模未标记数据集的无监督技术，以检测深度信念网络（DBN）和一类支持向量机（SVM）的组合异常**。单类支持向量机（1 SVM）用于通过无监督学习检测离群值，旨在对数据的潜在分布进行建模，同时不考虑训练记录中的无关属性或离群值。从训练样本中得到的特征被作为输入来训练1 SVM。相反，DBN是一种多类半监督方法和降维工具。它使用多层生成模型（非线性流形），每次从未标记的数据中学习一层特征。**[113]提出了一个有趣的异常检测大纲，通过解决大数据量，多样性，准确性和速度的4V来识别和解释取证系统网络中的异常事件**。

3、大多数异常检测策略都假设存在由未知的固定概率分布生成的有限数据量，可以使用批处理模式算法在各个步骤中存储和分析[119]。**流数据的异常检测是一个非常复杂的过程，因为数据量是无限的，不能无限期地存储**[35]。

### 7、高维大数据中的工具

1、MapReduce是处理大数据存储和处理的第一个分布式编程范式之一。尽管如此，许多分布式计算框架，如**Apache Hadoop [134]，Apache Storm [135]，Apache Spark [136]，Apache Flink [137]和MXNet [138]**都是为了满足不断增长的大数据需求而开发的。**这些框架中的大多数都有内部机器学习（ML）库，Apache Spark拥有比其他任何框架都强大的ML库[139]**。

2、**Koufakou等人[140]提出了一种快速并行异常检测方法**，该方法依赖于属性值频率方法，这是一种可扩展的、高速异常值检测过程，适用于分类数据，易于并行化，旨在识别大型数据挖掘问题中的异常。他们之所以使用MapReduce，是因为它提供了负载平衡和容错功能，并且在节点数量方面具有极强的可扩展性。**Leung和Jiang [36]报告了一种解决方案，该方案利用MapReduce挖掘不确定的大数据**，以获取满足用户指定的反单调限制的频繁模式。**Jiang等人[141]报告了一种基于树的技术BigSAM**，该技术允许操作员通过使用约束根据他们的兴趣来表达要挖掘的模式，因为MapReduce允许挖掘不确定的大数据以获得常见模式。**He等人[32]提出了一种基于KD树的异常识别技术的并行应用**，用于管理大型数据集，实现为一种基于KD树的并行异常检测算法。实验结果表明，新算法具有良好的可扩展性和高效性，能够在商用硬件上高效地处理大数据集。

3、**Apache Spark（Spark）[136]是另一个基于MapReduce的分布式框架**，用于在分布式系统上处理大量数据，然而，**它有一个称为内存计算的功能**[159，160]。**与MapReduce两阶段范式相比，Spark的内存计算模型旨在提高处理批量和实时工作负载的速度和可扩展性**。**Terzi等人[143]提出了一种使用Apache Spark作为分布式框架的无监督方法**。他们报告称，公共大网络数据中异常识别的准确率为96%。

4、对于实时处理，Apache Storm [135]是由Twitter开发的一个开源分布式框架，具有可扩展性，容错性和弹性等保证功能。**Zhang等人[144]开发了一个基于Apache Storm的框架**，用于支持使用两个数据集的大规模卷积神经网络（CNN）的分布式学习，适用于实时流处理。他们的实验表明，更合理的并行性可以显着提高他们的框架的执行速度。**Veen等人。[161]专注于使用基于Apache Storm的公共云虚拟机的流媒体分析平台的弹性**。他们选择该框架是因为添加和删除处理节点的可能性更容易。

5、**MXNet是一个开源、可扩展、内存高效、高性能的模块化深度学习框架，为C++、Python、Matlab和R等编程语言提供了一系列应用程序编程接口（API）**。**它运行在异构系统上，从移动的设备到分布式GPU集群[162]**。**Abeyrathna等人。[145]提出了一种基于异常提议的方法**，可以使用MXNet框架建立实时火灾检测的有效架构。**Apache Flink [137]提出了另一个开源框架**，结合了其他分布式范例（如MapReduce [163，164]）的可扩展性和编程灵活性。**Toliopoulos等人。[146]进行了基于距离的离群值检测工作**，并使用三个真实世界和一个合成数据集在大规模并行设置中进行了检查。**他们考虑了三个主要的并行流媒体平台，如Apache Storm，Apache Spark和Apache Flink**。**García-Gil等人[139]对两个框架Apache Spark和Apache Flink的可扩展性进行了比较研究**。他们的实验结果表明，Spark具有比Flink更好的性能和整体运行时间。

6、**Angiulli等人。[33]提出了一种分布式框架**，用于基于对异常检测解析集（数据集的一个小子集）的感知，在海量数据集中识别基于距离的异常**。后来，Angiulli等人[152]提出了一套用于GPU的并行和分布式算法，从而产生了两种基于距离的异常检测算法：BruteForce和SolvingSet**。它们之间的区别在于它们利用GPU架构和内存层次结构的方式，并提供针对CPU版本的改进，包括可扩展性和并行性利用。**松本等人[153]发表了一种使用密度采样对不确定数据进行异常检测的并行算法，通过OpenCL框架在图形处理单元（GPU）和多核中央处理单元（CPU）上建立了实现**。

7、**Lozano和Acufia [154]设计了两种并行算法来识别基于距离的异常**，使用随机化和修剪规则来识别基于密度的局部异常。**他们还构建了Bay和Local Outlier Factor（LOF）程序的并行版本**，这些程序在异常检测和运行时间方面表现出良好的性能。**Bai等人。[34]专注于大型数据的分布式基于密度的异常检测问题**。他们提出了一种基于网格的分区算法，作为一种数据预处理技术，在将数据集分发到分布式环境中的数据节点之前，将数据集划分为网格。**提出了一种分布式LOF计算方法，利用少量网络通信并行发现基于密度的离群点**。**Reilly等人。[155]提出了一种基于PCA的离群值识别方法，该方法在分布式环境中工作，在提取包含离群值的训练集的主成分时表现出鲁棒性**。**Gunter等人[147]探索了在大型分布式系统中识别异常值的各种技术**，并主张采用轻量级方法来实现真实的时间分析。没有找到单一的最佳方法;因此，他们得出结论，由于有效性的变化取决于异常的定义，因此需要各种方法的组合。

8、**Maruhashi等人。[148]提出了一种在具有数百万条边的异构网络中发现模式和异常的技术**，并根据经验证明该技术可扩展到高维数据集。**Shin等人。[149]开发了一种新的灵活框架，可以识别大规模高阶张量中的密集块**，并通过以近乎完美的准确度发现TCP转储中的网络攻击，证明他们的方法在真实的数据中是可扩展的。**Oh等人[44]提供了一种可以处理高维数据的可扩展方法**。特别是，他们还证明了他们的方法在维度方面优于许多基线方法。Hooi等人。**[150]提出了一种可扩展的基于密集子图的异常检测方法，称为FRAUDAR**，不仅可以检测真实的世界图中的各种欺诈攻击，还可以检测大数据中大量先前未检测到的行为。**Jiang等人。[151]提出了一种名为CROSSSPOT的可扩展算法**，该算法对可疑程度进行评分和排名，以在真实世界的大型多模态数据中找到密集的可疑块。

## 十二、《A Comparison of Outlier Detection Techniques for High-Dimensional Data》

### 1、评价指标

> 1、**AUC**。ROC（受试者工作特征）曲线是真阳性率与假阳性率的图表，其中真（假）阳性率表示前m个潜在离群值中离群值（内值）的比例。
>
> 2、**Precision（P）**。精度是指真实离群值的数量与离群值候选总数的比率
>
> 3、**Average precision (AP)**。Average precision不是仅对单个n值进行评估，而是指所有离群值对象的等级上的精度分数的平均值。
>
> 4、**Rank Power (RP)**。秩功率是另一种流行的测量，以评估离群值检测方法的性能。很明显，如果离群值排名算法将真正的离群值排在离群值候选列表的顶部，则该算法将被视为更有效。
>
> 5、**相关系数**。如斯皮尔曼等级相似性或Pearson相关性，也可用于评估文献中离群值检测的性能36。这种度量方法通过使用合并权重将更多的重点放在排名靠前的潜在离群值上。

### 2、数据集来源

在孤立点检测实验中，通常使用人工数据集和真实数据集来验证文献中的性能。**Wang等人37提供了一些在不同情况下具有异常值的合成数据集**。真实世界的数据集通常来自三个来源，如下所示：

> 1、**UCI机器学习库**。这些数据集中的大多数已被提议用于评估分类方法。**对于离群点检测任务，常用的策略是通过将小类中的对象作为离群点，其余的作为正常对象来预处理数据集**。
>
> 2、**ELKI数据集**。ELKI是一个积极开发和维护的“用于开发索引结构支持的KDD应用程序的环境”。最近的版本特别致力于异常值检测。**该平台不仅提供了离群点检测算法，还提供了用于离群点检测评估的多个数据集**。
>
> 3、**空间数据**。空间数据4的集合是由芝加哥大学捐赠的。**尽管最初用于空间分析，但这些空间数据（包括人口普查区域数据和邮政编码业务模式）也可用于离群点检测**。

**在分类中主要使用的数据集需要进行预处理以用于离群值检测任务**。在预处理期间，可以考虑两种情况：1、**对于语义上有意义的离群数据集，与稀有对象相关联的类被视为离群值，其余的被视为正常数据**。2、**对于其他数据集，从数据集中随机选择离群值类。特别地，对于只有两个类的数据集，具有次要对象的类通常被视为离群点**。

### 3、实验对比

在本节中，**我们在9个数据集上对10种流行的离群点检测算法进行了实验比较**。离群点检测算法包括**kNN、kNNW、ODIN、LOF、Loop、COP、SOD、FastABOD、HiCS和高斯均匀混合模型（GMM）**。数据集的详细信息见表2，**其中“N”和“O”分别指所有对象和离群值的数量**。在对数据集进行预处理时，我们采用了参考文献42中相同的处理步骤。例如，对于由7200个对象组成的Annthyroid数据，我们在实验中将类“hyper-function”和类“subnormal”作为离群值，并将类“healthy”作为内点。因此，在该数据集中有534个异常值和6666个正常

![image-20240906183347756](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183347756.png)

![image-20240906183523232](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183523232.png)

![image-20240906183537195](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183537195.png)

## 十三、《A comparative evaluation of outlier detection algorithms: Experiments and analyses》

这些异常可以被定义为与大多数观察结果偏离得足够远的观察结果，从而认为它们是由不同的生成过程产生的。当这些观测值的数量显著小于标称情况的比例（通常低于5%）时，这些观测值被称为离群值。

我们的论文扩展了以前的工作[7，33]，**使用了12个公开可用的标记数据集，其中大部分被推荐用于离群值检测[7]，此外还有3个来自旅游行业一家大公司生产环境的新工业数据集**。所选的参数和非参数算法来自各种方法，包括**概率算法，最近邻方法，神经网络，信息论和隔离方法**。在标记数据集上的性能与**ROC曲线下面积和精确度-召回率曲线进行了比较**。为了全面概述这些方法，我们还对每种方法的**训练时间，预测时间，内存使用和鲁棒性**进行了基准测试，当增加样本，特征和背景噪声的数量时。

### 1、异常检测方法

#### 1.1 概率方法

**概率算法通过推断模型参数θ来估计数据集X的概率密度函数。具有最小似然P（X|θ）的数据点被识别为离群值。**

在我们的基准测试中使用的第一种算法是**高斯混合模型（GMM）**。**在[3]中，Blei等人描述了Dirichlet过程混合模型（DPMM）**，这是一种非参数贝叶斯算法，通过监测对数边际似然的非递减下界来优化模型参数并测试收敛性。**该算法在文献[8]的KDD 99数据集上进行了入侵检测，其性能优于SVM和KNN算法**。由模型提供的聚类质心对于最终用户也是有价值的，因为它们表示平均标称数据点。

**核密度估计器（KDE）**，也称为Parzen窗口估计器，通过为每个数据点分配核函数，然后对核的局部贡献求和来近似数据集的密度函数。**Kim等人在[13]中展示了这个问题，其中作者描述了一种鲁棒核密度估计（RKDE）算法**，该算法使用M估计方法（如鲁棒损失函数）来克服普通kde的局限性。

**概率主成分分析（PPCA）[29]**是一种潜在变量模型，用于估计数据的主成分。

最近，**Quinn等人开发的最小二乘异常检测（LSA）[25]**将多类概率分类器扩展到一类问题。使用ROC曲线下面积将该方法与knn和一类SVM进行比较。

#### 1.2 基于距离的方法

**Mahalanobis距离适用于针对由单个高斯形聚类组成的多变量数据集的异常检测任务[2]**。

#### 1.3 基于邻居的方法

基于邻域的方法研究每个数据点的邻域以识别离群值。**在[4]中描述的局部离群因子（LOF）**是与该描述对应的众所周知的基于距离的方法。当应用于真实世界的离群值检测数据集时，**lof优于基于角度的离群值检测[16]和单类SVM [26]**，这使其成为该基准的良好候选者。

**基于角度的离群值检测（ABOD）[16]**使用在每个输入向量处测量的角度的半径和方差而不是距离来识别离群值。这里的动机是在高维空间中保持效率，并且对维数灾难不那么敏感。

**子空间离群值检测（SOD）[15]**算法为每个点p找到p和它的k个最近邻居之间共享的m个邻居的集合。

#### 1.4 信息论方法

**Kullback-Leibler（KL）发散度在[9]中被用作新奇检测的信息论度量**。该方法首先在训练集上训练高斯混合模型，然后通过测量估计密度与训练集上估计密度和新数据点之间的kl偏差来估计新数据点的信息含量。这在单个高斯的情况下简化为F检验。

#### 1.5 神经网络

**在[19]中，Margaret等人提出了一种基于重构的非参数神经网络，称为Grow When Required（GWR）网络**。**该方法基于Kohonen网络，也称为自组织映射（SOM）[14]**，并将输入空间中的自适应拓扑图拟合到数据集。在训练网络时，添加或删除节点和边，以便最好地拟合数据，目标是最终将节点定位在所有密集数据区域中，而边传播相邻节点的位移。

#### 1.6 基于域的方法

用于离群数据识别的其他方法依赖于将标称数据与输入空间的其余部分分离的边界的构造，从而估计标称类的域。因此，**落在定界边界之外的任何数据点都被标记为离群值**。

**单类SVM [26]是支持向量机（svm）算法在单类问题中的应用**，属于这类算法。该方法在高维空间中计算分离超平面，该分离超平面由在来自高维空间中的输入空间的点之间执行点积的核引起。

#### 1.7 隔离方法

在这项研究中，我们包括一个隔离算法，其重点是从其余的数据点分离离群值。这种方法与以前的方法不同，因为它隔离异常而不是分析正常点。**隔离森林的概念是由Liu在[17]中提出的，它使用随机森林来计算每个数据点的隔离分数**。该模型是通过对属性值执行递归随机拆分来构建的，因此生成的树能够将任何数据点与其余数据隔离开来。**作者指出，他的算法提供了线性时间复杂度，并在现实世界的数据集上证明了离群点检测性能明显优于lof**。

### 2、实验评估

#### 2.1 实验指标

我们使用**受试者工作特征（ROC）曲线**（真阳性率对假阳性率）和**精确度-召回（PR）曲线**

#### 2.2 实验数据集

**我们的评估使用15个数据集，范围从723到20，000个样本，包含6到107个特征**。在这些数据集中，**有12个在UCI [1]或OpenML [30]存储库中公开，而剩下的3个数据集是包含Amadeus公司生产数据的新型专有数据集**。

![image-20240906222707675](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906222707675.png)

#### 2.3 可扩展性数据集

我们的实验包括**每个算法在合成数据集上的训练时间，预测时间，内存使用和抗噪性**（通过精度-召回测量）。

对于这些可扩展性测试，我们生成包含固定比例背景噪声的不同大小的数据集。**数据集的范围从10个样本到1000万个样本，从2到10，000个数值特征**。我们还保持特征和样本的数量固定，同时**将背景噪声的比例从0%增加到90%**，以执行鲁棒性测量。实验重复5次，使用相同的数据集进行训练和测试。我们允许最多24小时完成训练或预测步骤，并在此时间段后停止计算。

#### 2.4 算法实现和参数

<img src="C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906223115710.png" alt="image-20240906223115710" style="zoom: 80%;" />

**本实验中使用的大多数实现都是公开可用的**。表2详细说明了所选的编程语言和初始化参数。**大多数方法具有灵活的参数，并且在没有大量调优的情况下执行得非常好**。**Python的Matlab引擎API和rpy2库允许我们从Python调用Matlab和R代码**。

#### 2.5 实验结果

对于每个数据集，**将第2节中描述的方法应用于通过蒙特卡罗交叉验证采样的5个训练和测试子集**

从平均精度来看，iforest、rkde、ppca和ocsvm表现出了出色的性能，达到了我们基准测试中最好的离群点检测结果。**iforest在多个数据集（例如kdd-sub，abalone或thyroid）上的表现优于所有其他算法，表现出良好的平均性能，这使其成为离群值检测的可靠选择。rkde排在第二位，在大多数数据集上也表现出出色的性能，特别是在应用于高维问题时**。

**单类SVM实现了良好的性能，而不需要显着的调整**。我们注意到，该算法**在包含小比例离群值的数据集上表现最好**，这似乎证实了该方法非常适合新奇检测。

关于大多数公共数据集，请注意，**异常不是稀疏背景噪音，而是来自分类数据集一部分的一个或多个类的实际样本**。因此，非参数方法产生的模型可能更加准确，因为它可以聚集密集的离群值云，即以前类别的残余。

我们确实观察到**sod在Amadeus数据集上优于其他方法，并且通常在由超过10，000个样本组成的大型数据集上表现得非常好**。这种方法是我们的基准的最佳邻居为基础的算法，但需要足够数量的功能，通过特征选择来推断合适的子空间。

**DPMM比DPGMM性能更好**。

**虽然gwr在我们的基准测试中比其他方法的性能要低，但在异常比例较低的情况下，例如pnr，共享访问和事务，该算法达到了出色的精确召回分数**，因为离群值的密度不足以吸引任何神经元

### 3、总结

我们的研究表明**，iforest是一个很好的方法，有效地识别离群值，同时显示了良好的可扩展性**，在大型数据集沿着与可接受的内存使用数据集高达一百万个样本。结果表明，该算法比rkde更适合于生产环境，因为后者的计算量和内存消耗更大。**ocsvm在这个基准中是一个很好的候选者，但是它也不适合大型数据集**。**SOD表现出良好的离群值检测性能，并以较差的可扩展性为代价有效地处理高维数据集**。**指数族表示的dpmm显示是非常耗时的，而没有实质性地提高检测离群值的高斯为基础的方法，如dpgmm**。**LOF、ABOD、GWR、KL和LSA达到最低性能，而前三种方法也显示出较差的可扩展性**。

## 十四、《On the Evaluation of Outlier Detection and One-Class Classification Methods》

离群值最常用的定义之一是Hawkins的定义[10]，其中将离群值称为“**与其他观察结果偏离如此之多的观察结果，以至于引起怀疑它是由不同的机制产生的**”。

本文通过比较单类分类方法和无监督的离群点检测方法在新奇检测问题中的应用，**提出了一种新的基于单类分类方法的离群点检测方法**。

Janssens等人。[13]**对单类分类提出的3种方法（kNN数据描述[7]，Parzen Windows [20]和SVDD [26]）和最初提出的扩展到单类分类场景的无监督离群值检测（LOF [4]和LOCI [19]）的2种方法进行了比较研究**。作者得出结论，**LOF和SVDD是表现最好的两种**，从统计学显著性检验的角度来看，它们无法区分。

### 1、实验设置

1、我们比较和评估了上一节中描述的11种算法：**ABOD，Auto-Encoder，Gaussian Density，GLOSH，kNNglobal，kNNlocal，LOCI，LOF，Linear Programming，Parzen Windows和SVDD**。对于大多数比较算法，我们使用来自http://prlab.tudelft.nl/users/david-tax/ [25]的代码，除了LOF，LOCI，kNNlocal和GLOSH。**在LOF和LOCI的情况下，修改了它们的实现，以确保待分类的新观测不会影响内点类的预计算模型**，遵循第III-C节中先前讨论的指南。由于**KNNlocal在该存储库中不可用**，因此我们使用自己的算法实现。**GLOSH是根据http://lapad-web.icmc.usp.br/上提供的HDBSCAN* 的实施情况进行调整的**。

2、我们使用来自**UCI机器学习库[17]的31个真实世界数据集作为单类分类的预处理**，并在http://prlab.tudelft.nl/ users/david-tax/上提供：**Abalone, Arrhythmia, Balance-scale, Ballbearing, Biomed, Breast, Cancer, Colon, Delft1x3, Delft2x2, Delft3x2, Delft5x1, Delft5x3, Diabetes, Ecoli, Glass, Heart, Hepatitis, Housing, Imports, Ionosphere, Iris, Liver, Satellite, Sonar, Spectf, Survival, Vehicle, Vowels, Waveform and Wine**

### 2、总结

**SVDD和kNNglobal是单类分类的首选**，而我们不推荐kNNlocal。**这与Janssens等人[13]之前的比较研究相反**，该研究不包括kNNglobal，并报告kNNlocal为最佳表现者。**此外，我们无法确认[13]中报告的LOF的最佳性能，而只能确认SVDD的最佳性能**。

## 十五、《Prediction and outlier detection in classification problems》

考虑训练数据和样本外测试数据具有不同分布时的多类分类问题，提出了一种**平衡共形优化预测集（Balanced and Conformal Optimized Prediction Sets，BCOPS）方法**.BCOPS将预测集C（x）构造为类标签的子集，可能为空。它试图优化样本外的性能，旨在包含正确的类并尽可能多地检测离群值x。如果BCOPS推断x为离群值，则不返回预测（对应于等于空集的C（x））。**该方法将监督学习算法与保形预测相结合，以最小化在样本分布外的平均误分类损失。所构造的预测集具有有限样本覆盖保证，无需分布假设**.我们还提出了一种方法来估计一个给定程序的离群值检测率。**在适当的假设下，我们证明了我们的方法的渐近一致性和最优性，并在真实的数据上说明了我们的方法**

## 十六、《Supervised outlier detection for classification and regression》

### 1、摘要

如今，存在大量提供良好结果的离群值检测算法，但它们的主要缺点是它们的**无监督性质以及必须正确设置以获得良好性能的超参数**。在这项工作中，提出了一种新的监督离群估计。这是通过将离群值检测器与下面的监督模型流水线化来完成的，以这种方式，**后者的目标监督如何最佳地选择离群值检测器中涉及的所有超参数**。在所做的实验中，**九个相关的离群检测器已结合三个回归器参与超过八个回归问题，以及与两个分类器结合涉及另外八个二进制和多类分类问题。**

### 2、引言

1、根据霍金斯[1]和[2]中引用的，**离群值可以定义为“一个观察结果与其他观察结果偏离如此之大，以至于引起怀疑它是由不同的机制产生的”**。**术语异常也出现在这种情况下，其含义或多或少相同，主要区别在于要解决的问题**[3]。

> **异常值检测（OD）的目标是从正常数据中检测和分离样本中的异常值**;换句话说，**样本被认为是“污染”的**，OD方法必须在将其用作训练样本之前对其进行“清洁”。另一方面，**异常检测[4]的目标是表征已经干净的样本并使用它来检测那些不遵循它的新模式**。原则上，**OD是一个无监督的问题**，因为通常不知道哪些模式是离群值。另一方面，**OD模型依赖于许多超参数**，其值通常对模型性能至关重要[5]。**OD算法构建评分函数来量化给定模式与样本一般结构的距离**[6]。一旦可用，这些分数允许我们对样本的模式进行排名，**并建立一个截止点作为正常模式和异常值之间的边界**[7]。**不幸的是，OD模型的无监督性质意味着缺乏用于将离群值与内点分离的基础事实，因此，很难执行最佳超参数估计。**在某些特定于应用的问题中，这种**异常模式的子集可能是已知的，然后OD问题可以变成一个监督的问题**，通常作为分类问题处理;这通常是被称为监督OD的情况

2、在OD问题可以变成一个监督问题时，**通常情况下，OD模型和分类器或回归器的最佳超参数是连续但独立地获得的**;也就是说，首先获得OD超参数，一旦训练样本被清理，然后估计分类器或回归器超参数。但是考虑到OD和监督模型必须一起工作，**一个自然的想法是利用这种联合工作来开发目标，不仅要获得监督模型的超参数，还要获得OD模型的超参数**。

![image-20240907103152771](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907103152771.png)

3、本文的方法与监督OD有很大区别。换句话说，**对于训练样本矩阵X，我们处于无监督OD场景下**。相比之下，**在标准的监督OD中，正常和异常模式的具体示例是已知的，这使得能够将OD问题作为分类问题来处理**（通常具有高度不平衡的类，因为异常将比正常模式少得多）。

4、本文的贡献点如下：

> 1、**将OD算法与监督回归和分类算法相结合**的建议，使得最佳OD超参数可以与监督超参数一起选择。
>
> 2、对八个分类和回归数据集进行了广泛的实验，对管道的性能进行了九种算法的OD组件和五种算法的建模组件
>
> 3、当它们与OD模型和实验框架进行流水线连接时，**基分类器和回归器的改进的数值理由**

### 3、离群值检测（OD）

#### 3.1 文献综述

1、在这项工作中，我们选择并比较了在文献中具有突出作用的**九种不同的离群值检测方法**，使用了**scikit-learn [10]或PyOD [11]中的实现**，这两个库是众所周知的Python库。**所有这些都有一个共同的参数：污染百分比，即，我们认为样本中异常值的比例**。

2、进入具体方法，我们将在这里考虑九个代表性的OD模型，即**最小协方差决定性估计[21，22]**，**局部离群因子[23]**，**基于连通性的离群因子[24]**，**k-最近邻离群估计[25，26]**，**隔离森林[27，28]**，**一类支持向量机[29]**，**主成分分析（PCA）OD [30]，[31]**、**子空间异常值检测[32]**和**基于直方图的异常值检测[33]**。

从应用程序的角度来看这种多样性**，一个非常好的参考是PyOD库[11]，我们使用了所有上述方法的实现，除了最小协方差行列式和隔离森林，我们使用它们的scikit-learn [10]实现**。除此之外，还必须提到诸如**Angle [34]或Copula [35]之类的基于算法的方法**，或**基于分类或回归树的其他方法，如[36]或基于集成的方法，如特征装袋OD [37]**。

最近，已经提出了许多**基于DNN的OD方法;最近关于这个主题的调查是[38]**。**这些方法中的许多方法将扩展基于PCA的OD算法的深度自动编码器作为其基础。[39]或[42]**。

#### 3.2 九种不同的离群值检测方法介绍

#### 3.3 监督OD

在这种情况下，**分类或回归问题由样本矩阵X和目标向量Y给出，其中X可能被污染，目标是在构建最终的分类或回归模型之前将其清除**。以这种方式**，D将被应用于X以获得干净版本Xcl及其对应的目标向量Ycl**。

##### 3.3.1 OD管道模型

##### 3.3.2 计算开销分析

### 4、数值实验

#### 4.1 实验设置

如前所述，本工作中应用的OD模型是**mcd，if，knn，lof，ocs，pca，cof，hbos和sod**，**在mcd和if的情况下使用它们的scikit-learn实现，在其他情况下使用它们的PyOD版本**。**回归监督模型将是 Ridge 和 Huber 回归作为线性回归模型，以及具有 ReLU 激活和具有 20 个单元的单个隐藏层的非线性多层感知器回归器**。 **对于分类，将使用逻辑回归，其用于两类问题的标准公式和用于多类问题的多项式版本； 再次使用 ReLU 激活的非线性多层分类器和具有 20 个单元的单个隐藏层**。 **所有分类器和回归器都选择了 scikit-learn 中的实现**。

为了测试不同的模型，**使用了五重嵌套交叉验证（CV）**，其中构建了前五个外层，并且我们循环使用其中四个作为模型超参数化的训练验证子集，其余一个用于测试 。 反过来，模型超参数化又通过训练验证子集上的五倍 CV 来完成。 **通过网格搜索得到最优超参数**。

![image-20240907105002773](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907105002773.png)

#### 4.2 数据集

我们将使用**八个回归数据集和八个分类数据集**。 更准确地说，将考虑以下数据集：用于回归的 abalone、boston、cal-housing、concrete、cpusmall、mg、winequality_red 和 winequality_white，以及用于分类的 australian、breast_cancer、diabetes、digits、dna、german、satimage 和 snippet。 

#### 4.3 回归结果

表 3、表 5 和表 7 分别给出了**五重嵌套 RR、HR 和 MLPR 模型的平均值和标准差**，而表 4、表 6 和表 8 给出了**每个问题按 MAE 值升序排列的不同模型的排名**。 可以看出，**COF 在 4 个问题中为 RR 提供了最佳结果，SOD 和 LOF 在 3 个问题中给出了最佳结果，HBOS、KNN 和 PCA 在 2 个问题中给出了最佳结果，除 OCS 之外的其余模型在 1 个问题中给出了最佳结果**。

**当考虑 Huber 回归时，情况发生了变化，其中 LOF 和基本回归器在四个问题中给出了最佳结果，在三个问题中给出了 COF 和 OCS，在一个问题中给出了所有其他模型**。**Huber 回归被设计为对于目标异常值具有鲁棒性**，因此这里基本模型的良好性能并不令人惊讶。

**对于 MLP 回归器**，这些情况再次发生变化。 现在，**LOF 在三个问题中给出了最小的 MAE（尽管在其他问题中表现较为平庸），HBOS、MCD、PCA IF 和基本 MLPR 在两个问题中给出了最小的 MAE，而其他模型则在一个问题中给出了最小的 MAE**。 

#### 4.4 分类结果

这里使用的大多数分类数据集没有特定的测试子集，并且将应用用于回归描述的相同 5 重嵌套 CV。 回归中考虑的相同超参数将用于 OD 模型，并结合**逻辑回归 (LR) 模型和多层感知器分类器 (MLPC)**，其中单个隐藏层具有 20 个分类单元。

表 17 和表 18 分别给出了测试数据集未过滤时五重嵌套 LR 和 MLPC 模型的平均值和标准差。可以看出，HBOS、LOF 和基本模型在 2 个问题中给出了 LR 的最佳结果，IF、SOD、COF 和 MCD 在 1 个问题中给出了最佳结果，而 KNN 和 OCS 从来都不是任何问题的最佳模型。 当它在回归中发生时，MLPC的情况发生了变化，其中MCD在四个问题中给出了最大的准确度，LOF在三个问题中给出了最大的准确度，基础模型在两个问题中给出了最大的准确度，SOD，IF，KNN和COF在一个问题中给出了最大的准确度，HBOS和一类SVM在一个问题中没有给出最大的准确度。

### 5、总结和展望

在这项工作中，**一个新的监督框架的离群检测器（OD）的最佳超参数估计已被提出**。**主要目标是克服OD模型所依赖的超参数的最佳值的选择困难，这是由于其无监督性质造成的困难**。为了达到这一目标，**新方法包括一个离群检测器和监督模型的组合，定义了一个新的联合估计与管道结构**。该估计器的优点在于，**它允许使用分类或回归目标来以自动和客观的方式监督每个检测器的最佳超参数的搜索**。此外，我们的方法的第二个优点是，**在许多问题中，可以单独通过分类器或回归器实现的性能提高**。

不仅在分类和回归性能方面，而且在执行时间方面，**如图1所示的所有OD方法和表28所示的五种OD方法似乎具有更好的性能**。在这方面，关于所获得的结果，**我们可以得出结论，一般来说，MCD和IF模型通常是一个很好的选择，而PCA，HBOS和LOF也应该考虑计算时间是一个加权因素**。

<img src="C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907110134633.png" alt="image-20240907110134633" style="zoom:80%;" />

![image-20240907110239135](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907110239135.png)

## 十七、《Robust Statistical Scaling of Outlier Scores: Improving the Quality of Outlier Probabilities for Outliers (Extended Version)》

### 1、摘要

异常值检测算法通常为数据集中的每个观测值分配一个**异常值分数**，指示观测值是异常值的程度。然而，**这些分数通常在算法之间不具有可比性，并且人类可能难以解释**。**统计缩放通过将离群值分数转换为离群值概率而不使用地面实况标签来解决这个问题**，从而提高算法之间的可解释性和可比性。然而，这种转换的质量对于离群值和内点可能是不同的。在特别感兴趣的场景中（如医疗保健、金融或工程），遗漏离群值可能代价高昂或危险。因此，确保离群值的良好概率至关重要。本文认为，统计尺度，在文献中常用的，不产生同样好的概率为离群值为内值。因此，**我们提出了稳健的统计尺度，它使用稳健的估计来提高离群值的概率**。我们评估了我们的方法的几个变体对其他离群值得分转换的真实世界的数据集和离群值检测算法，它可以提高离群值的概率。

### 2、实验

我们**首先使用离群值检测算法计算真实世界数据集的离群值得分**（第6.1节），**然后使用离群值得分转换将离群值得分转换为离群值概率**（第6.2节），**最后评估其离群值概率**（第6.3节）

#### 2.1 数据集和异常检测算法

我们**在21个真实世界的数据集[6]上计算离群值**，由于计算原因排除了KDD和ALOI数据集，使用11种离群值检测算法**：主成分分析[33]，核主成分分析[12]，高斯混合模型[7]，k-最近邻检测器[29]，局部离群因子[5]，隔离森林[18]，基于直方图的离群值检测[9]，轻量级异常在线检测器[27]，基于连接性的离群值因子[35]，基于采样的离群值检测[34]，以及使用经验累积分布函数的无监督离群值检测[17]**。对于所有异常值检测算法，**我们使用Python库PyOD [41]并将超参数设置为默认值**。

## 十八、《Human-in-the-loop Outlier Detection》

### 1、摘要

本文提出了一个基于人工智能的离群点检测方法HOD，该方法能够有效地利用人工智能来发现真实的离群点。在HOD中存在两个主要挑战。**第一种是设计人性化的问题，使得即使人类对离群点检测技术一无所知，人类也可以容易地理解问题。二是最大限度减少提问次数**。

### 2、引言

1、给定一个数据集，**离群值是与数据集中的其他对象（又名内点）显著不同的对象**。由于离群点检测的重要性，**已经提出了许多离群点检测方法[2，3，5，23，41]**。一般来说，这些方法可以分为两种：**有监督的和无监督**的方法。**有监督的方法需要标记离群点来训练二元分类模型，往往缺乏训练样本**。另一方面，无监督技术不依赖于任何标记数据[22]，并且它们将具有很少邻居的对象识别为离群值，然而，**简单地依赖于这些数据驱动（无监督）的方法往往会错误地将正常对象标记为离群值（假阳性）或错过真正的离群值（假阴性）**。

2、**与有监督的离群值检测方法不同，我们不以训练分类模型来检测离群值为目标。相反，我们建议首先使用无监督离群值算法生成一些离群值候选，然后使用人类根据机器生成的结果来识别真正的离群值。**

3、本工作的贡献点如下：

> (1) 我们提出了一种**人在环离群值检测方法（HOD）**，该方法能够使用尽可能少的人力来准确地发现离群值
>
> (2) 我们提出了一种**在理论保证下最小化问题数量的问题选择方法，从而有效地减少了人工努力**
>
> (3) 我们**设计了一个基于聚类的方法，发现了一组代表性的内点，有效地作为背景下容易评估离群候选点**
>
> (4) 我们在真实世界数据集上进行的实验证实，**与无监督离群值检测方法相比，HOD将离群值检测的精度和召回率提高了40%和20%以上**，而**与基线方法相比，只使用了一半的人工努力**。此外，在相同的预算下，**与基于主动学习的方法相比，HOD将F1分数提高了30%以上。HOD在质量和成本方面也优于基于众包的方法**

### 3、问题定义

![image-20240907112439745](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907112439745.png)

### 4、实验研究

#### 4.1 实验数据集

自己从网上抓取的数据集

#### 4.2 评估指标

精度和召回率

#### 4.3 参与对比的基准

我们将HOD与众所周知的无监督离群值检测方法进行了比较，包括**KNN [40]、LOF [5]、聚类方法[23]和Ensemble方法[3]。以及基于主动学习的方法AI 2 [42]和AAD [14]**。还有基于实体匹配的方法CrowdER和Magellan。

### 5、相关工作

#### 5.1 有监督异常检测方法

**这类技术假设事先有大量标记的离群值和内值可用**。使用这些标记的数据，然后训练分类模型，**该模型将测试对象分类为离群值或内界值**。然而，监督离群点检测存在两个严重的问题。首先，**训练集中的离群值通常比内值少得多。这会导致不平衡的类别分布，从而影响分类准确度[38，43，46]**。其次，**由于离群值的稀有性，难以获得大量的高质量标签，尤其是离群值标签[2，41]**。由于这些问题，监督离群点检测方法在真实的应用中并不普遍。

#### 5.2 无监督异常检测方法

**无监督类中的技术[3，5，6，23，40，52]在真实的世界中被广泛使用，因为它们不需要任何训练数据**。通常，**这些技术基于数据集中的内点通常比异常点更频繁的观察来检测异常点**。然而，**无监督技术的准确性往往很低**。然而，尽管涉及到人类，**但与监督技术不同，我们不需要人类显式地将对象标记为内点或离群点，这通常很难并且非常耗时**。相反，**通过仔细选择要由人类回答的问题**，如图2所示，**我们的HOD能够以最少的人力准确地发现离群值**。

#### 5.3 主动学习方法

给定人力成本预算，主动学习方法从数据集中选择对象，要求人类标记这些对象并迭代地训练分类器，直到预算用完。

（1）**AI2 [42]**：每次AI2选择X个对象供用户标记，**其中X/2个对象来自非监督方法，其他X/2个对象由监督方法（随机森林）提供**。在X个对象被标记后，它重新训练监督模型并选择另一个X个对象，直到预算用完。最后，利用该模型对剩余的未标记数据进行预测。

（2）**AAD [14]**：首先，AAD提取每个对象的特征，并使用监督方法来训练分类器。接下来，基于建模结果，AAD选择一个最有可能成为人类标记的离群值的对象。然后，它迭代地重新训练模型，以调整每个特征的权重，并选择新的离群候选。

尽管主动学习方法有效地减少了人类的标记努力，但它们并没有解决离群点检测中的独特挑战，即，**由于离群点的稀有性，在真实的应用中缺乏地面真值离群点**。

#### 5.4 众包技术

众包利用人类的认知能力来解决许多重要的数据管理和分析任务[8-13，19，21，27，28，30，32，34，35，39，47，48]。众包实体匹配（EM）[20，24，44]侧重于识别引用相同实体的记录，而我们提出的方法HOD侧重于识别与其他实体显著不同的离群值**。其他一些现有的工作集中于专家的数据清理[4，17，25，29，31，49-51]。SampleClean [25]是一个框架，它只需要人工清理数据样本，并利用清理后的样本来获得具有置信区间的无偏查询结果**。**QOCO [4]是一个面向查询的系统，它要求人群工作者清理不一致的记录或缺失的值**。**我们的HOD用于异常值检测。据我们所知，这是第一个关于众包离群点检测的工作**。