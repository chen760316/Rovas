

# Rovas实验框架

## 一、实验设置

### 1.1 实验数据集

真实异常检测数据集（主要来自ADBench，以及其他基准中使用的数据集）

合成异常检测数据集（合成自ADBench，Pyod提供的合成方法）

真实多分类数据集（部分异常检测数据集对应的原始多分类数据集，采集自UCI/Kaggle/OpenML）

**合成多分类数据集（合成方法待定，可以考虑高斯过程）**

**加噪多分类数据集（方法待定，在多分类数据集中添加噪声/异常值）**

不同异常比例的数据集（采集自LMU中不同异常比例的真实异常检测数据集，在Rovas\Rovas_rules\baselines\multi_class_datasets\open_source_data文件夹下）

不同异常类型的数据集（将原始异常全部删除，抽取一定比例的剩余值，转化为不同类型异常值，使用这部分异常值替换采样的正常值，参考ADbench中的实现）

#### **已选用的数据集如下**（加粗）：

| Number | Data                  | # Samples | # Features | # Anomaly | % Anomaly | Caregory     | Note         |
| ------ | --------------------- | --------- | ---------- | --------- | --------- | ------------ | ------------ |
| 1      | **wine**              | **4898**  | **11**     |           | **1.1**   |              | **正常规模** |
| 2      | **pendigits**         | 6870      | 16         | 156       | 2.27      | image        | 正常规模     |
| 3      | **optdigits**         | 5216      | 64         | 150       | 2.88      | image        | 列>20        |
| 4      | **Waveform**          | 3443      | 21         | 100       | 2.9       | Physics      | 列>20        |
| 5      | **shuttle**           | 49097     | 9          | 3511      | 7.15      | Astronautics | 正常规模     |
| 6      | **PageBlocks**        | 5393      | 10         | 510       | 9.46      | documents    | 正常规模     |
| 7      | **balita**            | 120999    | 3          |           | 11.4      | healthcare   | 行>10w       |
| 8      | **obesity**           | 1000      | 6          |           | 14.3      | healthcare   | 正常规模     |
| 9      | **adult**             | 48842     | 10         |           | 23.93     | social       | 正常规模     |
| 10     | **satellite**         | 6435      | 36         | 2036      | 31.64     | Astronautics | 列>20        |
| 11     | **iris**              | 150       | 5          |           | 33.33     | Biology      | 正常规模     |
| 12     | **yeast**             | 1484      | 8          | 507       | 34.16     | Biology      | 正常规模     |
| 13     | **breastw**           | 683       | 9          | 239       | 34.99     | healthcare   | 正常规模     |
| 14     | **apple**             | 4000      | 8          |           | 49.9      | Biology      | 正常规模     |
| 15     | **abalone**           | 4177      | 8          |           |           | Biology      | 正常规模     |
| 16     | **bank**              | 41188     | 10         |           |           |              | 正常规模     |
| 17     | **breast-cancer**     | 366       | 30         |           |           |              | 列>20        |
| 18     | chess                 | 28056     | 6          |           |           |              | 正常规模     |
| 19     | cmc                   | 1473      | 8          |           |           |              | 正常规模     |
| 20     | **credit-card-fraud** | 284808    | 29         |           |           |              | 行>10w       |
| 21     | kdd99                 | 620097    | 29         |           |           |              | 行>10w       |
| 22     | kdd2014               | 619237    | 10         |           |           |              | 行>10w       |
| 23     | kddcup99              | 64759     | 6          |           |           |              | 正常规模     |
| 24     | **pen-global**        | 808       | 16         |           |           |              | 正常规模     |
| 25     | pen-local             | 6723      | 16         |           |           |              | 正常规模     |
| 26     | seismic               | 2584      | 18         |           |           |              | 正常规模     |
| 27     | solar                 | 1066      | 11         |           |           |              | 正常规模     |
| 28     | speech                | 3685      | 40         |           |           |              | 列>20        |
| 29     | WPBC                  | 569       | 30         |           |           |              | 正常规模     |



### 1.2 实验基准算法

无监督算法（基于距离的，基于密度的，基于统计的，基于模型的，基于学习的（偏向深度和主动学习）的）

半监督算法（深度和主动学习的开源算法）

监督算法（基于深度的开源算法）

集成算法（基于bagging/boosting等）

#### 已选用的基准如下：

> 无监督统计方法：ECOD、COPOD、OCSVM、AKDE(add)、HBOS(add)
>
> 无监督基于距离的方法：LOF、COF、SOD、HBOS、RBRP(add)、LDOF(add)、RBDA(add)
>
> 无监督基于密度的方法：CBLOF(add)、LDCOF(add)、LOCI(add)、INFLO(add)、LOF(add)、COF(add)
>
> 无监督集成方法：LODA、IForest、BORE(add)、HeDES(add)、DCSO(add)、LSCP(add)
>
> 无监督基于角度的方法：FastABOD(add)
>
> 无监督主动学习方法：GLAD(add)
>
> 无监督子空间学习方法：SOD(add)
>
> 无监督深度方法：DeepSVDD、RDP(add)、RCA(add)、GOAD(add)、NeuTral(add)、ICL(add,2022)、DIF(add,2023)、SLAD(add,2023)、DAGMM
>
> 弱监督深度方法：GANomally、DeepSAD、REPEN、DevNet、PReNet(2023)、FeaWAD(add)、RoSAS(add)、XGBOD(add)
>
> 监督深度方法：LGB(add)、CatB(add)
>
> 监督深度集成方法：XGBoost（add）

### 1.3 实验评测指标

accuracy（分类准确度是正确分类的样本数与总样本数的比率，**适用于类别分布相对均匀的情况**）

precision（精确度是指所有被模型预测为正例的样本中，实际为正例的比例）

recall（召回率是指所有实际为正例的样本中，被模型正确预测为正例的比例）

F1分数（F1分数是精确率和召回率的调和平均值，**适用于类别不平衡的情况**）

ROC-AUC分数（AUC 值越接近 1，模型性能越好，适用于**二分类问题**）

PR AUC（PR 曲线绘制了精确度与召回率之间的关系，**适用于不平衡数据集**。可以用于**评估不同阈值下的模型性能，特别是在正类样本较少的情况下**。PR AUC 表示 PR 曲线下的面积，范围在 0 到 1 之间。**越接近 1，模型在平衡精确度和召回率方面的性能越好**。）

AP（**AP 是精确度和召回率的加权平均，综合考虑了不同召回率下的精确度**。用途：常用于多类分类任务，特别是检测任务。**AP 是一个重要的评估指标，能够全面反映模型在不同召回率下的表现。计算 AP 时，关注精确度与召回率的平衡，尤其是在处理不平衡数据时**。）

CD图（CD 图 是一种可视化工具，**通常用于比较多个算法或模型的性能**，特别是在机器学习和统计学中。**它主要用于显示不同算法之间的显著性差异，并帮助研究者判断哪些算法在特定任务上表现更好**）

Rank Power (RP)（是一种用于**评估排序模型或推荐系统性能的指标**。它主要用于判断一个模型在给定查询下的结果排名是否合理。Rank Power 指标**关注模型在预测时是否能将相关性更高的项目排在更前面**。通过判断前n个异常候选中实际有多少异常值，可以衡量不同异常检测算法的性能）

其他的性能评测指标（例如**CPU利用率、执行时间、训练时间、测试时间、计算时间、内存使用、鲁棒性**）

### 1.4 实验配置

实验环境（待定）

算法超参数设置（默认）

算法实现语言



## 二、实验设计

### 2.1 Rovas和传统离群值检测算法在离群值检测指标上的比较

#### 2.1.1 实验一（Rovas/基准算法性能对比）

将Rovas与基准在异常检测数据集上的**异常检测性能（Accuracy/PRAUC等指标）进行对比**（作表）

#### 2.1.2 实验二（Rovas/基准算法对不同种类，不同比例异常值的检测性能）

**改变数据集中的异常值种类**，探索Rovas和基准对不同种类异常值（good/bad/ugly，或adbench中对异常值的分类）的检测效果。**改变异常值比例**，检测Rovas和基准算法的鲁棒性。（作CD图）

#### 2.1.3 实验三（Rovas/ADbench探索性试验）可不加

good/bad/ugly的outliers和adbench中区分的四类异常值的区别和联系



### 2.2 Rovas算法自身性能的评估

#### 2.2.1 实验一（Rovas/基准算法可扩展性）

随着数据集规模（行/列）的增大，Rovas运行时间变化（可加入基准算法的时间变化，但估计比Rovas快）

#### 2.2.2 实验二（Rovas谓词评估）

评估Rovas规则中的机器学习/聚合/损失谓词（暂无评估指标，可参照谓词设定目标的实现程度，以及谓词的执行时间）



### 2.3 Rovas修复对下游分类任务的影响

#### 2.3.1 实验一（OHunt修复效果测试）

对比下游任务分类器（如SVM/RF分类器）**在原始数据集（含outliers），与ugly outliers修复后的数据集上，分类器性能(Accuracy/PRAUC等指标)的差异**

#### 2.3.2 实验二（OHunt修复方法对比）

对比不同异常值修复策略（如**基于统计修复**/**直接删除**/**训练机器学习模型用于异常修复**）的不同效果(Accuracy/PRAUC等指标)

#### 2.3.3 实验三（OHunt鲁棒性测试）

对比在**不同异常比例**的原始数据集中，经过Rovas修复策略进行修复后，**能保证分类器在原始数据集上分类效果（Accuracy/PRAUC等指标）随异常比例提高而降低，在修复后的数据集上，分类效果能稳定在一定水平范围内**。
