## 一、《ADBench: Anomaly Detection Benchmark》

### 1、主要贡献

1、**最全面的AD基准**。ADBench在57个基准数据集上测试了30种检测算法的性能。算法类别包括**（i）最新的无监督AD算法，（ii）SOTA半监督算法，（iii）最新的网络架构，（iv）集成学习方法**。公共AD数据集。在ADBench中，我们收集了4**0多个基准测试数据集[25、42、129、145]**，用于模型评估，为了进行尽职调查，我们**保留异常率低于40%的数据集**。数据集涵盖了医疗保健，音频和语言处理，图像处理和金融等领域。**由于大多数数据集相对较小，因此我们在ADBench中引入了CV和NLP域的10个更复杂的数据集**。

![image-20240907173416676](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173416676.png)

2、**公平和可访问的AD评估**。https://github.com/Minqi824/ADBench上以BSD-2许可证开源了ADBench

### 2、异常检测算法

1、**通过假设异常数据分布的无监督方法**。**如[3，15，129，150，198]**，大致分为浅层和深层（神经网络）方法。前者通常具有更好的可解释性，而后者更好地处理大型、高维数据。

2、**将异常检测视为二进制分类的监督方法**。没有专门的监督异常检测算法，人们经常为此使用**现有的分类器[3，170]，如随机森林[21]和神经网络[89]**。这些方法仅限于**检测未知类型的异常**[3]。最近的**机器学习书籍[4，54]和scikit-learn [133]可以作为监督ML方法的良好来源**。

3、**有效使用标签的半监督方法**。半监督AD算法可以**利用部分标签的监督，同时保持检测不可见类型异常的能力**。一些半监督模型仅在正态样本上训练，并且检测偏离在训练过程中学习到的正态表示的异常**[7，8，188]**。在**ADBench中，半监督主要指弱监督下的不完全标签学习**

### 3、各类具体异常检测算法

#### 1 无监督方法

在过去的几十年中，**已经提出了许多无监督方法[3，15，129，150，198]**，这些方法可以粗略地分为**浅层和深层（神经网络）方法**。前者通常具有更好的可解释性，而后者更好地处理大型、高维数据。最近的**书籍[3]和综述[129，150]提供了关于这些算法的大量细节**。

##### 2.1.1 代表性浅层方法

一些代表性的浅层方法包括：**（i）隔离森林（IForest）[100]**构建一个树的集合来隔离数据点，并将异常得分定义为单个实例到根的距离;（**ii）单类SVM（OCSVM）[157]**最大化原点和正常样本之间的间隔，其中决策边界是确定间隔的超平面;以及（**iii）基于经验累积分布的离群值检测（ECOD）[97]**计算输入数据的每个维度的经验累积分布，然后聚合每个维度的尾部概率以计算异常分数。

> 1、主成分分析（**PCA**）[162]。**当用于AD时，它将数据投影到低维空间，然后使用重建误差作为异常分数**。如果未指定，PyOD中的默认超参数将用于PCA（以及PyOD部署的其他无监督算法）
>
> 2、单类SVM（**OCSVM**）[157]。OCSVM最大化原始样本和正常样本之间的间隔，并将决策边界定义为确定间隔的超平面。
>
> 3、局部离群因子（**LOF**）[22]。LOF测量给定样本相对于其相邻样本的密度的局部偏差。
>
> 4、基于聚类的局部离群因子（**CBLOF**）[64]。CBLOF通过首先将样本分配给聚类，然后使用聚类之间的距离作为异常分数来计算异常分数。
>
> 5、基于连接性的离群值因子（**COF**）[167]。COF使用数据点的平均链接距离与数据点的第k个最近邻的平均链接距离的比率作为观测的异常分数。
>
> 6、基于直方图的离群值检测（**HBOS**）[52]。HBOS假设特征独立性，并通过构建直方图来计算异常度。
>
> 7、K-最近邻（**KNN**）[144]。KNN将输入实例的异常分数视为到其第k个最近邻居的距离。
>
> 8、子空间异常值检测（**SOD**）[80]。SOD旨在检测高维特征空间的不同子空间中的异常值。
>
> 9、基于Copula的离群值检测器（**COPOD**）[96]。COPOD是一种基于经验copula模型的无超参数、高度可解释的离群值检测算法。
>
> 10、基于经验累积分布的离群值检测（**ECOD**）[97]。ECOD是一种基于经验CDF函数的无超参数、高度可解释的离群值检测算法。基本上，它使用ECDF独立地估计每个特征的密度，并假设离群值位于分布的尾部。
>
> 11、轻量级在线异常检测器（**LODA**）[136]。LODA是一种集成方法，在需要实时处理大量样本的领域或数据流受到概念漂移影响且检测器需要在线更新的领域中特别有用。
>
> 12、隔离森林（**IForest**）[1].IForest通过随机选择一个特征，然后在所选特征的最大值和最小值之间随机选择一个拆分值来隔离观测。

##### 2.1.2 代表性深度方法

**（i）深度自动编码高斯混合模型（DAGMM）[205]**以端到端神经网络的方式联合优化深度自动编码器和高斯混合模型。（**ii）深度支持向量数据描述（DeepSVDD）[151]**训练神经网络学习一种变换，该变换使输出空间中数据封闭超球体的体积最小化，并计算异常分数作为变换嵌入到超球体中心的距离。

> 1、深度支持向量数据描述（**DeepSVDD**）[151]。DeepSVDD训练神经网络，同时最小化包含数据的网络表示的超球体的体积，迫使网络提取变化的共同因素。
>
> 2、深度自动编码高斯混合模型（**DAGMM**）[205]。DAGMM利用深度自动编码器为每个输入数据点生成低维表示和重建误差，并进一步将其馈送到高斯混合模型（GMM）中。

#### 2.2 有监督方法

**我们在ADBench中实现了几种代表性的监督分类算法（如Appx.§B.1）**，并推荐感兴趣的读者阅读**最近的机器学习书籍[4，54]和scikit-learn [133]**，以了解有关最近为分类任务设计的监督方法的更多细节。

> 1、Naive Bayes（**NB**）[14].NB方法基于应用贝叶斯定理，并假设每对特征之间的条件独立性是给定的类变量的值。我们在ADBench中使用高斯NB。
>
> 2、支持向量机（**SVM**）[31]。SVM在高维空间中是有效的，并且在维数大于样本数的情况下仍然有效。我们使用scikit-learn中的默认超参数用于SVM（以及以下的MLP和RF）。
>
> 3、多层感知器（**MLP**）[148]。MLP使用二进制交叉熵损失来更新网络参数。
>
> 4、随机森林（**RF**）[21]。RF是一个Meta估计器，它将多个决策树分类器拟合到数据集的各个子样本上，并使用平均值来提高预测准确性并控制过度拟合
>
> 5、极端梯度提升（**XGBoost**）[29]。XGBoost是一种优化的分布式梯度增强方法，旨在实现高效，灵活和便携。我们使用XGBoost官方存储库中的默认超参数设置1
>
> 6、高效梯度提升决策树（**LightGBM**）[74]。LightGBM是一个梯度增强框架，它使用基于树的学习算法，具有更快的训练速度，更高的效率，更低的内存使用量和更好的准确性。使用LightGBM官方存储库2中的默认超参数设置。
>
> 7、Categorical Boosting (**CatBoost**) [138]。CatBoost是一种快速、可扩展、高性能的决策树梯度提升算法。CatBoost使用其官方存储库中的默认超参数设置
>
> 8、剩余网络（**ResNet**）[56]。这种方法为基于表格的数据引入了一种类似ResNet的架构[62]。ResNet训练了100个epoch，64个批次大小。AdamW [108]优化器采用0.001的学习率来更新网络参数。
>
> 9、特征令牌化器+ Transformer（**FT Transformer**）[56]。FT Transformer是Transformer架构[171]对表格数据的有效适配。FTTransformer训练了100个epoch，64个批次大小。AdamW优化器采用0.0001的学习率和10−5的权重衰减来更新网络参数。

#### 2.3 半监督方法（GANomaly、FEAWAD和XGBOD未包含）

**半监督AD算法旨在利用部分标签的监督，同时保持检测未知类型异常的能力**。我们在这里进一步提供了代表性的半监督AD方法的一些技术细节。请看Appx。§B.1。

> 1、通过对抗性训练进行半监督异常检测（**GANomaly**）[7]。一种基于GAN的方法，将输入实例的重建误差定义为异常分数。**我们将原始GANomaly中的卷积层替换为具有tanh激活函数的密集层，用于在表格数据上对其进行评估**，其中GANomaly的编码器-解码器-编码器结构的隐藏大小设置为输入维度的一半。我们训练GANomaly 50个epoch，64个批次大小，其中SGD [149]优化器具有0.01的学习率和0.7的动量，用于生成器和迭代器。
>
> 2、深度半监督异常检测（**DeepSAD**）[152]。一种深度单类方法，**通过惩罚异常表示的距离的倒数来改进无监督DeepSVDD [151]**，使得异常必须映射到更远离超球体中心的位置。损失函数中的超参数η被设置为1.0，其中DeepSAD被训练了50个epoch，具有128个批量大小。亚当优化器与0.001的学习率和10 - 6的权重衰减应用于更新网络参数。DeepSAD还使用了一个自动编码器来计算超球体的初始中心，其中自动编码器被训练了100个epoch，128个批次大小，并由Adam优化器优化，学习率为0.001，权重衰减为10−6。
>
> 3、表示基于随机最近邻距离的方法（**REPEN**）[127]。一种基于神经网络的模型，利用转换后的低维表示进行基于随机距离的检测。REPEN的隐藏大小设置为20，三重丢失的余量设置为1000。REPEN被训练30个epoch，具有256个批次大小，其中总步骤数（样本批次）被设置为50。Adadelta [187]优化器采用0.001学习率和0.95 ρ来更新网络参数。
>
> 4、Deviation Networks（**DevNet**）[131].基于神经网络的模型使用先验概率来强制输入实例的统计偏差分数。偏差损失中的裕度超参数a被设置为5。DevNet被训练了50个epoch，512个批次大小，其中总步骤数设置为20。使用具有0.001学习率和0.95 ρ的RMSprop [149]优化器来更新网络参数。
>
> 5、基于成对关系预测的有序回归网络（**PReNet**）[130]。一种基于神经网络的模型，定义了双流有序回归来学习实例对的关系。将{未标记，未标记}、{标记，未标记}和{标记，标记}样本对的得分目标分别设置为0、4和8。PReNet被训练了50个epoch，512个批次大小，其中总步骤数被设置为20。应用学习率为0.001和0.01权重衰减的RMSprop优化器来更新网络参数。
>
> 6、用于弱监督异常检测（**FEAWAD**）的自动编码器特征编码[203]。一种基于神经网络的模型，将DAGMM [205]的网络架构与DevNet [131]的偏差损失相结合。FEAWAD被训练30个epoch，512个批次大小，其中总步骤数被设置为20。采用学习率为0.0001的Adam优化器更新网络参数。
>
> 7、极端梯度提升离群值检测（**XGBOD**）[195]。XGBOD首先使用passedin无监督离群检测器来提取更丰富的数据表示，然后将新生成的特征连接到原始特征以构建增强的特征空间。然后将XGBoost分类器应用于该增强的特征空间。我们使用PyOD中的默认超参数。

#### 2.4 现有的异常检测基准

**[150]讨论了浅层和深层异常检测方法的统一评论**，但它们主要集中在理论观点，因此缺乏从实验观点的结果。**[25]在10个数据集上对19种不同的无监督方法进行了测试**，并分析了**基于密度和基于聚类的算法的特点**。**[38]在15个公共数据集上测试了14种无监督异常检测方法**，并分析了不同方法的**可扩展性、内存消耗和鲁棒性**。**[166]提出了一个通用的过程中产生的现实合成数据**。合成正常实例是从现有的真实世界基准数据重建的，而合成异常符合与合成正常数据的建模的可表征偏差。**[42]在19个公共数据集上评估了8种无监督方法，并生成了一个大型的合成异常检测数据集语料库**，这些数据集在对现实世界应用很重要的几个维度上的结构各不相同。**[25]比较了12个无监督的异常检测方法在23个数据集，提供了一个基准数据集的特征和他们的异常检测基准集的适用性**。

## 3、各类具体的数据集

**对于那些小于1，000的数据集，我们将样本大小重新采样为1，000，对于那些大于10，000的数据集，由于计算成本，我们使用10，000的子集**。如有可能，我们将在https://github.com/Minqi824/ADBench/tree/main/datasets上发布所有数据集及其原始版本。

在选定的浅层方法上直接运行大型CV和NLP数据集通常具有挑战性，例如，OCSVM [157]和kNN [144]具有高时间复杂度，**我们遵循DeepSAD [152]，ADIB [33]和DATE [115]通过神经网络提取CV和NLP数据集的表示**，用于下游检测任务。**DeepSAD [152]使用预训练的自动编码器来提取用于训练经典AD检测器（如OCSVM [157]和IForest [100]）的特征**。

![](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909112547110.png)

![image-20240909123000574](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909123000574.png)

### 3、现有的表格异常检测数据集和基准

1、现有基准主要评估来自**ODDS库[145]、DAMI库[25]、ADRepository [129]和异常检测荟萃分析基准[42]**的部分数据集。在ADBench中，我们包含了几乎所有公开可用的数据集，并添加了**从CV和NLP领域改编的更大的数据集**，以获得更全面的视图。**现有的基准包括[25, 38, 42, 150, 166]**

### 4、ADBench中的异常类型

我们在公共数据集的基础上，通过注入特定类型的异常来创建合成数据集，以分析AD算法的响应。**我们遵循并丰富了[166]中的方法来生成“真实”的合成数据**;我们的方法支持更多类型的异常生成

> **局部异常是指偏离其局部邻域的异常[22]**。我们**遵循GMM过程[118，166]来生成合成正态样本，然后通过缩放参数α = 5来缩放协方差矩阵= α以生成局部异常**。
>
> **全局异常与正态数据[68]有更大的不同，由均匀分布生成**。
>
> **依赖异常是指不遵循正常数据遵循的依赖结构的样本[117]**，即，**依赖性异常的输入特征被假定为彼此独立**。**我们使用核密度估计（KDE）[61]来估计特征的概率密度函数并生成正常样本。Vine Copula [1]方法用于生成异常样本**
>
> **异常群，也称为群异常[93]，表现出类似的特征**

局部异常（图3a）与正常样本有很好的重叠。全局异常（图3b）更偏离正常样本，并且位于正常聚类的边缘。

### 5、测试模型鲁棒性

我们试图通过在三种噪声和腐败设置下评估AD算法来评估异常检测模型的鲁棒性：
**1、重复异常**。在许多应用中，由于记录错误等原因，某些异常可能会在数据中重复多次[83]。**重复异常的存在也被称为“异常屏蔽”[55、60、100]**，这**对许多AD算法[25]提出了挑战，例如，基于密度的KNN [11，144]**

**2、不相关的特征**。**表格数据可能包含由测量噪声或不一致的测量单位[28，55]引起的不相关特征，其中这些噪声维度可能隐藏异常数据的特征，并因此使检测过程更加困难[128，150]**。

**3、注释错误**。虽然现有研究[131，152]探讨了未标记样本中的异常污染，但我们进一步讨论了标记污染对算法性能的更普遍影响，**其中考虑了正常样本和异常之间的标记翻转[122，202]（高达总标记的50%）**。此设置不影响未受监督的方法，因为它们不使用任何标签。

### 6、实验结果与分析

#### 6.1 实验设置

1、**训练集与测试集比例。7比3的比例，流行的AD库包括PyOD [198]，TODS [84]和PyGOD [102]**。所选用的数据集如下：

2、超参数设置。我们使用了它们在原始论文中的**默认超参数（HP）设置**

**3、评价指标和统计检验。我们通过两个广泛使用的指标来评价不同的AD方法：**

> **AUCROC（受试者操作特征曲线下的面积）**
>
> **AUCPR（精确度-回忆曲线下的面积）。**
>
> **基于Wilcoxon-Holm方法的临界差异图（CD图）[34，70]用于统计学比较AD方法组（p ≤ 0.05）**

#### 6.2 具有不同监督程度的数据集上的整体模型性能

1、没有一种无监督的方法在统计学上比其他方法更好

2、当标签信息有限时，半监督方法优于监督方法

3、最新的网络架构（如Transformer）和新兴的集成方法在AD中具有竞争力的性能

4、**HBOS、COPOD、ECOD和NB是最快的，因为它们独立处理每个功能。XGBOD、ResNet和FTTransformer的计算量很大**

5、未来方向。注意算法选择，超参数优化和**半监督AD方法**

#### 6.3 不同类型异常下的算法性能

**1、无监督算法的性能高度依赖于其假设和潜在异常类型的对齐**。**局部异常因子（LOF）在统计上优于局部异常的其他无监督方法**。**KNN是全局异常的统计最佳检测器**。没有算法在所有类型的异常上都表现良好

2、**关于异常类型的先验知识的“力量”可能超过部分标签的使用**。对于局部、全局和依赖异常，大多数标签通知方法的性能都比每种类型的最佳无监督方法差。利用异常类型作为有价值的先验知识。即使在没有标签的情况下，了解异常类型在实现高检测性能方面的重要性。

![image-20240907173452258](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173452258.png)

![image-20240907173533060](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173533060.png)

![image-20240907173629307](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173629307.png)

![image-20240907173911408](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173911408.png)

![image-20240907173956387](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173956387.png)

#### 6.4 算法在噪声和破坏数据下的鲁棒性

**1、无监督方法更容易受到重复异常的影响**。

**2、由于特征选择，不相关的特征对监督方法的影响很小**。例如，像XGBoost这样的集成树可以过滤不相关的特征，此外，监督方法（和一些半监督方法，如DevNet）的鲁棒性能表明，标签信息可以有利于特征选择。

**3、半监督和全监督方法都对轻微的注释错误表现出很大的弹性**。尽管**当注释错误严重时这些方法的检测性能显著降级**，但是它们关于较小注释错误的降级是可接受的。

![image-20240907174157311](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907174157311.png)

## 二、《Generalized Out-of-Distribution Detection: A Survey》

### 1、 Outlier Detection

1、背景：**AD、ND、OSR和OOD中的问题设置检测与训练数据分布不同的未见过的测试样本。相比之下，离群值检测直接处理所有观测值，旨在从污染数据集中选择离群值[12，13，14]**。由于离群值检测不遵循训练测试程序，但可以访问所有观察结果，因此**解决这个问题的方法通常是转导而不是归纳[75]**。

2、定义：离群点检测的目的是检测**由于协变量或语义变化而与给定观测集中其他样本显著不同的样本**。**与所有先前的子任务不同，其内分布是在训练期间定义的，离群值检测的“内分布”是指大多数观察值。由于P（Y）上的语义移位或P（X）上的协变量移位，可能存在离群值**。

3、离群值划分：**要在MNIST上构建离群值检测基准，应选择一个类，以便将属于该类的所有样本视为内点。一小部分来自其他类别的样本被引入作为待检测的离群值。**

4、评价方案：除了**F-scores，AUROC和AUPR**之外，离群检测器的评估还可以通过其支持的主要任务的性能来评估。例如，**如果使用离群值检测器来净化具有噪声标签的数据集，则在经净化的数据集上训练的分类器的性能可以指示离群值检测器的质量**。

### 2、AD、ND和OD检测的方法

#### 2.1 Anomaly Detection & Novelty Detection

**1、基于密度的方法：**

> **基于密度的方法对正态数据（ID）分布进行建模，假设异常测试数据具有较低的可能性，而正常数据具有较高的可能性**。
>
> **参数密度估计假设预定义的分布**[272]。方法涉及多元高斯分布[273，274]、混合高斯分布[275，276]和泊松分布[277]。
>
> **非参数密度估计使用直方图**[279，280，281，282]和核密度估计（KDE）[283，284，285]处理更复杂的场景[278]。
>
> **神经网络**生成高质量的特征，以增强经典的密度估计。自动编码器（AE）[286]和变分自动编码器（VAE）[287]的模型、生成对抗网络（GAN）[288]、基于流的模型[195，289]和表示增强策略
>
> **EBM使用标量能量分数来表达概率密度[290]并为AD提供解决方案[291]**。

**2、基于重建的方法：**

> **这些AD方法利用特征空间中的正常和异常数据或重建误差的模型性能差异。**
>
> **稀疏重建**假设正常样本可以使用有限的基函数集精确重建，而异常具有更大的重建成本和密集表示[297，298，299]。技术包括基于L1范数的内核PCA [300]和低秩嵌入式网络[301]。
>
> **重建误差方法**假设在正常数据上训练的模型将为正常测试样本产生比异常更好的重建。深度模型包括AE [302]，VAE [303]，GAN [304]和U-Net [305]。基于AE/VAE的模型将联合收割机重建误差与AE/VAE模型[302，303]相结合，并使用诸如通过记忆的常态重建[306，307]，适应模型架构[308]和部分/条件重建[192，309，310]等策略。在半监督AD中，CoRA [311]使用重建误差进行异常检测，在内点和离群点上训练两个AE。使用GAN的重建误差方法利用GAN来计算异常检测的重建误差[304]。去噪GAN [194]，类条件GAN [54]和集成[312]等变体进一步提高了性能。基于梯度的方法在重建任务中观察训练梯度和异常之间的不同模式，使用基于梯度的表示来表征异常[313]。

**3、基于距离的方法：**

> **基于距离的方法**通过计算样本和原型之间的距离来检测异常[314]，需要内存中的训练数据。方法包括**K-最近邻[315]和基于原型的方法[316，317]**。

**4、基于分类的方法：**

> AD和单类ND通常被表述为无监督学习问题，但也有一些**监督和半监督方法**。**单类分类（OCC）直接学习与正态数据分布的期望密度水平集相对应的决策边界[318]**。**DeepSVDD [319]将经典OCC引入深度学习社区**。**PU学习[320，321，322，323]被提出用于半监督AD设置**。**自监督学习方法使用借口任务，如对比学习[139]，图像变换预测[324，325]和未来帧预测[326]**，其中异常更有可能在设计的任务中出错。

**5、理论分析：**

> 一些工作中也提供了对AD和一类ND的理论分析。例如，**[58]构建了一个干净的ID集和一个具有相同样本量的ID/OOD混合集，实现了一个PAC式的有限样本保证，用于以最小的虚警数量检测特定部分的异常**。

#### 2.2 Outlier Detection

离群值检测（OD）观察所有样本，以识别与多数分布的显著偏差。

**1、基于密度的OD方法：**

> 包括**高斯分布[327，328]，马氏距离[273]，高斯混合[329]和局部离群值因子（LOF）**[330]。**RANSAC [331]估计数学模型的参数。还可以应用经典密度方法和基于KNN的密度方法**。

**2、基于距离的方法：**

> 离群值可以通过**邻居计数**[332，333]，**DBSCAN聚类**[334]和**基于图形的方法**[335，336，337，338，339，340，341，342，343]来检测。

**3、基于分类的方法：**

> AD方法，如**隔离森林[344]和OC-SVM** [318，319]可以应用于OD。**深度学习模型**可以识别离群值[345]。鲁棒性和特征泛化的技术包括**集成[346]，协同训练[347]和蒸馏[345，348]**。

![image-20240907175554569](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907175554569.png)

## 三、《Empirical study of outlier impact in classification context》？

### 1、离群点检测技术

离群点检测技术可以大致分为以下几类：**基于统计/基于分布的算法、基于距离的算法、基于密度的算法和基于聚类的算法**

> (1) **在基于统计的算法中，离群值是与标准分布有很大偏差的观测值**。**统计方法具有明显的缺点，即不适用于统计分布未知的数据集**。
>
> (2) **基于距离的方法来检测离群值，这是最常用和最简单的检测方法**。在这些方法中，离群点被识别为远离其相邻点的点。注意到，**当处理高维数据集时，基于距离的方法计算量大，并且难以检测正常对象边界内的离群值**。
>
> (3) **基于密度的方法，其中离群值被假设为具有比它们的邻居更低的密度**。与基于距离的方法不同，**基于密度的方法（Bai等人，2016; Breunig等人，2000; Tang & He，2017; Xie et al.，2020）比较对象的密度与其邻居的密度**。存在许多经典的基于密度的方法，包括**局部离群值因子（LOF）**（Breunig等人，2000）和**低密度模式（COF）**的离群值检测（Tang等人，2002），尽管给定的数据集可能具有不同程度的聚类密度，但其功能良好。Campos等人（2016）发现，**LOF检测器是使用KNN技术的12个检测器组中最精确的**。**当使用基于密度的方法时，必须选择最佳邻居参数k以获得必要的邻居信息**，当特定项目的邻居分布在密度变化的两个集群之间时，精确地测量它们的密度变得困难。
>
> (4) **基于集群的方法**。**（Chen等人，2024; Kang，2022; Li等人，2022）首先对数据集进行聚类，然后计算每个聚类而不是每个单独对象的离群值程度**。**基于聚类的方法的有效性在很大程度上取决于正常对象的聚类效果。如果聚类结果是不利的，则检测离群点的结果是无效的**。**ROCF聚类算法**是专门设计来检测离群聚类，以提高基于聚类方法的效率。**在Yu和Kang（2023）中，提出了一种基于聚类集成的新奇得分算法**，其中将随机子空间和随机k集成方法生成的多个聚类解决方案相结合以计算新奇得分。在基于聚类的集成方法中，为了实现个体分类器的多样性，创建尽可能多的聚类是很重要的。**由于大量的聚类，每个聚类都有少量的观察结果，导致单个分类器的效率低下**。

### 2、相关工作

> 1、Qin et al.（2019）提出了**使用核密度估计估计局部离群值，称为KELOS**，以高效检测窗口化数据流中的top-n局部离群值。
>
> 2、**Yoon et al.（2020）采用了不同的剪枝策略来检测窗口数据流中的前n个局部离群值**。
>
> 3、近年来提出了一种**基于二元分类器集合的一类分类器（BCE-OC）（Kang，2022）**。
>
> 4、**Chen et al.（2024）还描述了一种基于密度的空间聚类方法（DBSCAN）**。
>
> 5、**为了克服参数敏感性问题以及现有离群值算法难以同时检测聚类和局部离群值的问题，Huang et al.（2023）首先基于样本间距离计算了转弯密度**。然后，根据k-最近邻和逆k-最近邻的计数，计算样本的转弯比。最后，使用每个样本的转向密度和转向比来计算离群转向因子（OTF）。当OTF值较高时，更有可能出现离群值。
>
> 6、**Zhou et al.（2024）提出了一种用于检测离群值的高密度迭代方法**。与其他基于k-近邻的方法相比，**该方法更适合于各种复杂的数据分布**。
>
> 7、**Tran et al.（2020）使用“核心点”数据结构实施了一种新的离群值检测系统**，该数据结构通过多个距离进行索引。
>
> 8、为了克服基于密度的离群点检测方法的局限性，**熊等（2022）提出了邻域加权离群点检测算法（NWOD）**
>
> 9、**Li等人（2022）使用了一个扩展的近邻集，其中包括k-最近近邻以及反向k-最近近邻，以适应复杂的数据分布**。
>
> 10、**Yuan et al.（2018）提出了一种混合数据驱动的离群值检测方法**。
>
> 11、对于异常值的检测，**Zhang等人（2023）提出了一种多源信息融合方法**。
>
> 12、此外，**在Xie et al.（2020）中，提出了LGOD检测模型来检测异常值**，该模型同时考虑了对象的质量和由其邻居产生的局部合力（LRF）。
>
> 13、**在Wang和Mao（2019）中，为了监测工业过程，提出了一种基于单类分类的动态集成离群值检测方法**。他们生成伪离群值，然后将基础分类器的所有输出转换为概率模型
>
> 14、此外，**Baldomero-Naranjo等人（2021）提出了一种基于支持向量机（SVM）的鲁棒分类模型**，该模型**同时检测离群值并从输入数据中选择特征**。
>
> 15、**Wang和Mao（2020）中检测和去除离群值的标准基于两个几何标准，即局部密度和与局部拟合平面的偏差**。作为Yang等人（2021）提出的均值漂移离群值检测（MOD）方法的一部分，计算样本最近邻的均值，以均值漂移方法执行数据集，并计算样本的偏移距离，以估计离群值的程度。
>
> 16、除了上面提到的离群值检测方法之外，**Yang等人（2023 b）提出了基于邻域一致性的搜索方法（KFC）**，**以确定最佳参数k**。**作为基于k-近邻的离群点检测方法的一部分，该方法试图解决最优参数的选择问题**
>
> 17、此外，还提出了不同的**基于图的离群值检测方法**，**例如Wang和Li（2021），Wang等人（2019）提出的工作**，首先构建一个图，然后采用定制的马尔可夫随机游走方法来检测图中的离群值。**在Huang et al.（2017）中，基于相互邻居图的概念，提出了一种称为ROCF的方法，其中通过设置聚类大小间隙来分离正常聚类和离群值**。**在Li et al.（2022）中，提出了一种密度距离决策图，它通过结合全局和局部离群值来同时检测全局、局部和聚类离群值**。利用样本与最近邻样本的密度比来判断局部离群点，利用密度提升距离来识别全局离群点。**基于图的方法特别强大，因为它具有强大的表达能力和捕捉一组数据中的长期相关性的卓越能力。尽管这些方法是有用和有效的，但缺点是它们需要大量的时间**。**Wang et al.（2018）提出了一种新的离群点检测模型，该模型将图表示与每个对象周围的局部邻域信息相结合，以构建局部信息图**。在该模型中，使用随机游走过程计算离群值评分。**此外，Pourhabibi et al.（2020）还概述了基于图的异常检测技术**。

### 3、实验研究

#### 3.1 实验设置

> **F1分数在处理不平衡数据集时非常有用，因为它同时考虑了假阳性和假阴性。与仅使用accuracy相比，此度量提供了对模型性能的更全面的评估。**此外，有10种不同的分类器被训练用于数据分类，包括**线性支持向量机（SVM）、K-最近邻（KNN）、随机森林（RF）、决策树（DT）、线性判别分析（LDA）和逻辑回归（LR）。此外，还使用基于集成的分类算法，诸如梯度提升（GB）、Bagging、AdaBoost和直方图提升梯度分类器（HBGB）**。**我们使用所有上述的分类器及其默认参数，除了在逻辑回归的情况下，我们将迭代次数设置为1000**。**最后，在所有数据集上执行5重交叉验证**。

![image-20240907181435656](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907181435656.png)

#### 3.2 实验结果

> 在所有数据集上的实验结果表明，**所提出的FCM-AD方法能有效提高分类准确率，但需要消耗更多计算资源**。因为**我们没有关于每个样本是否为离群值的真实依据**。在这种情况下，**如果在离群数据上训练模型，则输入数据中的离群值可能导致机器学习算法被不正确地训练**。

![image-20240907181509119](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907181509119.png)

![image-20240907181522609](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907181522609.png)

## 四、《Machine Learning for Anomaly Detection: A Systematic Review》

### 1、摘要和引言

1、本文从**异常检测的应用、ML技术、ML模型的性能度量和异常检测的分类**四个方面对模型进行了分析。我们识别了**29个不同的ML模型，用于识别异常**。最后，**我们在实验中测试了22个不同的数据集**

2、异常分为三大类[1]、[9]、[10]：

> **点异常**：**如果一个数据实例可以被认为是其余数据的异常，则该实例被称为点异常**，并被认为是最简单的异常形式。
>
> **上下文异常**：**如果在特定上下文中数据实例异常，但在另一个上下文中不异常，则称为上下文异常**。在某些情况下，识别上下文很容易，因此应用上下文检测技术是有意义的。
>
> **集体异常**：**如果一组关联的数据实例对于整个数据集是异常的，则称为集体异常**。

3、**统计异常检测技术是用于检测异常的一些最古老的算法**[10]。**统计方法为所提供的数据的普通行为建立统计模型。然后可以执行统计推断测试以检测实例是否属于该模型**。有几种方法用于进行统计异常检测[11]。这包括**基于邻近度的方法、参数方法、非参数方法和半参数方法**。

4、**机器学习（ML）技术越来越多地被用作检测异常的方法之一。**。**该技术被用来建立一个模型，区分普通和异常类**。

> **监督异常检测：**在这个类中，**正常和异常训练数据集都包含标记的实例**。在这个模型中，**方法是建立一个预测模型的异常和正常的类，然后比较这两个模型**。问题如下：**首先，与正常实例相比，训练集中异常的数量要低得多。其次，精确和代表性的标签是具有挑战性的识别，特别是对于异常类**。
>
> **半监督异常检测**：**这里的训练仅包括普通类案例**。因此，**任何不能被归类为普通的东西都被标记为异常**。。**由于它们不需要异常类标签，因此它们比监督方法更常见**。
>
> **无监督异常检测**：在这种情况下，**该方法不需要训练数据集**。因此，**这些方法意味着在测试数据集中，正常实例比异常实例更常见**。然而，**如果该假设失败，则导致该技术的高虚警率**。
>
> **许多半监督技术可以适于通过使用未标记的数据集样本作为训练数据而在无监督模式下操作**。**这种自适应假设测试数据中存在非常少的异常，并且这些异常对于训练期间的模型学习是鲁棒的**。

### 2、相关工作

1、**Albertola等人[1]提供了异常检测技术和应用的广泛调查。详细讨论了机器学习和非机器学习的不同技术**，同一作者介绍了**另一项关于离散序列异常检测主题的调查[10]**。此外，**Hodge和Austin [15]还对机器学习和统计异常检测方法进行了全面研究**。**文中对各方法的优缺点进行了比较**。另一方面，**Agrawal和Agrawal [8]提出了使用数据挖掘技术进行异常检测的综述**。

2、异常检测中最常用的计数分类：

![image-20240903195831062](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903195831062.png)

![image-20240903195752246](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903195752246.png)

### 3、机器学习技术类型

我们确定了28种ML技术，这些技术可分为六类：**分类、集成、优化、规则系统、聚类和回归**。这些ML技术以两种形式使用：**独立模型或混合模型**。表4显示了所收集的研究文章中ML技术的频率。**很多研究者过去常常将一种以上的ML技术结合起来。**。此外，**支持向量机是最常用的技术，无论是独立的还是在混合模型中**。

![image-20240903200952961](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903200952961.png)

**特征选择/提取**已经在文献中被广泛发现，并且它是朝着丢弃不相关数据的重要举措，这**有助于增强和提高所建议的模型的精度和计算效率**。图4展示了正在应用的21种不同的特征选择/提取技术。此外，**我们注意到PCA和CFS是异常检测中最常用的特征选择技术**。

![image-20240903201010569](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903201010569.png)

### 4、机器学习模型的总体估计和准确度

**估计精度是机器学习模型的主要性能指标**。本题重点关注以下四个方面的估计精度：**性能指标、精度值、用于构建的数据集和模型验证方法**。此外，**我们确定了22个不同的数据集**，这些数据集已用于相关文章的实验和许多其他一般数据集。**数据集可以被分类为合成数据、真实的生活数据和虚拟化数据**。此外，48篇研究论文使用**KDDCup 1999**虚拟数据集，**38篇研究论文采用基准数据集**。

![image-20240903201920698](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903201920698.png)

图6显示，**使用最多的性能指标是真阳性率（TPR）**，也称为灵敏度和召回率。**它测量被正确分类的异常**。此外，**116篇论文使用假阳性率（FPR）作为性能指标。该指标测量被错误分类的异常，也可以称为误报率**。此外，**准确度（Acc），精度和F-分数经常被研究人员作为性能指标**。**Acc是正确分类的异常百分比。此外，AUC测量整个ROC曲线下的整个二维面积**。**ROC曲线是用于有效评估入侵检测系统性能的最强指标之一，它是一种说明FPS准确性的图形工具**。另一方面，**精确度通常与F分数和召回率相关，它测量被正确分类为攻击的异常的比率**。此外，我们发现290篇论文中有64篇只使用了一个性能指标，**其中大多数论文只使用了准确性或AUC，这不足以确定ML模型的质量性能**。**另一方面，像A10和A69这样的论文使用7到9个性能指标来表示其ML模型的性能**。此外，**除了性能指标之外，许多论文还提出了计算性能指标，例如CPU利用率、执行时间、训练时间、测试时间和计算时间**。

![image-20240903202553328](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903202553328.png)

### 5、无监督、半监督或监督的异常检测技术的百分比

根据图7，**27%的选定论文应用了无监督异常检测类型，使其成为研究文章中使用最多的技术**。**另一方面，18%的人应用了监督异常检测，而7%的人同时应用了监督和非监督异常检测分类**。相比之下，**5%的研究文章采用了半监督学习。此外，1%的人应用半监督与非监督异常检测**。令人惊讶的是，**42%的研究文章没有提到他们应用的异常检测的分类类型**。

### 6、总结

我们展示了研究人员应用的**29种不同的ML模型**，其中**最常用的是SVM**。此外，我们注意到对**构建混合模型的兴趣****。此外，我们发现**PCA和CFS是21种特征选择/提取技术中最常用的**。在RQ 3中，我们介绍了每篇研究论文应用的性能指标，我们发现**290篇论文中有64篇使用准确性或AUC作为主要性能指标，这是不够有效的**。此外，**我们确定了22个不同的数据集，已被用于相关文章的实验以及许多其他一般的数据集**，**和大多数实验使用真实的生活数据集作为训练或测试数据集的模型**。最后，在RQ 4中，我们统计了所选研究文章中使用的异常检测分类类型。**我们发现27%的选定论文应用了无监督异常检测类型，使其成为研究文章中最常用的方法。其次使用最多的方法是应用监督异常检测，占18%，其次是7%的论文同时应用监督和非监督异常检测分类**。

## 五、《Deep Learning for Anomaly Detection: A Review》

本文对深度异常检测方法的研究进行了全面的分类，包括**3个高级分类和11个细粒度分类**。我们回顾了它们的**关键直觉、目标函数、基本假设、优缺点**。

### 1、本文的贡献点

> 1、分类和制定。我们将当前的深度异常检测方法制定为三个原则框架：**用于通用特征提取的深度学习，正常性的学习表示，以及端到端的异常得分学习**。一个层次分类法的基础上提出了**11个不同的建模角度的方法**进行分类。
>
> 2、综合文献综述。我们回顾了机器学习，数据挖掘，计算机视觉和人工智能，以全面的文献综述研究进展。为了提供深入的介绍，我们描述了**基本假设，目标函数，关键的直觉和它们的能力**，在解决上述一些挑战的所有类别的方法。
>
> 3、源代码和数据集。**我们征集了几乎所有类别的方法的公开源代码和大量具有真实的异常的真实数据集**，以提供一些经验比较基准。

### 2、问题复杂性

与大多数、规则或明显模式的问题和任务不同，**异常检测解决少数、不可预测/不确定和罕见事件，导致所有（深度和浅层）检测方法都存在一些独特的问题复杂性**：

> **不可知**。**异常与许多未知因素有关，突发行为、数据结构和分布未知的实例**。它们在实际发生之前是未知的，例如新的恐怖袭击、欺诈和网络入侵。
>
> **异常类。异常是不规则的**，因此，**一类异常可能表现出与另一类异常完全不同的异常特征**。例如，在视频监控中，异常事件抢劫、交通事故和入室盗窃在视觉上有很大的差异。
>
> **稀有和类不平衡**。异常通常是罕见的数据实例，与通常占数据绝大多数的正常实例形成对比。这导致在大多数应用程序中无法获得大规模标记数据。
>
> **各种类型的异常**。**点异常**是指相对于温度异常的个别情况。**条件异常**，又名上下文异常也指在特定上下文中的个别异常实例，即，数据实例在特定上下文中是异常的，否则是正常的。**群体异常，**又名集体异常是作为整个w.r. t异常的数据实例的子集。其他数据实例;集体异常的各个成员可能不是异常

### 3、现有的深度异常检测方法面临的挑战

> 1、**异常检测召回率低**。许多正常情况被错误地报告为异常，而真正复杂的异常却被遗漏了。当前最先进的方法，特别是无监督方法（例如，[17，84]），仍然经常在真实世界的数据集上产生高误报[20，115]。**如何减少误报和提高检测召回率是最重要但也是最困难的挑战之一，特别是未能发现异常的巨大代价**。
>
> 2、**高维和/或非独立数据中的异常检测**。**异常通常在低维空间中表现出明显的异常特征，而在高维空间中变得隐藏和不可察觉**。**在由原始特征或新构造的特征的小子集所跨越的降低的低维空间中执行异常检测是直接的解决方案**，例如，**在基于子空间[70，77，84，123]和基于特征选择的方法[12，109，111]中**。
>
> 3、**正常/异常的数据有效学习**。由于收集大规模标记异常数据的难度和成本，**完全监督的异常检测通常是不切实际的**，因为它假设具有正常和异常类别的标记训练数据的可用性。**在过去的十年中，主要的研究工作一直集中在无监督的异常检测，不需要任何标记的训练数据**。然而，**无监督方法不具有任何真实异常的先验知识。他们在很大程度上依赖于他们对异常分布的假设。另一方面，通常不难收集标记的正常数据和一些标记的异常数据。在实践中，经常建议尽可能利用这些易于访问的标记数据[2]**。因此，利用这些标记的数据来学习正常/异常的表达表示对于准确的异常检测至关重要。**另一个研究方向是弱监督异常检测，假设我们有一些异常类别的标签，但类别标签是部分/不完整的（即，它们不跨越异常类的整个集合），不精确（即，粗粒度标签），或不准确的（即，某些给定的标签可能是不正确的）**。两个主要的挑战是**如何学习表达正常/异常表示与少量的标记异常数据，以及如何学习检测模型**，被推广到新的异常发现的给定的标记异常数据。
>
> 4、**抗噪声异常检测**。**许多弱/半监督异常检测方法假设标记的训练数据是干净的，这可能容易受到错误地标记为相反类别标签的噪声实例的影响**。在这种情况下，我们可以使用无监督的方法，但这无法利用真正的标记数据。主要的挑战是，噪声的数量可能与数据集有很大的不同，并且噪声实例可能不规则地分布在数据空间中。
>
> 5、**检测复杂异常**。**现有的大多数方法都是针对点异常的，不能用于条件异常和群异常**，因为它们表现出与点异常完全不同的行为。这里的一个主要挑战是**将条件/组异常的概念纳入异常测量/模型**。另一个主要的挑战是，**一些异常只有在考虑两个或更多数据源时才能检测到**。
>
> 6、**异常现象解释**。在许多安全关键领域中，**如果将异常检测模型直接用作黑盒模型，则可能存在一些重大风险。缓解此类风险的一种有效方法是使用异常解释算法，提供有关特定数据实例被标识为异常的原因的直接线索**。然后，**人类专家可以调查并纠正这种偏见**。在一些应用中，提供这样的解释可能与检测准确性同样重要。**大多数异常检测研究只关注检测的准确性，而忽略了对已识别异常的解释能力**。

**深度方法可以实现整个异常检测管道的端到端优化，并且还可以学习专门为异常检测定制的表示。这两种能力对于应对上述六大挑战至关重要，但传统方法不具备。**

### 4、深度异常检测的分类

**从建模的角度将深度异常检测方法分为三个主要类别和11个细粒度类别**。方法分类的概述如图1所示。具体来说，深度异常检测由三个概念范式组成-**用于特征提取的深度学习，学习常态的特征表示和端到端异常得分学习**。

![image-20240903211755055](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903211755055.png)

#### 4.1 用于特征提取的深度学习

1、**这类方法旨在利用深度学习从高维和/或非线性可分离的数据中提取低维特征表示，用于下游异常检测**。特征提取和异常评分是完全脱节的，彼此独立。因此，深度学习组件仅作为降维工作。**与异常检测中流行的降维方法（如主成分分析（PCA）[21，140，180]和随机投影[80，112，123]）相比，深度学习技术在提取语义丰富的特征和非线性特征关系方面表现出更好的能力[14，49]**。深度学习模型提取的特征表示保留了有助于将异常与正常实例区分开的区分信息。

2、**一条研究路线是直接使用流行的预训练深度学习模型，如AlexNet [75]，VGG [143]和ResNet [58]来提取低维特征**。此外，与许多其他任务类似，**从在源数据集上预训练的深度模型中提取的特征表示可以被转移到目标数据集上微调异常检测器**。这一类别中的**另一个研究方向是明确地训练深度特征提取模型，而不是用于下游异常评分的预先训练的模型**[44，65，163，168]。

3、**优势是**(i)大量最先进的（预先训练的）深度模型和现成的异常检测器是现成的。(ii)深度特征提取比常用的线性方法具有更强的降维能力。(iii)由于深层模型和检测方法的公开可用性，该方法易于实现。**缺点是**(i)特征提取和异常评分完全脱节，往往导致异常评分不理想。(ii)预先训练的深度模型通常限于特定类型的数据。

#### 4.2 学习正态性的特征表征

**这类方法在某种程度上将特征学习与异常评分相结合，而不是像上一节那样完全解耦这两个模块**。这些方法通常分为两类：**通用特征学习和异常度量相关特征学习**。

##### 4.2.1 通用特征学习

**这类方法通过优化并非主要针对异常检测设计的通用特征学习目标函数来学习数据实例的表示，但学习的表示仍然可以增强异常检测**，因为它们被迫捕获一些关键的底层数据。此类方法代表性技术有**自动编码器（AE）、生成性对抗网络（GAN）和自监督模型分类。

1、**自动编码器的优点如下**。

> (i**)不良事件的概念是直接的，对不同类型的数据是通用的**。
>
> (ii)可以利用**不同类型的强大AE变体来执行异常检测**。

它们的**缺点**如下。

> (i)**所学习的特征表示可能由于训练数据中的不频繁的规则性和离群值或异常的存在而有偏差**。
>
> (ii)**数据重构的目标函数是针对降维或数据压缩而设计的，而不是异常检测**。结果，所得到的表示是底层规则性的一般概括，其对于检测不规则性不是最佳的。

2、**生成式对抗网络的优点如下**。

> (i)GAN已经证明了在**生成真实实例方面的上级能力，特别是在图像数据上**，使得能够检测到从潜在空间重构较差的异常实例。
>
> (ii)**大量现有的基于GAN的模型和理论[32]可适用于异常检测**。

**缺点**。

> (i)遗传神经网络的训练可能会遇到多种问题，例如**无法收敛和模式崩溃**[99]，这导致了在训练基于遗传神经网络的异常检测模型时存在很大的困难。
>
> (ii)**生成器网络可能会被误导，并生成正态实例流形之外的数据实例**，特别是当给定数据集的真实分布是复杂的或者训练数据包含意外的离群值时。
>
> (iii)**基于GAN的异常评分可能是次优的，因为它们是建立在生成式网络上的，其目的是为数据合成而不是异常检测而设计**。

3、**自监督分类的优点如下**。

> (i)**它们在无监督设置与半监督设置下都能很好地工作**。
>
> (ii)**异常评分的基础是梯度幅度及其更新的一些固有特性**。

**它们的缺点如下**。

> (i)特征变换操作通常与数据相关。**上述变换操作仅适用于图像数据**。
>
> (ii)**虽然分类模型是以端到端的方式训练的，但是基于一致性的异常分数是基于分类分数而不是优化中的集成模块导出的，因此它们可能是次优的**。

##### 4.2.2  异常度量相关特征学习

异常度量相关特征学习的目的是**学习针对一个特定的现有异常度量进行专门优化的特征表示**。此类方法代表性技术有**基于距离的度量，基于单类分类的度量和基于聚类的措施**。

1、**基于距离的度量的优点如下**。

> (i)基于距离的异常是简单明了的，**并且在文献中有丰富的理论支持**。因此，基于深度距离的异常检测方法可以在已有的相关工作中打下坚实的基础。
>
> (ii)**该方法工作在低维表示空间，能够有效地处理传统的基于距离的异常测度所不能处理的高维数据**。
>
> (iii)**他们能够学习专门为自己量身定制的表征**。

**它们的缺点如下**。

> (i)大多数基于距离的异常度量**所涉及的大量计算**可能是将基于距离的异常度量结合到表示学习过程中的障碍。
>
> (ii)它们的能力可能受到**基于距离的异常测量的固有弱点**的限制。

2、**基于单类分类的度量的优点如下**。

> (i)**基于一类分类的异常在文献中有很好的研究**，并且为基于一类分类的深异常方法提供了坚实的基础。
>
> (ii)表示学习和单类分类模型可以被统一以学习定制的和更优的表示。
>
> (iii)在传统的一类模型中，它们将用户从手动选择合适的核函数中解放出来。

**它们的缺点如下**。

> (i)**在正态类内具有复杂分布的数据集中，一类模型可能无效**。
>
> (ii)**检测性能取决于基于单类分类的异常度量**。

3、**基于聚类的措施的优点如下**。

> (i)**大量的深度聚类方法和理论**可以用来支持异常检测的有效性和理论基础。
>
> (ii)与传统的基于聚类的方法相比，**基于深度聚类的方法学习特别优化的表示，这有助于比在原始数据上更容易地发现异常，特别是在处理复杂数据集时**。

它们的**缺点**如下。

> (i)异常检测的性能在很大程度上依赖于聚类结果。
>
> (ii)聚类过程可能由于训练数据中的污染异常而有偏差，这又导致较低效的表示。

#### 4.3 端到端异常评分学习

该研究线旨在**以端到端的方式学习标量异常分数。与依赖于异常度量的特征学习相比，这种方法中的异常评分不依赖于现有的异常度量;它具有直接学习异常评分的神经网络**。下面我们回顾这一类别中的四种主要方法：**排序模型、先验驱动模型、软最大似然模型和端到端一类分类模型**。该框架的关键是将顺序或判别信息纳入异常评分网络。

##### 4.3.1 排序模型

1、**这组方法旨在直接学习排名模型**，以便可以根据与异常的绝对/相对排序关系相关的可观察有序变量对数据实例进行排序。异常评分神经网络是由可观察的有序变量驱动的。假设是**存在一个可观察到的有序变量，可以捕捉到某些数据异常**。

2、**基于模型的深度排序方法的优点如下。**

> (i)异常分数可以直接用适应的损失函数来优化。
>
> (ii)它们通常不受异常定义的限制，因为它们对异常和正常实例之间的有序顺序施加了一个弱假设。
>
> (iii)这种方法可以建立在诸如学习排名等领域的成熟的排名技术和理论的基础上[85，87，158]。

3、**它们的缺点如下。**

> (i)在这些方法中**至少需要某种形式的标记异常**，这可能不适用于这样的标记异常不可用的应用。[117]中的方法是完全无监督的，并且获得了一些有前途的性能，但是与半监督方法相比仍然存在很大的差距。
>
> (ii)由于模型被专门地拟合以检测少数标记的异常，因此它们可能**不能推广到表现出与标记的异常不同的异常特征的看不见的异常**。

##### 4.3.2 先验驱动模型

##### 4.3.3 Softmax Likelihood Models

##### 4.3.4 端到端单类分类

### 5、算法和数据集

#### 5.1 代表性算法

![image-20240905154608876](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154608876.png)

![image-20240905154706461](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154706461.png)

#### 5.2 具有真实异常值的数据集

**异常检测发展的一个主要障碍是缺乏具有真实的异常的真实世界数据集**。许多研究（例如，[3，48，103，132，157，170，175]）因此评估了他们提出的方法在从流行分类数据转换的数据集上的性能。这种方式可能无法反映在现实世界中的异常检测应用的方法的性能。我们在表3中总结了**21个公开可用的具有真实的异常的真实世界数据集的集合**，以促进对这些数据集的性能评估。这些数据集涵盖了以各种数据类型呈现的广泛的流行应用领域。这里**只包括大规模和/或高维复杂数据集**，为深度异常检测提供具有挑战性的测试平台。此外，**在https://git.io/JTs93上提供了广泛使用的异常检测数据集**（包括表3中的一些预处理数据集）的持续更新集合。

![image-20240905154951383](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154951383.png)

## 六、《Outlier Detection: Methods, Models, and Classification》

### 1、异常值定义和分类

1、离群值通常基于以下假设定义[21]：

> **（1）离群值在其特征方面不同于正常值;**
>
> **（2）与正常实例相比，离群值在数据集中是罕见的**。

2、**anomalies表明了一种不同的潜在生成机制。相比之下，Outliers往往强调统计稀有性和偏差，而它们是否由不同的机制产生并没有直接说明**。在统计学和机器学习的某些情况下，**outliers是指那些使模型更难拟合的数据实例**。**在监督学习中，anomalies是更好的术语，因为有可靠的指导来建模异常的生成机制**。相比之下，由于缺乏可靠的指导，**无监督学习方法通常依赖于数据的内在分布或结构，以测量偏离规范的程度，希望发现的离群值代表感兴趣的异常**。

3、基于构成异常模式所涉及的数据实例的数量，存在**（1）点离群值和（2）集体离群值[14]**。点异常值是指与数据集的其余部分有很大偏差的单个数据实例。集体离群值是相对于整个数据集的其余部分出现异常的数据实例的集合。根据比较的范围，**点异常值可进一步分为（1）局部异常值和（2）全局异常值**。局部离群值的检测依赖于特征差异（例如，邻域密度的差异），而全局离群值解决整个数据集的差异。

根据输入数据的类型，离群值可以分为**（1）矢量离群值和（2）图形离群值[24]**。**向量离群点是指向量类多维数据，而图离群点存在于图数据中**。**类向量数据点有多个属性，每个属性都有一个数值或一个分类值**。**图形数据中的异常值可以是点异常值（例如，节点离群值和边缘离群值）或集体离群值（例如，子图异常值）**[24]。

### 2、方法分类和讨论范围

1、我们将方法分为**基本方法和高级方法**，这是基于高级方法是在基本方法的基础上发展起来的。以应对新的挑战。这些挑战包括**高维数据（“维数灾难”）、无界和动态数据流、分布式环境中的大数据以及有效使用非常有限的标记数据**。根据这些方法所使用的基本技术，**基本方法进一步分为基于邻近的方法和基于投影的方法**。为了避免复杂性和混乱，**我们统一了“基于距离”和“基于密度”类别的方法，并将它们置于“基于最近邻”的保护伞下**。这是因为它们都涉及最近邻的概念。然而，**本文中讨论的基于密度的数据流方法都是在LOF [23]之上开发的**。

![image-20240905162152003](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905162152003.png)

### 3 基于邻近度的方法

**基于邻近度的方法基于离群值与附近数据点的关系来识别离群值。一种常见的情况是离群值位于稀疏区域，在给定距离内只有很少的数据点，或者最近的数据点非常远。**

#### 3.1 最近邻方法

有两种主要的方法来定义邻域：**k最近邻（k-NN）和以数据点为中心的预定半径内的邻域**。

![image-20240905162832856](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905162832856.png)

1、Ramaswamy等人[41]的方法使用与第k个最近邻居的距离作为离群值得分。Angiulli等人[41]的方法使用到k-NN的距离之和[42]。Knorr等人[31]依赖于数据点的预定半径内的相邻点的数量。**由于异常程度是在整个数据集的上下文中进行比较的，因此这些方法检测全局离群值**。他们假设数据集不同区域的密度是均匀的。

2、**考虑到不同密度的方法往往优于它们[22]。后一种方法侧重于局部离群值。LOF [23]是一种著名的方法，它首先引入了局部离群值的概念。基于连通性的离群因子（COF）[36]解决了LOF的缺点。Papadimitriou等人[37]基于局部密度的定义提出了局部相关积分（LOCI）。受影响的离群值（INFLO）[38]使用反向最近邻集（k-RNN）与k-NN相结合来计算离群值得分。[39]提出了局部离群值概率（Loop）。Loop试图解决其他方法面临的困境：如何选择合适的离群值阈值来区分离群值和内点**

3、基于子采样，使用**最近邻包络（iNNE）[40]**的隔离创建隔离区域以确定离群值分数。**LeSiNN [16]**是另一种离群值检测方法，也可以使用子采样构建模型。**iNNE和LeSiNN都具有线性时间复杂度，此外，iNNE和LeSiNN都使用集成来确保离群检测器的稳定性**

4、**与基于聚类的方法相比，基于最近邻的方法在离群点分析上具有更精细的粒度的优点。这使得基于最近邻的方法能够区分强离群值和弱离群值，而弱离群值更有可能被视为噪声[22]。由于成对距离的昂贵计算，高的计算复杂度通常作为代价而出现。此外，k的选择对整体性能有着巨大的影响。使用二次采样是将时间复杂度降低到线性的好方法。二次采样还有助于实现上述掩蔽效应。新的问题是如何确定合适的样本大小和集合大小。**

#### 3.2 基于聚类的方法

基于聚类的离群点检测算法通常分为两步：**首先用聚类算法对数据进行分组，然后根据聚类结果分析数据的偏离程度。不属于任何聚类的数据点被认为是离群值**。除了聚类成员（无论是否在聚类中），还有两个其他常用的聚类相关量来构建离群值。**第一个是到聚类中心的距离，假设正常数据点靠近聚类中心，而异常值远离它们。第二个是簇的基数，假设正常数据点的簇是密集和大的，而离群数据点的簇是稀疏和小的。与基于最近邻的离群点检测方法相比，基于聚类的离群点检测方法的一个主要优点是检测效率高**。

![image-20240905164918032](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905164918032.png)

1、**Jiang等人[44]提出了一种离群点检测方法，该方法基于改进的k均值聚类和从聚类中心构建的最小生成树**。**基于聚类的局部离群值因子（CBLOF）[46]是一种基于聚类的离群值检测方法，通过定量测量区分小聚类和大聚类**。**在Amer等人的后期工作中。[47]，证明了简单地去除CBLOF的簇基数可以产生更好的结果**。**CBLOF和LDCOF都具有独立于框架的合并的聚类算法。但正如[47]所建议的，具有固定数量的聚类（如k-means）的算法在性能上是有利的，并且由于潜在的非球形分布，建议高估聚类数量**。**Du等人。[17]设计了一种基于密度峰值聚类算法的局部离群值检测方法[48]，这是一种简单但有效的基于密度的方法，可以检测任意形状的聚类**。

#### 3.3 基于预测的方法

**本节是各种投影技术的方法**（例如，随机投影[50]、LSH [29]等）为了**将原始数据转换到具有降低的维度或复杂度的新空间中，同时仍然保留邻近信息**（例如，成对欧几里德距离、最近邻关系等）在一定程度上是原始数据集。**然后可以在投影空间中执行离群点检测，从而大大改善了执行时间**。表3是本节介绍的各种方法的摘要。它们中的许多非常有效，也适用于高维数据。值得注意的是，**子空间技术也是一种直接投影**。**它们已被广泛用于解决高维数据的挑战**。

![image-20240905165736586](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905165736586.png)

**1、投影索引最近邻（PINN）[51]基于随机投影方案来降低数据维度，随机投影优于其他降维技术（如PCA [57]）的优点是其效率。局部敏感离群值检测（LSOD）[52]利用局部敏感哈希（LSH）[29，53]来创建离群值的初始排名，LSOD集成了许多基于距离的离群值检测的修剪策略，包括PPSN [41]，ANNS [41]和PPSO [61]。Schubert等人提出了另一种基于投影的离群值检测算法[54]。此外，他们提供了一个分布式框架来扩展算法。Loda [55]采用稀疏随机投影线，Loda遵循了集合的精神，并演示了如何将多个弱离群值检测器组合在一起，从而产生非常好的结果**

#### 3.4 基于树的方法

**从广义上讲，树模型的构建也可以被视为一种投影，其中原始数据点被映射到特定的树节点，并且这些树节点包含关于原始数据的邻近信息**。**柳塔尔。[28]开发了Isolation Forest，它是一种无监督的树集成**。**Hariri等人[56]提出了扩展隔离森林来解决隔离森林的缺点**。

### 4、高维离群点检测技术

高维数据实现效率的困难主要归因于两个原因。首先，**由于增加的维度，相似性搜索（诸如k-NN搜索）在计算成本方面变得更昂贵**。其次，**一些用于加速离群值检测的技术，如采样[66，67]，修剪[68]，排名策略[38，69]和有效的索引结构（R树[58]，X树[59]等），不适用**。与这个问题相关的一个常用术语是**“维数灾难”[34，70-72]**。**这种现象是由大量“正常噪声”不相关维度/属性的稀释效应引起的[22]**。**为了提高高维数据离群点检测的效率，Ghoting等人。[73]提出了递归分箱和重投影（RBRP）**。RBRP受到ORCA [68]的启发，ORCA是一种嵌套循环离群值检测方法，其离群值得分基于到第k个最近邻居的距离。

![image-20240905173128567](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905173128567.png)

1、请注意，第3节中提到的**投影索引最近邻（PINN）[51]算法也旨在提高高维离群值检测的效率**。更多的工作在文献中**集中在高维离群检测问题的有效性方面**。Kriegel等人。**[74]引入了一种基于角度的离群值检测方法（ABOD），以解决基于欧几里得距离的算法在面对高维数据集时遇到的质量恶化的问题**。因此这会导致昂贵的**O（n3）时间复杂度**。为了降低时间复杂度，引入了两个近似变体：**FastABOD和LB-ABOD**。FastABOD将离群值得分计算的数据点对的选择限制在数据点的k-NN。**LB-ABOD是ABOD的一个下界近似，其目的是有效地获得具有最高分数的顶级离群值**。

2、许多作品探索**子空间的解决方案**，以处理“维数灾难”的影响。**Kriegel等人。[75]开发了一种离群值检测模式**，该模式基于单个数据点与由一组参考点跨越的轴平行超平面的偏差来评估离群值。**[76]提出了一种测量子空间对比度的方法，并相应地提出了一种称为高对比度子空间（HiCS）的子空间搜索方法**。**Sathe等人。[77]提出了RS-Hash，这是一种基于随机散列的非常有效和准确的子空间离群值检测方法**。

3、**除了上述方法，近年来其他有趣的工作包括：HighDOD [80]，使用动态子空间搜索方法和基于样本的学习过程; LODES [81]，依赖于一种新的基于局部密度的谱嵌入来识别非线性子空间中的离群值; RAMODO [82]使用表示学习来降低维度，并将其与基于随机距离的方法相结合[16]**。

### 5、分布式异常检测技术

**将离群值检测扩展到分布式环境的一个具有挑战性的任务是在保证准确性的同时最大限度地减少通信开销。这个任务对于需要计算数据点之间的成对距离的方法来说尤其困难**。值得注意的是，除了随后介绍的算法之外，**一些专注于分布式k-NN搜索的工作[105-109]可以为基于分布式k-NN的离群点检测算法的开发提供启发**。

![image-20240905175602124](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905175602124.png)

1、**Bhaduri等人。[110]开发了DOoR，这是ORCA方法[68]的分布式解决方案。Angiulli等人。[111]将SolvingSet算法[112]扩展到分布式环境。Bai等人[115]提出了LOF的分布式解决方案。分布式Top-N LOF（DTOLF）[114]为参考文献[116]中提出的Top-N LOF方法提供了分布式解决方案。Tsou等人。[12]提出了一种分布式无监督异常检测框架**。

### 6、基于深度学习的异常检测技术

**通过假设离群值实例更难以由训练的自动编码器重建，利用自动编码器进行离群值检测的一种简单方法是使用重建误差作为离群值得分[124]**。然而，由于在**无监督设置中训练数据可能被离群值污染**，由于其对离群值的敏感性和可能的过拟合，模型的有效性可能会显着减弱。

![image-20240909184100815](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909184100815.png)

1、**为了解决当训练数据包含离群值时自动编码器对过拟合的敏感性，Chen等人。[121]提出了一种基于集合的离群值检测方法，该方法将一组自动编码器的结果与连接架构中的多样性相结合**。

2、**鲁棒深度自动编码器（RDA）[18]通过将输入数据分为两个矩阵来解决受污染的训练数据问题，一个包含离群值，另一个由自动编码器有效重建。这个想法受到鲁棒主成分分析的启发[125]**

3、**Schlegl等人[122]设计了AnoGAN，旨在检测图像数据中的异常作为疾病标记**。**另一种基于GAN的异常检测方法是逆向学习异常检测（ALAD）[123]**。类似于AnoGAN [122]的想法，ALAD也依赖于GAN来对正常实例的分布进行建模，并且由此产生的异常分数基于重建误差。

4、**[82]提出了一种基于深度神经网络的框架，称为RAMODO**，用于学习由与目标离群值检测器相关的损失函数指导的离群值检测表示

将深度神经网络应用于离群值检测的主要优势是能够从复杂和高维数据中提取代表性特征，与传统方法相比，它可以提供更准确的结果。然而，**通常需要大的数据量才能让深度神经网络避免过拟合**。此外，**许多基于深度学习的方法对超参数非常敏感**。调整超参数以获得最佳性能可能是一项具有挑战性且耗时的任务

### 7、人在环的异常检测技术

如果标记的数据被适当地利用来调整现有的模型，则原始无监督技术的准确性可以显著提高。**一种典型方法是通过主动学习**[135]：初始模型建立在未标记数据上，基于此，**一些数据实例通过一些查询策略被领域专家标记**。然后用新获取的标签信息更新模型。这种类型的反馈循环可以迭代地进行，直到满足某些标准。

1、**在Görnitz等人的工作中。[136]，异常检测被认为是一个名为支持向量数据描述（SVDD）的优化问题[137]**。**Das等人。[27]提出了一种半监督方法，该方法将专家反馈迭代地结合到称为Loda [55]的集成异常检测方法的模型中**。**Vercruyssen等人[11]描述了一种半监督异常检测方法**。**Siddiqui等人。[139]提出了一种用于异常检测的通用算法，旨在通过结合专家反馈将异常分数与应用程序特定的兴趣度对齐**。

## 七、《Evaluation of Machine Learning Algorithms for Anomaly Detection》

1、我们评估了12种机器学习（ML）算法在网络实践中检测异常行为的能力。该评估是在三个公开的数据集上进行的：**CICIDS-2017，UNSW-NB 15和工业控制系统（ICS）网络攻击数据集**。

**KDD CUP 99 [26]已经过时**，因为网络流量是在1998年生成的，不能反映新的网络结构和攻击动态，**CICIDS2017 [29]和UNSWNB 15 [30]被用来评估我们当前论文中的12种ML算法**。这是因为这些数据集包含了广泛的当前攻击场景，符合现实世界的标准。

评价结果表明，**随机森林（RF）算法在所有数据集上的准确度、精确度、召回率、F1评分和受试者工作特征（ROC）曲线方面均达到最佳性能**。在本研究中，我们评估了六个经典的监督ML算法和六个深度学习算法。所选的经典ML算法有**Logistic回归、朴素贝叶斯、K邻近（KNN）、决策树（Decision Tree）、自适应增强（Adaptive Boosting）和随机森林（RF）**。我们选择的深度学习算法包括**卷积神经网络（CNN）、卷积神经网络和长短时记忆（CNN-LSTM）、长短时记忆（LSTM）、门控递归单元（Gated Recurrent Units，GRU）、简单递归神经网络（Simple Recurrent Neural Network，RNN）和深度神经网络（Deep Neural Network，DNN）**。

![image-20240905193120233](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905193120233.png)

2、使用七个评估矩阵来衡量所选ML算法的性能，即**准确度**，**精确度**，**真阳性率**（TPR），也称为召回率，**假阳性率**（FPR），**F1分数**，**受试者操作特征（ROC）曲线**和**混淆矩阵**。

![image-20240905194109674](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905194109674.png)

## 八、《A critical overview of outlier detection methods》

1、离群值与噪声数据有很大的不同，而噪声是无用的，必须被去除，**离群值可以提供无用和有趣的（例外）信息**。换句话说，**离群值是极端偏离数据集的定义良好的规范或预期行为的给定概念的数据实例**。

### 1、离群值检测算法

#### 1.1 基于统计的检测算法

提出了**参数和非参数方法**，这些方法需要两个阶段来完成离群点检测过程，即**训练阶段和测试阶段**。在训练阶段，数据集中的所有数据实例都基于给定的统计模型进行训练。然而，测试阶段涉及检测数据实例是否适合模型，即离群值检测。**参数方法在我们已经知道数据分布的情况下使用**，在参数方法中，我们可以提到**基于高斯和基于回归的方法**。

##### 3.1.1 基于高斯的方法

**箱形图[3]和均值-方差**是基于高斯的方法中最常用的技术。**乔马湖，加-地等人[4]提出了一种使用箱形图识别单变量和多变量离群值的方法**。

##### 3.1.2 基于回归的方法

为了处理大数据集，Rumseeuw和Driessen [5]提出了一种新的回归方法，称为**LTS回归算法**。。**FAST-LTS方法使用不同的节省时间的方法**：集中步骤（C-步骤），选择性迭代和嵌套扩展。

##### 3.1.3 无参数的方法

**直方图和基于核的方法**是最著名的非参数离群点检测方法。Markus G.和Andreas D.[7]叫做**HBOS算法**。**为每个单个元素构建单变量直方图，然而对于数值元素，可以构建两种类型的直方图：静态箱宽度直方图和动态箱宽度直方图**。**Longin J.L.等[8]提出的方法**可以被认为是一种统计检测方法，也可以被认为是一种基于密度的检测方法，因为它使用非参数核来估计数据实例的密度。

**统计检测方法**在给出概率分布模型时显示出有效的实验结果，但**在应用于大数据集时具有高计算成本和维数灾难**。因此，这些方法不能应用于大型和高维数据集。这些技术的**另一个缺点是它们不适用于分布未知的数据集**。

#### 1.2 基于距离的检测算法

**通过基于各种距离相关度量计算所有数据对象之间的距离来检测离群值。之后，没有足够邻居的对象最有可能是离群值。最近邻方法是最常用的方法。**

1、**解集方法由Fabrizio A.等[9]提出**，为了计算ODP求解集，已经开发了三种算法，**SolvingSet算法，RobustSolvingSet算法和MinimalRobustSolvingSet算法**。**[10]提出了一种称为基于角度的离群值检测ABOD方法的新方法，该方法仍然使用距离，但也考虑所有数据对象的角度方差**。**另一种基于距离的算法LDOF由[11]引入**。**基于距离的方法似乎是有效的，因为它们独立于数据分布，易于实现**。然而，它们**在高维数据集中仍然表现不佳**。**ABOD是唯一讨论过的克服这个问题的技术**。**ABOD不能适当地识别低密度周围区域中的离群值**。

#### 1.3 基于密度的检测算法

我们可以提到**LOF和INFLO作为基于这种技术的众所周知的方法**。**LOF方法需要良好分离的聚类以便良好地执行**，否则它会遭受错误的离群值得分。**[13]提出了另一种基于对称邻域关系的离群点检测方法INFLO**。

#### 1.4 基于聚类的检测算法

**DBSCAN的有效性依赖于Martin E.等人**，直接密度可达性概念（见定义1）、密度可达性概念（见定义2）以及最后密度连通性概念（见定义3）。**[17]提出了一种新的无监督离群点检测和聚类改进的方法，通过发展ODC算法**，该算法通过使用众所周知的K均值的修改版本来检测离群值。**将该算法与FindCBLOF和ORC离群点检测方法进行了比较，以确认其质量。ODC在离群点检测和聚类精度方面表现出更好的性能**。[20]提出了一种基于离群点比内点（正常对象）更难识别的思想的异常检测精确排序方法OF算法。**[21]提出了基于聚类的离群点检测（CLOPD）算法**，该算法也是为了检测医学数据中的异常。[22]**在现有的离群点检测算法中，几乎都存在top-n参数问题**，这意味着算法需要一个参数n来指定离群点的个数。他们开发了**ROCF算法，在算法6中描述，它不需要这个参数**。

### 2、总结

**基于统计的方法对于给定的分布模型可能是有效的，但当该分布未知时，它们不能应用。基于距离的方法克服了这个缺点，并且不依赖于数据分布，但是它们在多变量和高维数据中可能非常昂贵。基于密度的方法更有效，但它们仍然不适合大型数据集和数据流。此外，基于聚类的方法虽然可以处理数据流，但仍然需要太多的参数。**

## 九、《A comprehensive survey of anomaly detection techniques for high dimensional big data》

### 1、相关工作

**Agrawal和Agrawal [9]提供了各种异常检测技术的综述，目的是对各种异常检测方法进行基本了解**。**Albertola等人[11]介绍了用于各种应用的几种异常检测技术的调查。Hodge和Austin [7]通过比较技术的优点和缺点，对离群值检测技术进行了调查**。也可以观察到各种其他调查，例如Gama等人[15]，Gupta等人[16]，Heydari等人[17]，Jindal和Liu [18]，Pathasarathy [19]，Phua等人[20]，Tamboli等人[21]和Spirin等人[22]，这些调查进一步突出了**异常检测或高维数据中的问题**。**Zimek等人。[23]详细介绍了高维数值数据中异常检测的专用算法;他们还强调了维数灾难的重要方面。Parsons等人。[24]对高维数据的各种子空间聚类算法进行了调查，并讨论了可以使用这些算法的一些潜在应用**。目前，**还没有一项调查直接强调了大数据中的异常检测和高维性问题**。

![image-20240906153027280](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906153027280.png)

### 2、高维问题

**如果一个数据集有n个样本和m个维度（或特征），那么这个数据可以被称为m维数据。一般来说，当维数m导致“维数灾难”的影响时，数据集可以被称为高维数据集。**

### 3、解决高维问题的传统模型

**许多算法建立在接近度的概念上，Aggarwal [28]提出，几乎任何主要基于邻近概念的技术都会在高维空间中质量下降，因此需要以更有意义的方式重新定义。**

#### 3.1 基于距离的技术

Angiulli和Pizzuti [30]提出了一种基于距离的异常检测技术，称为“HilOut”，用于检测大型和高维数据集的前n个离群值，该方法扩展性良好。**Koufakou和Georgiopoulos [61]提出了一种异常检测策略，其中通过非常接近线性的分布式版本来实现加速**。他们称这种方法为“快速分布式”

#### 3.2 基于聚类的技术

#### 3.3 基于密度的技术

**[62]介绍了一种用于估计高维数据中的度量的密度估计器，并将其应用于识别数据分布变化的问题**。

#### 3.4 基于分类的技术

一些机器学习技术是基于这样的假设，**即可以通过将数据投影到较低维空间上来实现维度缩减，在该较低维投影之后，学习可能更容易[65，66]**。基于降维策略的技术将数据投影到较低维度的子空间[8]或PCA [7，67，68]上，如在以下部分中所讨论的。

![image-20240906172326849](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906172326849.png)

#### 3.5 解决高维问题的策略

**如上所述，已经提出了许多降维方法，例如PCA，MDS，Karhunen-Loeve变换，局部线性嵌入，拉普拉斯特征映射和扩散映射，以实现降维[51，70-74]**。**这些数据表示的内在维度小于可用的相关维度。已经提出了许多技术来测量内在维度[75-80]**。

1、**Wang等人。[86]提出了一种PCA以及可分离压缩感知**，以识别不同的矩阵。**压缩感知（或压缩采样[CSG]）理论由Candes和Wakin [87]提出**。**使用基于PCA的降维方法的主要缺点是它们可能导致显著的信息损失，PCA识别属性之间的隐藏线性相关性[73]。如果数据集的属性是非线性的或不相关的，PCA可能会导致复杂的，并且可能无法解释的假阳性**。

2、**子空间是数据集维度的子集，其使用的维度空间小于完整的维度空间**。**异常只能在数据的低维子空间或具有缺失属性的数据集中识别[8]**。**同时找到相关的子空间和低维空间。同时发现起着至关重要的作用，因为不同的维度子集与不同的异常相关**。多个子空间的发现是重要的，因为选择单个或仅几个相关子空间可能导致不可预测的结果[28]

3、**Lazervic和Kumar [92]提出了一种模型，该模型使用称为“特征装袋”的评分系统来检测异常**。这导致不相关维度的增加。为了解决这个问题，**Kriegel等人。[23]采用了一种技术来选择信息或相关维度**。**[93]提出了一种名为“OUTERS”的子空间方法**，这是一种通过引入一种新的评分算法来对异质高维数据中的异常进行排名的方法。Zhang等人。**[94]提出了一种基于角度的子空间离群点检测方法**。**Thudumu等人。[41]提出了一种检测离群值的方法**，通过使用Pearson相关系数（PCC）和PCA将高维空间分叉为局部相关和低维子空间。**Koufakou和Georgiopoulos [61]提出的另一种算法称为混合属性数据集的离群值检测（ODMAD）**。他们的结果表明，分布式版本的ODMAD的速度接近线性加速与计算中使用的节点数量**。混合属性由Ye等人提出。[95]，他们提出了一种离群点检测算法**，通过计算异常子空间结合信息熵来检测高维混合属性数据集中的异常

#### 3.6 高维大数据异常检测带来的独特挑战

解决高维问题的最常见策略是定位最重要的维度（即，特征子集），称为变量选择方法，或者将结合维度组合成一组较小的新变量，称为降维方法[73]。高维问题的挑战如下：

![image-20240906174436695](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906174436695.png)

**Fabien和Kelloer [100]提出通过计算在真实的数据集上评估的高对比度投影的分数来提高传统异常排名的质量**，从而估计子空间的对比度。**Tomasev等人。[102]通过评估频繁出现的点（称为枢纽）来解决高维数据中的聚类问题**。**Radovanović等人[103]使用数据点提供了有用的见解，称为反枢纽**。

#### 3.7 高维大数据中的工具

许多分布式计算框架，如**Apache Hadoop [134]，Apache Storm [135]，Apache Spark [136]，Apache Flink [137]和MXNet [138]**都是为了满足不断增长的大数据需求而开发的。**这些框架中的大多数都有内部机器学习（ML）库，Apache Spark拥有比其他任何框架都强大的ML库[139]**。

1、Koufakou等人[140]提出了一种快速并行异常检测方法。**Leung和Jiang [36]报告了一种解决方案，该方案利用MapReduce挖掘不确定的大数据**。**Jiang等人[141]报告了一种基于树的技术BigSAM**。He等人[32]提出了一种基于KD树的异常识别技术的并行应用。**Apache Spark（Spark）[136]是另一个基于MapReduce的分布式框架**，用于在分布式系统上处理大量数据，然而，**它有一个称为内存计算的功能**[159，160]。**与MapReduce两阶段范式相比，Spark的内存计算模型旨在提高处理批量和实时工作负载的速度和可扩展性**。**Terzi等人[143]提出了一种使用Apache Spark作为分布式框架的无监督方法**。Zhang等人[144]开发了一个基于Apache Storm的框架。Veen等人。[161]专注于使用基于Apache Storm的公共云虚拟机的流媒体分析平台的弹性。

2、**MXNet是一个开源、可扩展、内存高效、高性能的模块化深度学习框架，为C++、Python、Matlab和R等编程语言提供了一系列应用程序编程接口（API）**。**它运行在异构系统上，从移动的设备到分布式GPU集群[162]**。**Abeyrathna等人。[145]提出了一种基于异常提议的方法**，可以使用MXNet框架建立实时火灾检测的有效架构。**Apache Flink [137]提出了另一个开源框架**，结合了其他分布式范例（如MapReduce [163，164]）的可扩展性和编程灵活性。**Toliopoulos等人。[146]进行了基于距离的离群值检测工作**，并使用三个真实世界和一个合成数据集在大规模并行设置中进行了检查。**他们考虑了三个主要的并行流媒体平台，如Apache Storm，Apache Spark和Apache Flink**。**García-Gil等人[139]对两个框架Apache Spark和Apache Flink的可扩展性进行了比较研究**。

3、**Angiulli等人。[33]提出了一种分布式框架**，用于基于对异常检测解析集（数据集的一个小子集）的感知，在海量数据集中识别基于距离的异常**。后来，Angiulli等人[152]提出了一套用于GPU的并行和分布式算法，从而产生了两种基于距离的异常检测算法：BruteForce和SolvingSet**。它们之间的区别在于它们利用GPU架构和内存层次结构的方式，并提供针对CPU版本的改进，包括可扩展性和并行性利用。**松本等人[153]发表了一种使用密度采样对不确定数据进行异常检测的并行算法，通过OpenCL框架在图形处理单元（GPU）和多核中央处理单元（CPU）上建立了实现**。

4、**Lozano和Acufia [154]设计了两种并行算法来识别基于距离的异常**，使用随机化和修剪规则来识别基于密度的局部异常。**他们还构建了Bay和Local Outlier Factor（LOF）程序的并行版本**，这些程序在异常检测和运行时间方面表现出良好的性能。**Bai等人。[34]专注于大型数据的分布式基于密度的异常检测问题**。他们提出了一种基于网格的分区算法，作为一种数据预处理技术，在将数据集分发到分布式环境中的数据节点之前，将数据集划分为网格。**提出了一种分布式LOF计算方法，利用少量网络通信并行发现基于密度的离群点**。**Reilly等人。[155]提出了一种基于PCA的离群值识别方法，该方法在分布式环境中工作，在提取包含离群值的训练集的主成分时表现出鲁棒性**。**Gunter等人[147]探索了在大型分布式系统中识别异常值的各种技术**，并主张采用轻量级方法来实现真实的时间分析。没有找到单一的最佳方法;因此，他们得出结论，由于有效性的变化取决于异常的定义，因此需要各种方法的组合。

5、**Maruhashi等人。[148]提出了一种在具有数百万条边的异构网络中发现模式和异常的技术**，并根据经验证明该技术可扩展到高维数据集。**Shin等人。[149]开发了一种新的灵活框架，可以识别大规模高阶张量中的密集块**，并通过以近乎完美的准确度发现TCP转储中的网络攻击，证明他们的方法在真实的数据中是可扩展的。**Oh等人[44]提供了一种可以处理高维数据的可扩展方法**。特别是，他们还证明了他们的方法在维度方面优于许多基线方法。Hooi等人。**[150]提出了一种可扩展的基于密集子图的异常检测方法，称为FRAUDAR**，不仅可以检测真实的世界图中的各种欺诈攻击，还可以检测大数据中大量先前未检测到的行为。**Jiang等人。[151]提出了一种名为CROSSSPOT的可扩展算法**，该算法对可疑程度进行评分和排名，以在真实世界的大型多模态数据中找到密集的可疑块。

## 十、《A Comparison of Outlier Detection Techniques for High-Dimensional Data》

### 1、评价指标

1、**AUC**。ROC（受试者工作特征）曲线是真阳性率与假阳性率的图表，其中真（假）阳性率表示前m个潜在离群值中离群值（内值）的比例。

2、**Precision（P）**。精度是指真实离群值的数量与离群值候选总数的比率

3、**Average precision (AP)**。Average precision不是仅对单个n值进行评估，而是指所有离群值对象的等级上的精度分数的平均值。

4、**Rank Power (RP)**。秩功率是另一种流行的测量，以评估离群值检测方法的性能。很明显，如果离群值排名算法将真正的离群值排在离群值候选列表的顶部，则该算法将被视为更有效。

5、**相关系数**。如斯皮尔曼等级相似性或Pearson相关性，也可用于评估文献中离群值检测的性能36。这种度量方法通过使用合并权重将更多的重点放在排名靠前的潜在离群值上。

### 2、数据集来源

在离群点检测实验中，通常使用**人工数据集和真实数据集**来验证文献中的性能。**Wang等人37提供了一些在不同情况下具有异常值的合成数据集**。真实世界的数据集通常来自三个来源，如下所示：

> 1、**UCI机器学习库**。这些数据集中的大多数已被提议用于评估分类方法。**对于离群点检测任务，常用的策略是通过将小类中的对象作为离群点，其余的作为正常对象来预处理数据集**。
>
> 2、**ELKI数据集**。ELKI是一个积极开发和维护的“用于开发索引结构支持的KDD应用程序的环境”。最近的版本特别致力于异常值检测。**该平台不仅提供了离群点检测算法，还提供了用于离群点检测评估的多个数据集**。
>
> 3、**空间数据**。空间数据4的集合是由芝加哥大学捐赠的。**尽管最初用于空间分析，但这些空间数据（包括人口普查区域数据和邮政编码业务模式）也可用于离群点检测**。

**在分类中主要使用的数据集需要进行预处理以用于离群值检测任务**。在预处理期间，可以考虑两种情况：

> 1、**对于语义上有意义的离群数据集，与稀有对象相关联的类被视为离群值，其余的被视为正常数据**。
>
> 2、**对于其他数据集，从数据集中随机选择离群值类。特别地，对于只有两个类的数据集，具有次要对象的类通常被视为离群点**。

### 3、实验对比

**我们在9个数据集上对10种流行的离群点检测算法进行了实验比较**。离群点检测算法包括**kNN、kNNW、ODIN、LOF、Loop、COP、SOD、FastABOD、HiCS和高斯均匀混合模型（GMM）**。**其中“N”和“O”分别指所有对象和离群值的数量**。

![image-20240906183347756](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183347756.png)

![image-20240906183523232](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183523232.png)

## 十一、《A comparative evaluation of outlier detection algorithms: Experiments and analyses》

我们的论文扩展了以前的工作[7，33]，**使用了12个公开可用的标记数据集，其中大部分被推荐用于离群值检测[7]，此外还有3个来自旅游行业一家大公司生产环境的新工业数据集**。所选的参数和非参数算法来自各种方法，包括**概率算法，最近邻方法，神经网络，信息论和隔离方法**。在标记数据集上的性能与**ROC曲线下面积和精确度-召回率曲线进行了比较**。为了全面概述这些方法，我们还对每种方法的**训练时间，预测时间，内存使用和鲁棒性**进行了基准测试。

### 1、异常检测方法

#### 1.1 概率方法

> **概率算法通过推断模型参数θ来估计数据集X的概率密度函数。具有最小似然P（X|θ）的数据点被识别为离群值。**在我们的基准测试中使用的第一种算法是**高斯混合模型（GMM）**。**在[3]中，Blei等人描述了Dirichlet过程混合模型（DPMM）**。该算法在文献[8]的KDD 99数据集上进行了入侵检测，其性能优于SVM和KNN算法。**核密度估计器（KDE）**，也称为Parzen窗口估计器，通过为每个数据点分配核函数，然后对核的局部贡献求和来近似数据集的密度函数。**Kim等人在[13]中展示了这个问题，其中作者描述了一种鲁棒核密度估计（RKDE）算法**。**概率主成分分析（PPCA）[29]**是一种潜在变量模型，用于估计数据的主成分。**Quinn等人开发的最小二乘异常检测（LSA）[25]**将多类概率分类器扩展到一类问题。使用ROC曲线下面积将该方法与knn和一类SVM进行比较。

#### 1.2 基于距离的方法

**Mahalanobis距离适用于针对由单个高斯形聚类组成的多变量数据集的异常检测任务[2]**。

#### 1.3 基于邻居的方法

**在[4]中描述的局部离群因子（LOF）**，**lof优于基于角度的离群值检测[16]和单类SVM [26]**。**基于角度的离群值检测（ABOD）[16]**使用在每个输入向量处测量的角度的半径和方差而不是距离来识别离群值。**子空间离群值检测（SOD）[15]**算法为每个点p找到p和它的k个最近邻居之间共享的m个邻居的集合。

#### 1.4 信息论方法

**Kullback-Leibler（KL）发散度在[9]中被用作新奇检测的信息论度量**。

#### 1.5 神经网络

**在[19]中，Margaret等人提出了一种基于重构的非参数神经网络，称为Grow When Required（GWR）网络**。**该方法基于Kohonen网络，也称为自组织映射（SOM）[14]**

#### 1.6 基于域的方法

用于离群数据识别的其他方法依赖于将标称数据与输入空间的其余部分分离的边界的构造，从而估计标称类的域。因此，**落在定界边界之外的任何数据点都被标记为离群值**。**单类SVM [26]是支持向量机（svm）算法在单类问题中的应用**，属于这类算法。该方法在高维空间中计算分离超平面，该分离超平面由在来自高维空间中的输入空间的点之间执行点积的核引起。

#### 1.7 隔离方法

**隔离森林的概念是由Liu在[17]中提出的，它使用随机森林来计算每个数据点的隔离分数**。该模型是通过对属性值执行递归随机拆分来构建的，因此生成的树能够将任何数据点与其余数据隔离开来。**作者指出，他的算法提供了线性时间复杂度，并在现实世界的数据集上证明了离群点检测性能明显优于lof**。

### 2、实验评估

#### 2.1 实验指标

我们使用**受试者工作特征（ROC）曲线**（真阳性率对假阳性率）和**精确度-召回（PR）曲线**

#### 2.2 实验数据集

**我们的评估使用15个数据集，范围从723到20，000个样本，包含6到107个特征**。在这些数据集中，**有12个在UCI [1]或OpenML [30]存储库中公开，而剩下的3个数据集是包含Amadeus公司生产数据的新型专有数据集**。

![image-20240906222707675](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906222707675.png)

#### 2.3 算法实现和参数

<img src="C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906223115710.png" alt="image-20240906223115710" style="zoom: 80%;" />

**本实验中使用的大多数实现都是公开可用的**。表2详细说明了所选的编程语言和初始化参数。**大多数方法具有灵活的参数，并且在没有大量调优的情况下执行得非常好**。**Python的Matlab引擎API和rpy2库允许我们从Python调用Matlab和R代码**。

### 3、总结

**iforest是一个很好的方法，有效地识别离群值，同时显示了良好的可扩展性。ocsvm在这个基准中是一个很好的候选者，但是它也不适合大型数据集**。**SOD表现出良好的离群值检测性能，并以较差的可扩展性为代价有效地处理高维数据集**。**指数族表示的dpmm显示是非常耗时的，而没有实质性地提高检测离群值的高斯为基础的方法，如dpgmm**。**LOF、ABOD、GWR、KL和LSA达到最低性能，而前三种方法也显示出较差的可扩展性**。

## 十二、《On the Evaluation of Outlier Detection and One-Class Classification Methods》

### 1、实验设置

1、我们比较和评估了11种算法：**ABOD，Auto-Encoder，Gaussian Density，GLOSH，kNNglobal，kNNlocal，LOCI，LOF，Linear Programming，Parzen Windows和SVDD**。对于大多数比较算法，我们使用来自http://prlab.tudelft.nl/users/david-tax/ [25]的代码，除了LOF，LOCI，kNNlocal和GLOSH。**在LOF和LOCI的情况下，修改了它们的实现，以确保待分类的新观测不会影响内点类的预计算模型**。由于**KNNlocal在该存储库中不可用**，因此我们使用自己的算法实现。**GLOSH是根据http://lapad-web.icmc.usp.br/上提供的HDBSCAN* 的实施情况进行调整的**。

2、我们使用来自**UCI机器学习库[17]的31个真实世界数据集作为单类分类的预处理**，并在http://prlab.tudelft.nl/users/david-tax/上提供：**Abalone, Arrhythmia, Balance-scale, Ballbearing, Biomed, Breast, Cancer, Colon, Delft1x3, Delft2x2, Delft3x2, Delft5x1, Delft5x3, Diabetes, Ecoli, Glass, Heart, Hepatitis, Housing, Imports, Ionosphere, Iris, Liver, Satellite, Sonar, Spectf, Survival, Vehicle, Vowels, Waveform and Wine**

### 2、总结

**SVDD和kNNglobal是单类分类的首选**，**而我们不推荐kNNlocal**。**这与Janssens等人[13]之前的比较研究相反**，该研究不包括kNNglobal，并报告kNNlocal为最佳表现者。**此外，我们无法确认[13]中报告的LOF的最佳性能，而只能确认SVDD的最佳性能**。

## 十三、《Prediction and outlier detection in classification problems》

提出了一种**平衡共形优化预测集（Balanced and Conformal Optimized Prediction Sets，BCOPS）方法**。该方法将监督学习算法与保形预测相结合，以最小化在样本分布外的平均误分类损失。所构造的预测集具有有限样本覆盖保证，无需分布假设。在适当的假设下，我们证明了我们的方法的渐近一致性和最优性，并在真实的数据上说明了我们的方法。

## 十四、《Supervised outlier detection for classification and regression》

通常情况下，OD模型和分类器或回归器的最佳超参数是连续但独立地获得的。**一个自然的想法是利用这种联合工作来开发目标，不仅要获得监督模型的超参数，还要获得OD模型的超参数**。

![image-20240907103152771](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907103152771.png)

### 1、离群值检测（OD）

1、我们选择并比较了在文献中具有突出作用的**九种不同的离群值检测方法**，使用了**scikit-learn [10]或PyOD [11]中的实现**，这两个库是众所周知的Python库。**所有这些都有一个共同的参数：污染百分比，即，我们认为样本中异常值的比例**。我们将在这里考虑九个代表性的OD模型，即**最小协方差决定性估计[21，22]**，**局部离群因子[23]**，**基于连通性的离群因子[24]**，**k-最近邻离群估计[25，26]**，**隔离森林[27，28]**，**一类支持向量机[29]**，**主成分分析（PCA）OD [30]，[31]**、**子空间异常值检测[32]**和**基于直方图的异常值检测[33]**。

**一个非常好的参考是PyOD库[11]，我们使用了所有上述方法的实现，除了最小协方差行列式和隔离森林，我们使用它们的scikit-learn [10]实现**

### 2、数值实验

#### 2.1 实验设置

如前所述，本工作中应用的OD模型是**mcd，if，knn，lof，ocs，pca，cof，hbos和sod**，**在mcd和if的情况下使用它们的scikit-learn实现，在其他情况下使用它们的PyOD版本**。**回归监督模型将是 Ridge 和 Huber 回归作为线性回归模型，以及具有 ReLU 激活和具有 20 个单元的单个隐藏层的非线性多层感知器回归器**。 **对于分类，将使用逻辑回归，其用于两类问题的标准公式和用于多类问题的多项式版本； 再次使用 ReLU 激活的非线性多层分类器和具有 20 个单元的单个隐藏层**。 **所有分类器和回归器都选择了 scikit-learn 中的实现**。

为了测试不同的模型，**使用了五重嵌套交叉验证（CV）**，其中构建了前五个外层，并且我们循环使用其中四个作为模型超参数化的训练验证子集，其余一个用于测试 。 反过来，模型超参数化又通过训练验证子集上的五倍 CV 来完成。 **通过网格搜索得到最优超参数**。

![image-20240907105002773](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907105002773.png)

#### 2.2 数据集

我们将使用**八个回归数据集和八个分类数据集**。 更准确地说，将考虑以下数据集：用于回归的 abalone、boston、cal-housing、concrete、cpusmall、mg、winequality_red 和 winequality_white，以及用于分类的 australian、breast_cancer、diabetes、digits、dna、german、satimage 和 snippet。 

#### 2.3 分类结果

表 17 和表 18 分别给出了测试数据集未过滤时五重嵌套 LR 和 MLPC 模型的平均值和标准差。可以看出，**HBOS、LOF 和基本模型在 2 个问题中给出了 LR 的最佳结果，IF、SOD、COF 和 MCD 在 1 个问题中给出了最佳结果，而 KNN 和 OCS 从来都不是任何问题的最佳模型**。 当它在回归中发生时，MLPC的情况发生了变化，其中MCD在四个问题中给出了最大的准确度，LOF在三个问题中给出了最大的准确度，基础模型在两个问题中给出了最大的准确度，SOD，IF，KNN和COF在一个问题中给出了最大的准确度，HBOS和一类SVM在一个问题中没有给出最大的准确度。

### 3、总结和展望

**我们可以得出结论，一般来说，MCD和IF模型通常是一个很好的选择，而PCA，HBOS和LOF也应该考虑计算时间是一个加权因素**。

## 十五、《Robust Statistical Scaling of Outlier Scores: Improving the Quality of Outlier Probabilities for Outliers (Extended Version)》

### 1、数据集和异常检测算法

我们**在21个真实世界的数据集[6]上计算离群值**，由于计算原因排除了KDD和ALOI数据集，使用11种离群值检测算法**：主成分分析[33]，核主成分分析[12]，高斯混合模型[7]，k-最近邻检测器[29]，局部离群因子[5]，隔离森林[18]，基于直方图的离群值检测[9]，轻量级异常在线检测器[27]，基于连接性的离群值因子[35]，基于采样的离群值检测[34]，以及使用经验累积分布函数的无监督离群值检测[17]**。对于所有异常值检测算法，**我们使用Python库PyOD [41]并将超参数设置为默认值**。

## 十六、《Human-in-the-loop Outlier Detection》

### 1、摘要

本文提出了一个基于人工智能的离群点检测方法HOD，该方法能够有效地利用人工智能来发现真实的离群点。在HOD中存在两个主要挑战。**第一种是设计人性化的问题，使得即使人类对离群点检测技术一无所知，人类也可以容易地理解问题。二是最大限度减少提问次数**。

### 2、参与对比的基准

我们将HOD与众所周知的无监督离群值检测方法进行了比较，包括**KNN [40]、LOF [5]、聚类方法[23]和Ensemble方法[3]。以及基于主动学习的方法AI 2 [42]和AAD [14]**。还有基于实体匹配的方法CrowdER和Magellan。

### 3、相关工作

#### 3.1 有监督异常检测方法

**这类技术假设事先有大量标记的离群值和内值可用**。使用这些标记的数据，然后训练分类模型，**该模型将测试对象分类为离群值或内界值**。然而，监督离群点检测存在两个严重的问题。首先，**训练集中的离群值通常比内值少得多。这会导致不平衡的类别分布，从而影响分类准确度[38，43，46]**。其次，**由于离群值的稀有性，难以获得大量的高质量标签，尤其是离群值标签[2，41]**。由于这些问题，监督离群点检测方法在真实的应用中并不普遍。

#### 3.2 无监督异常检测方法

**无监督类中的技术[3，5，6，23，40，52]在真实的世界中被广泛使用，因为它们不需要任何训练数据**。通常，**这些技术基于数据集中的内点通常比异常点更频繁的观察来检测异常点**。然而，**无监督技术的准确性往往很低**。然而，尽管涉及到人类，**但与监督技术不同，我们不需要人类显式地将对象标记为内点或离群点，这通常很难并且非常耗时**。相反，**通过仔细选择要由人类回答的问题**，如图2所示，**我们的HOD能够以最少的人力准确地发现离群值**。

#### 3.3 主动学习方法

给定人力成本预算，主动学习方法从数据集中选择对象，要求人类标记这些对象并迭代地训练分类器，直到预算用完。

（1）**AI2 [42]**：每次AI2选择X个对象供用户标记，**其中X/2个对象来自非监督方法，其他X/2个对象由监督方法（随机森林）提供**。在X个对象被标记后，它重新训练监督模型并选择另一个X个对象，直到预算用完。最后，利用该模型对剩余的未标记数据进行预测。

（2）**AAD [14]**：首先，AAD提取每个对象的特征，并使用监督方法来训练分类器。接下来，基于建模结果，AAD选择一个最有可能成为人类标记的离群值的对象。然后，它迭代地重新训练模型，以调整每个特征的权重，并选择新的离群候选。

尽管主动学习方法有效地减少了人类的标记努力，但它们并没有解决离群点检测中的独特挑战，即，**由于离群点的稀有性，在真实的应用中缺乏地面真值离群点**。

## 十七、《Progress in Outlier Detection Techniques: A Survey》

1、首先，我们提供了离群点检测的基本概念，然后将其分类为不同的离群点检测技术，如**距离，聚类，密度，集成和基于学习**的方法。一些常见的困难与**输入数据的性质、离群值类型、数据标签、准确性以及CPU时间和内存消耗**方面的计算复杂性有关[6]-[9]。离群值检测很复杂，原因如下：

> 1、异常值和正常行为之间的不准确界限
>
> 2、正常行为继续发展的可能性很高，也许它在未来可能不是一个正确的表示
>
> 3、不同的应用和相互冲突的概念使得很难将一个领域的技术应用到另一个领域
>
> 4、模仿真实的离群值并因此产生的数据中的噪声对于区分和去除它们是具有挑战性的。

2、由于异常值检测在各个领域的固有重要性，**在异常值检测（OD）方法的调查中进行了大量的研究工作[22]-[34]**。大部分调查都只针对特定范畴，而没有就最新的研究提供深入的报道和见解，如表1所示。例如，**[25]中的评论仅关注数据流，[27]关注高维数值数据，[23]，[33]关注动态网络，最近的评论关注深度学习[32]**。**最全面的[28]，[33]，[41]，尽管包含了很多见解，但他们没有回顾大多数主要的最先进的方法，大多数至少在五年前发表**

### 1、背景

1、离群值定义：**2017年，Ayadi等人[14]从不同作者的角度给出了对离群值的十二种不同解释**。尽管定义离群值的复杂性和复杂性，**但它通常可以被描述为与其他数据点显著不同的数据点，或者不模仿其他点的预期典型行为的点[5]，与异常值相反的数据点称为内点。**P1、P3、P4和具有非常少的数据点P2的另一部分远离两个大的聚类区域，因此，它们被称为离群值。

![image-20240910154804691](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240910154804691.png)

2、在识别异常值的过程中，**需要考虑的必要特征和需要执行以识别异常值的测试是同样重要的问题**。多年来，离群点识别的过程在机器学习和数据挖掘中有很多名称，如**离群点挖掘，新奇检测，离群点建模，异常检测**等。在检测离群值的过程中，**知道需要考虑的特征的数量**也是至关重要的-单变量或多变量情况。

3、异常值检测算法的种类如下：

> 1、**基于统计的方法**：**标记或识别异常值的基于统计学的技术的基本思想取决于与分布模型的关系**。这些方法通常分为两大类-参数和非参数方法。
>
> 2、**基于距离的方法**：基本原理集中于观测之间的距离计算。**一个点被看作是一个离群点，它远离它附近的邻居**。
>
> 3、**基于密度的方法**：这些方法的核心原理是**可以在低密度区域中找到离群点，而内点位于密集邻域中**。
>
> 4、**基于聚类的方法**：关键思想是应用标准聚类技术从给定数据中检测离群值。**离群值被认为是不在任何大的或密集的聚类内或附近的观测**。
>
> 5、**基于图的方法**：**使用图技术来有效地捕获互连实体的相互依赖性以识别离群值**。
>
> 6、**集成方法**：重点是**将不同模型的结果结合起来，以产生更强大的模型来有效地检测离群值**。它们有助于回答离群值是否应该基于线性模型、基于距离或其他类型的模型的问题。
>
> 7、**基于学习的方法**：如主动学习和深度学习，其基本思想是**通过应用这些学习方法来学习不同的模型来检测离群值**。

4、**数据中的异常值有时会产生负面影响。在机器学习和深度学习离群值检测过程中，这将导致数据训练过程更长、模型准确度较低，并最终降低结果**。

### 2、离群值检测技术

#### 2.1 基于密度的方法

使用这种方法设计的一些算法已经成为许多新算法[76]-[78]的基线算法[8]，[75]。

**Breunig等人。[8]提出了局部异常值因子（LOF）方法**，这是第一个基本的松散相关的基于密度的聚类异常值检测方法之一。该技术使用k-最近邻。**Schubert等人。[79]发现LOF密度估计可以简化**，他们提出了一个简化的LOF，用KNN距离代替LOF的可达距离。

在后来的研究中，**Tang等人[80]提出了对LOF [8]和简化LOF [79]的改进，他们称之为基于连接的离群值因子（COF）**。该方法与LOF非常相似，唯一的区别是计算记录密度估计的方式。

为了确定哪个阈值分数可以作为LOF中的离群值，**Kriegel等人。[81]然后为称为局部离群概率（Loop）的离群值检测方法**，制定了一个更稳健的局部密度估计，该方法将提供离群值“得分”的想法与概率和概率导向方法相结合。

在LOF [8]和COF [80]中，这些方法不能正确处理多粒度问题。**Papadimitriou等人。[82]提出了一种称为LOCI的LOcal相关积分及其离群值度量多粒度偏差因子（MDEF）的技术**，以处理此缺点。

尽管LOCI表现出良好的性能，但是它具有更长的运行时间，**Papadimitriou等人[82]提出了另一种方法，称为aLOCI的LOCI近似版本**。

**Ren等人提出了一种称为相对密度因子（RDF）的方法**，该技术由于其对集群中深层数据点的修剪能力而更有效地执行。[83]。

**Jin等人。[75]提出了INFLuenced Outlierness（INFLO）**，这是另一种类似于LOF的局部离群值检测技术，并使用对称邻域关系来挖掘离群值。

上述算法的挑战在于高维数据集的距离计算。**Keller等人。[85]提出了一种高对比度子空间方法（HiCS）**，以改进离群值的评估和排名，其中离群值评分密切相关。**Campello等人[86]将焦点扩展到仅包括局部离群值以包括全局离群值，提出了一种新的有效离群值检测度量算法，称为层次结构的全局-局部离群值得分（GLOSH）**

**Momtaz等人。[87]，**在计算局部离群值时偏离了大多数先前算法的中心焦点。他们引入了一种新的基于密度的离群值检测技术，该**技术通过为每个对象提供称为动态窗口离群值因子（DWOF）的分数来检测前n个离群值**。

**Lozano等人[90] -并行LOF算法（PLOFA）**并行扩展性较好

**Tang和He [78]提出了一种使用本地KDE的离群值检测方法**。为了测量局部离群值，使用基于相对密度的离群值得分（RDOS）。

**Vázquez等人。[91]提出了一种新的算法来检测基于低密度数据模型的离群值，称为稀疏数据观测器（SDO）。Su等人。[93]提出了一种有效的基于密度的方案，该方案基于分散数据的局部OD方法，称为E2DLOS**。

#### 基于密度方法的优劣：

在基于密度的方法中，**使用的密度估计是非参数的;它们不依赖于假设的分布来拟合数据**。**一些基于密度的技术[8]，[75]，[81]，[82]已经成为许多后续算法的基本基线，实验表明，它们对于现代方法效果良好，经常优于其竞争对手，如一些现有的统计和基于距离的方法[39]，[94]，[95]**。

但是，**它们对参数设置很敏感，例如确定邻居的大小**。对于不同的密度区域，它变得更加复杂，并导致较差的性能。对于高维数据，当离群值彼此密切相关时，这也是具有挑战性的。Goldstein等人[97]比较了COF和LOF，发现**LOF球形密度估计对于有效检测离群值来说是一个糟糕的选择。COF算法通过连接规则记录来估计局部密度，解决了上述问题。当具有不同密度的聚类彼此相距不远时，INFLO显示出改进的离群值得分**。

![image-20240910161523836](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240910161523836.png)

![image-20240910161542269](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240910161542269.png)

#### 2.2 基于统计的方法

使用统计技术检测离群值可以使用监督、半监督和无监督样式来完成。根据与分布模型的关系，某些数据点可以被标记为离群值。异常值和内部值的声明取决于数据分布模型。**基于统计的方法通常分为两大类-参数和非参数方法。这两种方法的主要区别在于前者对给定数据的潜在分布模型进行假设，并从已知数据中估计分布模型的参数。后一种方法没有任何关于分布模型先验知识的假设[98]**。

##### 2.2.1 参数方法

对于这种具有潜在分布模型假设的方法，用于离群值检测的两种众所周知的方法是**高斯混合模型**和**回归模型**。

#### 高斯混合模型：

在这个模型中，**训练阶段使用最大似然估计（MLE）方法[100]来执行高斯分布的均值和方差估计。在检验阶段，应用了一些统计不一致性检验（箱形图，均值方差检验）**。

Yang等人。[101]介绍了一种具有全局最优基于样本的GMM（高斯混合模型）的无监督离群值检测方法。

在2015年，为了更稳健地检测离群值，**Tang等人提出了使用具有局部保持投影的GMM。[102]。**他们**结合使用GMM和子空间学习，在能量分解中进行稳健的离群值检测**。在他们的方法中，使用子空间学习的局部保持投影（LPP）来有效地保持邻域结构，然后揭示数据的内在流形结构。这项研究解决了以前的方法，LOF [8]和Tang等人的研究空白，改进了性能（真阳性93.8%到97%，假阳性从35.48%下降到25.8%）

#### 回归模型：

根据需要解决的问题，**用户选择的模型可以是线性的或非线性的**。通常，当采用该技术时，**第一阶段，即训练阶段，涉及构建拟合数据的回归模型。然后，测试阶段通过针对模型评估每个数据实例来测试回归模型**。

**Park等人[105]提出了另一种基于回归的离群值检测技术**，但这一次，它的中心是检测传感器测量中的离群值。

最近，**在2017年，Dalatu等人。[106]通过分析受试者工作特征（ROC）曲线的误分类率和准确性，对离群值检测的线性和非线性回归模型进行了比较研究**。对于离群值检测，**非线性模型（93%的准确度）往往比线性模型（68%的准确度）更适合**，这为研究人员提供了更好的理由，为什么在更一般的情况下采用非线性模型更有效。

##### 2.2.2 非参数方法

核密度估计方法：**核密度估计（KDE）是一种用于检测离群值的常见非参数方法[107]**。**Latecki等人在[108]中提出了一种使用核函数进行离群值检测的无监督方法**。与一些流行的基于密度的方法相比，对所提出的技术的实验评估[8]，[82]在大多数情况下会产生更好的检测性能。

后来，**Gao等人[109]提出了一种更好的方法来解决之前的一些缺点**。与LOF和Latecki等人[108]提出的方法相比，**该方法显示出改进的性能，以及使用基于内核的技术的广泛数据集的良好可扩展性，计算时间更少**。

Kumar和Verma [110]使用KDE来估计传感器数据分布以检测恶意节点。

**作者在[111]中提出了一种自适应核密度估计器（AKDE）的近似方法**，用于概率密度函数（PDF）的鲁棒和准确估计，与KDE相比有更高的计算成本和更好的效果。

S**mrithy等人。[113]提出了一种非参数在线离群值检测算法来检测大数据流中的离群值。Zhang等人[114]还研究了使用高斯核的自适应核密度技术，用于检测非线性系统中的异常。Qin等人。[115]提出了一种新的局部离群值语义，它可以很好地利用KDE来有效地从数据流中检测局部离群值。**

总而言之，**大多数KDE方法的一个大挫折是它们通常遭受高计算成本和维数灾难，这使得它们在实践中非常不可靠**。

##### 2.2.3 其他统计方法

已经提出了许多统计方法，但在识别离群值的更直接的统计方法中，**有直方图[116]和其他统计测试[40]，如箱形图，修剪平均值，极端学生化偏差和迪克森类型测试[40]**。在其他方法中，修剪平均值对离群值的抵抗力更强，而要识别单个离群值，极端学生化偏差检验是正确的选择。Dixon型检验具有在小样本量下表现良好的优点，因为不需要假设数据的正态性。

使用基于直方图的方法，**Goldstein和Dengel [116]提出了一种基于直方图的异常值（HBOS）检测算法，该算法使用静态和动态箱宽直方图来对单变量特征密度进行建模**

Hido等人[95]提出了一种新的统计方法，通过使用定向密度比估计，用于基于内点的离群点检测问题。

**Du等人。[118]提出了另一种具有统计参数的鲁棒技术来解决局部离群值检测问题，称为鲁棒局部离群值检测（RLOD）**。该方法支持Campello等人[86]技术中的**局部和全局离群值检测**，并且他们通过实验证明该方法在运行时间和检测率方面优于其他方法[8]，[26]。

#### 基于统计方法的优劣：

它们在**数学上是可以接受的**，一旦模型建立，就有一个快速的评估过程。这些模型通常拟合定量实值数据集或某些定量有序数据分布。它们**更容易实现**，即使局限于特定的问题。

由于它们的依赖性和参数模型中分布模型的假设，由于缺乏关于基础分布的先前知识，所产生的结果的质量对于实际情况和应用大多是**不可靠**的。由于大多数模型适用于单变量特征空间，因此它们通常**不适用于多维场景**。在直方图技术中，多变量数据的一个基本缺点是**无法捕捉不同属性之间的相互作用**。**当面对维数增加的问题时，统计技术采用不同的方法。这导致处理时间的增加和数据分布的错误表示**。统计方法的大多数缺点都集中在**异常值检测精度、缺乏针对非常高数据集的有效技术、维数灾难和计算成本上**。

**非参数方法是最有吸引力的，因为它们不依赖于分布特征的假设**。为了在发现和发现异常值时更有效和更鲁棒的解决方案，**应用鲁棒回归而不是普通回归更合适**，因为异常值会影响后者。对于非参数情况，**KDE在大多数情况下表现更好，尽管它对离群值的敏感性和在污染数据集中确定标称数据密度的良好估计的复杂性**。

**与PCA方法[103]相比，Tang等人的方法[102]对离群值和噪声检测问题给出了稳健的改进。在HBOS [116]中，他们的方法显示出良好的计算速度，甚至超过一些基于聚类的算法和其他类型的算法（LOCI，LOF，INFLO），因此使其适合大规模近实时应用。而Hido等人[95]的方法对于大规模数据集更具可扩展性，Du等人[118]的方法具有更稳健的分析。**

![image-20240910170157906](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240910170157906.png)

![image-20240910170217590](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240910170217590.png)

### 2.3 基于距离的方法

**基于距离的方法通过计算点之间的距离来检测离群值**。与最近邻相距较远的数据点被视为离群值。最常用的基于距离的离群值检测定义集中在局部邻域，k-最近邻（KNN）[121]和传统距离阈值的概念上。**基于距离的离群值检测方法是温和的非参数方法，适用于中高维的大型数据集。与统计技术相比，它们往往具有更强大的基础，更灵活，计算效率更高**。

##### 2.3.1 K最近邻方法

利用这些方法计算离群值已经成为许多研究者用来检测离群值的最流行的方法之一。它与k-最近邻分类不同。**这些方法主要用于检测全局离群值**。

**Knorr和Ng [122]和Ramaswamy等人[123]是最早提出在大型数据集中检测离群值的技术的人之一**，这些技术在现有的最先进的研究中取得了重大进展。Knorr和Ng [122]提出了一种非参数方法，这与之前的一些统计技术[101]、[104]形成鲜明对比。[123]提出了一种基于单元格的算法，该算法相对于N是线性的，相对于K是指数的，以优化先前的算法[122]。在[122]的扩展版本中，为了找到每个候选空间索引结构的最近邻居，使用了KD树，X树和R树[99]。

**Angiulli等人[7]与传统的方法稍有不同，该算法可以从给定的未标记数据集中检测出顶级离群值，并预测未检测到的数据点是否是离群值**

Ghoting等人。[124]提出了一种称为递归分箱和重新投影（RBRP）的算法，以提高高维数据集的计算速度，并改善以前方法的缺点[122]，[123

Zhang等人。[76]提出了一种基于局部距离的离群值检测方法，称为基于局部距离的离群值因子（LDOF），他们的研究表明，与LOF相比，在邻居大小范围内的性能有所改善[8]。

Huang等人。[126]提出了一种称为基于秩的检测算法（RBDA）的方法来对邻居进行排序。

在另一项研究中，Dang等人。[121]应用k-最近邻检测一些先进城市每日收集的大规模交通数据中的离群值。在另一项研究中，为了提高KNN邻居的搜索效率，Wang等人。[128]应用了最小生成树。

**Radovanovi'c等人。[129]提出了一种反向最近邻方法来解决高维数据集中计算离群值的最大挑战之一，即“维数灾难”**。他们表明，他们的方法可以有效地应用于低维和高维环境。当与原始KNN方法[123]相比时，它在检测率方面表现出改进的性能。

Huang等人。[130]实现了自然邻居的概念来获取邻域的信息。Ha等人。[131]提出了一种启发式方法，通过采用迭代随机采样来确定k的合适值。为此，最近，Tang等人[78]提出了一种方法来确定本地KDE中的离群值。

##### 2.3.2 剪枝方法

**Bay等人[132]提出了一种基于嵌套循环的算法**，该算法使用随机化和修剪规则。通过修改嵌套循环算法，该算法因其二次性能O（N2）而被认可，**他们能够在大多数数据集上获得接近线性的时间**。然而，该算法做了很多假设，这将导致性能不佳。

Ren等人。[134]提出了Ramaswamy等人的改进版本。技术[123]，一种基于垂直距离的离群值检测方法，通过应用修剪方法和“相邻”标记技术来检测大型数据集中的离群值。

在另一项工作中，Vu等人。[135]引入了多规则离群值（MIRO），该方法采用了与[134]类似的技术，通过使用修剪技术来加速检测离群值的过程。

#### 基于距离方法的优劣：

它们简单易懂，**因为它们大多不依赖于假设的分布来拟合数据**。在可扩展性方面，**它们在多维空间中的扩展性更好**，因为它们**具有强大的理论基础**，**并且与统计方法相比，它们的计算效率更高**。

它们在高维空间方面与基于统计和密度的方法有一些类似的缺点，因为它们的**性能由于维数灾难而下降**。当使用基于距离的方法时，诸如**高维空间中的邻域和KNN搜索的搜索技术是昂贵的任务**。现有的大多数基于距离的方法不能处理数据流，因为它们难以保持数据在局部邻域中的分布。

大多数基于距离的方法的关键缺点之一是它们无法很好地扩展非常高维的数据集[144]。像维度灾难这样的问题仍然是一个不断发展的挑战。为了解决二次复杂度的问题，研究人员专注于提出几种重要的算法和优化技术，例如应用紧凑的数据结构[124]，[145]，使用修剪和随机化[132]等。

### 2.4 基于聚类的方法

基于聚类的技术通常依赖于使用聚类方法来描述数据的行为。重要的是要注意，**聚类方法与离群值检测过程不同**。**聚类方法的主要目的是识别聚类，而孤立点检测方法的主要目的是检测孤立点。基于聚类的技术的性能高度依赖于聚类算法在捕获正常实例的聚类结构方面的有效性[146]**。基于排序的方法是无监督的，因为它们不需要任何先验知识，Zhang [26]在他的工作中介绍了许多基于聚类的算法，并将它们分为不同的组。由于这些基于聚类的算法中的大多数都不是在这十年内提出的，我们认为没有必要在我们的工作中重复它们

1、分区聚类方法：属于这一组的算法的一些例子包括PAM [147]，K-Means [148]，K-Means [149]，K-Means [147]等。

2、层次聚类方法：它们将对象集划分为不同级别的组，并形成树状结构。要将它们分组到不同的级别，通常需要最大数量的群集。一些例子包括MST [150]、CURE [151]、CHAMELEON [152]

3、基于密度的聚类方法：它们不需要像在划分方法的情况下那样初始给定聚类的数目;例如K-均值。给定集群的半径，他们可以将集群建模为密集区域。密度聚类方法的一些示例包括DBSCAN [153]和DENCLUE [154]。

4、基于网格的聚类方法：STING [94]，Wavecluster [155]，DCluster [156] 

5、高维数据的聚类方法：CLIQUE [157]，HPStream [158]

除了现有文献[5]、[22]、[26]、[33]中已经涵盖的以下算法之外，**Cao等人[9]和Chen等人[159]分别提出了一种称为DenStream的两阶段算法**。在DenStream中，初始阶段记录数据流的摘要信息，后一阶段对已经汇总的数据进行聚类

**在另一种技术D-Stream [159]中，它类似于DenStream，具有在线和离线组件**，不同之处在于它是基于密度网格的聚类算法。在时间性能和聚类性能方面，该算法也优于CluStream算法。

由于[9]和[159]中的算法使用阻尼窗口模型，**Ren等人[161]提出了SDstream**，这是一种使用滑动窗口模型的算法。**Assent等人[162]提出AnyOut**来快速计算和检测流数据中任何时间的离群值。

**Elahi等人。[163]，使用k-means，提出了一种基于聚类的离群值检测技术**，用于将数据流拆分为块进行处理。实验结果表明，**他们的方法在发现数据流中的显著离群值方面比一些现有技术[141]，[164]取得了更好的性能**。

在另一项研究中，使用与MacQueen等人[149]类似的k均值概念以及权重规则，作者提出了一种基于聚类的框架来检测变化数据流中的离群值[165]。当这种技术与LOF [8]相比时，它具有更少的时间消耗，显示出更高的离群值检测率，以及更低的误报率。

在另一项工作中，Bhosale等人提出了一种无监督的离群值检测方案，该方案使用基于密度和基于分区的方案进行流数据。[167]。它具有比[163]更高的离群值检测率。

Moshtaghi等人[169]使用聚类方法提出了一个模型，将聚类边界外的对象标记为离群值。与[169]类似，Moshtaghi等人在另一项工作中提出了eTSAD [170]，这是一种使用已建立的椭圆模糊规则对流数据进行建模的方法。Salehi等人[171]提出了一种用于演化数据流的集成技术。Chenaghlou等人[172]提出了一种有效的离群点检测算法，其中提出了活动聚类的概念，以获得更好的时间和存储器有效的离群点检测结果。Rizk等人[173]提出了一种优化的计算算法，该算法增强了在大型和小型聚类中搜索离群值的过程。Chenaghlou等人[174]扩展了他们在[172]中的工作，提出了一种可以实时检测离群值的算法。该算法不仅能真实的检测离群点，而且能发现聚类的有序演化。

#### 基于聚类方法的优劣：

它们都是**无监督的方法**，这使得它们成为合适的选择，并且**对于数据流中的离群点检测非常有用**。它们**对不同的数据类型都很健壮**。在分区聚类相关技术中，它们被认为是**相对简单和可扩展的**

在聚类设置中，离群值是二元的；也就是说，没有对象离群值的定量指示。**大多数聚类方法都依赖于用户预先指定聚类的个数**，这是一项困难的任务。**划分方法据说对初始化阶段、异常值和噪声高度敏感**。

从所提到的基于聚类的技术中，我们可以看到，最近没有做太多的工作。

### 2.5 基于集成的方法

基于集成的方法通常用于机器学习，因为与其他相关方法相比，它们具有相对更好的性能。尽管与其他OD方法相比，用于离群值检测的基于集合的技术的报告很少[37]，[38]，[176]-[182]。然而，它们经常用于最近的离群值检测问题[183]，[184]，并且具有更多的开放挑战。然而，已知在异常值检测的背景下的集成方法是非常困难的。近年来，**已经引入了几种技术，包括：（I）Bagging [37]和boosting [184]用于分类问题（ii）隔离森林[192]用于并行技术。(iii)对于顺序方法[185]和极端梯度提升离群值检测（XGBOD）[183]以及混合方法的Bagged Outlier Representation Entrial（BORE）[186]。**

**Lazarevic等人。[37]提出了第一个已知的集成方法，用于使用集成方法改进离群值检测**。它利用特征装袋方法来处理非常大的高维数据集。该技术结合了多个离群值检测算法的输出，每个算法都是通过随机指定的特征子集创建的。

**Aggarwal [178]提出了一项关于离群值集成分析的研究，该研究最近引起了文献[187]，[236]的极大兴趣**。他讨论了各种离群值集成方法，以及如何使离群值集成分析更有效。**在分类上下文中，boosting [187]和bagging（Bootstrap Aggregating）[37]是已经提出的基于集成的方法的两个例子**。在集群的上下文中，多视图[188]和替代集群[189]作为示例。在boosting中，结果取决于先前的执行，这样的方法并不独立于其他方法，而bagging则相反;它们彼此独立。

**其他随后的研究[38]，[190]，[191]在后来的几年里，专注于使用集合进行离群值检测面临着许多挑战**。其中一些挑战包括使用不同函数和混合模型来比较分数以拟合离群值分数并给出分数组合的问题。**Schubert等人[191]使用相似性度量比较了基于评分的离群值排名**。2010年早些时候，Nguyen等人[38]研究了高维数据集的集合OD方法的困难。利用离群值的形式化概念，他们提出了基于随机子空间的异质检测器包围（HeDES），通过函数的组合，解决异质性问题。与Lazarevic等人不同。[37]框架**，HeDES可以将不同的技术结合在一起，产生不同的离群值和分数类型;例如，实值与二进制值**

Zimek等人。[176]提出了一种随机子采样技术来估计最近的邻居，然后估计其局部密度Zimek等人[180]在另一项工作中，作者从学习理论的角度考虑了他们的技术，作为另一种可能的集成离群值检测方法。

**Pasillas-Diaz等人。[177]考虑了子采样和特征装袋技术**。特征装袋技术用于在每次迭代中获得各种元素，而子采样技术计算不同数据子集的离群值。

Zhao等人。[227]提出了一种无监督离群值检测器框架，即离群值集合的检测器分数动态组合（DCSO）。DCSO试图解决在缺乏不同基础检测器的基础事实的情况下选择和组合离群值分数的挑战。Zhao等人。[228]提出了并行离群值集成（LSCP）框架中的局部选择性组合，以解决[227]中的相同问题。他们使用了与[227]类似的方法，并提出了LSCP框架的四种变体。

Aggarwal等人。[229]离群值集成书对离群值集成方法进行了详细的讨论。虽然书中提到的大多数研究都是在2017年之前完成的，但是这本书本身非常全面，并且对于理解离群值集成方法有着丰富的细节

#### 集成方法的优劣：

**它们更稳定，并提供更好的预测模型**。像boosting和bagging这样的算法的可用性增强了集成方法，使其更有效地执行。**它们适用于高维数据中的离群值分析**;例如，Lazarevic等人[37]将特征装袋应用于高维数据中的离群值检测。在噪声和流场景中，由于处理时间和数据质量问题**，单个分类器的结果不是很鲁棒，集成分析是有用的**。

与其他数据挖掘问题相比，在检测离群值的上下文中的集成技术开发得很差。此外，选择正确的元检测器是一项艰巨的任务。对于真实的数据集，由于较小的样本空间及其无监督性质的组合，离群值分析可能非常复杂。

为了解决这些挑战和Zimek等人提出的许多其他挑战。[181]，已经提出了几种额外的方法[38]，[182]，[190]-[192]来使用集成方法改进离群值检测，但这些方法中的大多数都是Meta方法，除了[37]提出的方法。为了进一步讨论和深入研究离群值集成技术，Zimek等人。[181]在他们的研究中提出了使用集成方法检测离群值的几个开放性问题和挑战。一些技术[181]，[184]是静态的，不涉及任何检测器选择方法。这种技术[184]的特点是没有检测器选择过程，这阻碍了识别未知离群值情况的方式的性能。另一个没有得到太多关注的重要方面是数据局部性的重要性。

### 2.6 基于学习的方法

离群值检测过程中基于学习的方法已应用于机器学习的不同子学科-**主动学习，基于图的学习和深度学习**。

#### 2.6.1 主动学习

主动学习是半监督学习方法的一个例子，其中设计的算法与用户或信息源交互以获得所需的输出[193]，[194]。主动学习类似于一个系统，其中学习算法可以请求用户输入实例的标签以给出更好的预测。异常值检测的主动学习最近被不同的研究领域所接受[195]-[199]。Aggarwal等人。[6]在离群值检测中使用主动学习的概念来解决给出离群值被标记的明确原因以及促使基于密度估计的OD方法的相对高的计算需求的模糊性。Gornitz等人。[200]提出了另一项工作，其中应用主动学习策略进行异常检测。

Das等人。[196]，[197]使用主动方法询问人类分析师以获得更好的结果。在2019年，Das等人。[201]然后提出了一种通过集成的主动离群值检测方法，称为GLocalized Anomaly Detection（GLAD）。在GLAD中，最终用户保持使用适度和可理解的全局离群值检测器。这是通过标签反馈自动学习特定数据实例中的局部权重来实现的。

人类分析员发现真实异常值的过程可能是困难的，未来人类分析员需要通过设计和配置有效的异常值检测器来最小化误报的影响的技术。此外，需要更好地了解和解释离群值分数和通过采用不同算法获得的相关结果。在离群值检测的背景下，主动学习需要坚实的解释和解释，以便在研究界得到很好的理解。

#### 2.6.2 子空间学习

在这一点上提到的离群点检测方法通常从考虑所有维度的完整数据空间中检测离群点。但大多数离群点通常表示为降维子空间中的罕见邻域活动。Zimek等人。[179]指出，只有具有重要属性的子集才能提供有价值的信息。

在孤立点检测领域，子空间学习在高维问题中得到了广泛的研究和应用。这**些方法主要分为稀疏子空间[195]，[196]和相关子空间[126]，[198]，[202]方法**。**前者将高维数据点投影到稀疏的低维子空间上。然后，稀疏子空间内的这些对象可以被标记为离群值，因为它们具有较低的密度**。这些方法的一个**很大的缺点是从整个高维空间探索稀疏投影的时间消耗**。为了解决这个缺点**，Aggarwal等人。[6]提出了一种方法，提高了探索子空间的有效性**。子空间是通过进化算法实现的。然而，该算法的性能评估是高度依赖于初始种群。

Dutta等人[196]提出了一种实现稀疏空间的方法。他们应用稀疏编码将对象开发到多个线性变换空间。Huang等人。[126]提出了子空间离群点检测（SOD），一种相关子空间方法。在这里，每个对象与其共享的最近邻居的相关性被检查。

在类似的研究中，Kriegel等人[17]应用主成分分析来获得相关子空间，并通过伽马分布计算Mahalanobis距离来检测离群值。Keller等人。[85]设计了一种灵活的OD技术，该技术使用子空间搜索和离群值排名过程。最初，他们使用蒙特卡罗抽样方法获得高对比度子空间（HiCS），然后基于HiCS组合LOF分数

#### 2.6.3 基于图的学习

Akoglu等人。[34]，提出了一个全面的调查基于图的离群检测技术和描述。其中包括最先进的方法和一些开放的研究挑战和问题。此外，还指出了在离群点检测技术中采用图的重要性。**基于图的异常值检测方法至关重要，因为它们显示了数据的相互依赖状态、富有洞察力的表示和强大的机制**。

**Moonesinghe等人。[204]提出了Outrank，这是第一个构建的基于图的离群点检测框架之一**。从原始数据集，他们开发了完全链接的无向图，并在预定义的图上应用马尔可夫随机游走方法。

Wang等人。[205]提出了一种新的方法，将图的表示与每个对象在其周围环境中的局部信息结合在一起。Wang等人[206]在另一项研究中提出了另一种OD方法，该方法从不同的角度捕获不同的局部信息。然而，由于使用基于图的学习方法尚未被广泛接受，因此它是未来离群点检测研究的另一个领域。

#### 2.6.4 深度学习方法

最近，深度学习在许多领域得到了更多的关注，包括与离群值检测问题相关的几项研究[35]，[36] [30]，[207]-[209]。最近，Chalapathy和Chawla [32]在他们的调查中提出了一项针对离群值检测的深度学习方法的全面研究。他们回顾了深度学习方法如何用于各种异常值检测应用程序并评估其有效性。深度学习可以基于监督、半监督和无监督的方法来学习数据表示。

在有监督的深度OD方法中，通过利用正常和异常数据实例的标签来训练二进制或多类分类器。虽然有监督的方法被证明具有改进的性能，**但是，大多数采用半监督和无监督的方法。这是因为，监督方法缺乏标记训练数据的准备，并且存在类不平衡的问题，这使得它对其他方法来说是次优的**。

在大多数无监督深度OD模型中，自动编码器起着核心作用[210]，[238]。采用深度学习技术的OD方法的大多数新兴研究都使用无监督方法。使用深度学习解决无监督离群点检测问题已被证明是有效的[211]，[212]。它们大部分被分类为采用自动编码器的模型架构[213]和混合模型[214]。Dan等人[215]提出了离群值暴露（OE）来提高离群值检测性能。

在另一项研究中，Du等人[216]提出了Deeplog，这是一种通用框架，采用深度神经网络方法进行在线日志离群值检测和分析。Borghesi等人。[217]提出了一种通过采用一种称为自动编码器的神经网络来检测高性能计算系统（HPCS）中异常的新方法。

在深度OD方法中，基于训练目标，这些方法可以采用深度混合模型（DHM）或一类神经网络（OCNN）[32]。Chalapathy等人。[218]和Ruff等人。[219]分别提出了一类神经网络和深度一类分类。单类神经网络（OC-NN）结合了深度网络提取数据丰富特征表示的能力，以及单类在正常数据周围创建紧密拟合结构的优势。

#### 2.6.5 基于学习方法的优劣

在基于OD的学习方法中，例如在**主动学习中，由于该技术不是被动学习，因此减少了检测离群值的时间消耗**。它有助于减少训练模型以发现离群值所需的标记数据的数量。**基于图的方法显示了数据的重要的相互依赖状态**，并为异常值的检测提供了一种有见地的表示。**深度学习技术有助于提供和展示从数据中学习分层区别特征的更好方法**。它们为检测大规模数据中的异常值提供了更好的方法。此外，它们还提供了更好的方法来设置连续变化的数据集中正常和异常行为之间的界限。

一些基于学习的技术，如子空间学习，可能是**计算昂贵的**，**并具有挑战性的发现离群值的相关子空间**。

### 3、异常检测问题的评估技术、工具和数据集

#### 3.1 评估方法

与分类问题相比，孤立点检测算法的性能评价更为复杂。研究人员已经提供了几种采用的测量方法来评估离群值检测算法的性能[223]。它们的定义如下：

> 1、Precision：表示**正确离群值数量m除以离群值总数t的比值**。**在特定的应用中，设置t可能是困难的。因此，t通常被指定为地面真实值中离群值的数量**。
>
> 2、R-precision：这是指**正确离群值在识别出的最大数量的地面真实潜在离群值中的比例**。R-精度不包含足够的信息，因为与数据的总大小相比，真实离群值的数量是最小的。
>
> 3、Average precision：**这表示在离群点的等级上的精度分数的平均值。它结合了召回率和精确度**。
>
> 4、Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)：ROC是示出了真阳性率对假阳性率的曲线图。**真阳性率或假阳性率表示实际数据中离群值最多的潜在离群值中离群值或内值的数量。AUC显示了离群值检测方法的数值评价性能**。
>
> 5、Correlation coefficient：是相关性的数值度量，即，两个变量之间的统计关系。例如，斯皮尔曼等级相似性或皮尔逊相关性。**更重要的是放在可能的离群值排名在顶部**。
>
> 6、Rank power (RP)：它将真正的离群值排在顶部，将正常值排在底部。它全面评估真实离群值的排名。

大多数评估方法是启发式的，并侧重于精度，受试者工作特征（ROC）曲线和曲线下面积（AUC）显示结果。**这些评价程序的缺点是，没有提供方法之间的相似性检查。了解离群值评分的相似性或相关性被认为是构建更好OD方法的非常重要的一步**。**AUC完全忽略了分数之间的微小变化，只考虑排名**。**与精确率-召回曲线下区域等技术相比，它对于不平衡的类问题也较差且不完美，而精确率-召回曲线下区域等技术在突出微小的检测变化方面显示出更好的可能性**。然而，尽管存在这些缺点，**AUC，ROC和精确召回仍然作为评估许多离群值检测问题的事实上的标准**。由于了解离群值评分的相似性或相关性是构建更好OD方法的重要一步，**Schubert等人[191]在其研究中给出了一个全局视图，允许评估不同方法的性能**。该框架考虑了类不平衡的问题，然后提供了一个新的理解流行的离群点检测技术的相似性和冗余。为了实现对离群值排名和分数进行更好评价的主要目标，建立了一种适当的相关性度量，用于通过考虑离群值分数来比较排名。

Goldstein等人。[102]提出了一种相对通用的评估，使用10个公开可用的数据集对19种不同的无监督离群值检测算法进行评估。主要目的是解决缺乏有趣的文献存在[224]，[225]，这给出了一个更好的评价离群值检测算法。他们研究的关键发现是**LOF [8]，INFLO [75]，COF [80]和Loop [81]等局部离群值检测算法不适合检测全局离群值**，因为它们在由全局离群值组成的数据集上表现不佳。此外，他们发现基于聚类的算法在大多数情况下不如基于最近邻的算法。**建议对于全局任务应用最近邻技术，而对于局部任务，LOF等局部离群算法比其他基于聚类的方法更适合**。

**Campos等人[226]与[97]类似，在各种特定数据集上进行了实验研究，以观察不同无监督离群值检测算法的性能**。在他们的研究中，**他们对不同的数据集进行了分类，并仔细考虑了它们作为离群值检测标准数据集的合适程度**。此外，他们还进一步讨论和检查了比较离群值检测性能的常用方法/措施。通常，数据集中的大比例离群值不适合评估离群值检测技术，因为离群值在数据集中不太常见。**在大多数情况下，一小部分离群值和标准化数据集通常会产生更好的性能**。另一个重要的误解是关于维度的影响。**维数的增加通常会导致高计算成本，但与整体性能不成正比，特别是在检测率方面**。

#### 3.2 异常检测工具

**异常值检测在工业应用中的流行已经看到了许多软件工具的开发**，例如下面提供的以下软件工具。

> 1、Scikit-learn Outlier Detection：scikit-learn项目提供了一些机器学习工具，可用于离群值检测问题。它包括一些算法，如LOF [8]和隔离森林[192]。
>
> 2、Python Outlier Detection (PyOD)：**PyOD用于检测多变量数据中的离群值**。它是一个可扩展的Python工具，已被用于许多研究和商业项目，包括新的深度学习和离群集合模型[60]，[62]，[233]。
>
> 3、Environment for Developing KDD-Applications Supported by Index-Structures (ELKI) [43]：ELKI是一个开源的数据挖掘算法，它提供了一系列数据挖掘算法，包括OD算法。它允许OD算法的轻松和公平的评估和基准测试。它是用Java实现的。
>
> 4、Rapid Miner [234]：该工具的扩展包含许多流行的无监督离群值检测算法，如LOF，COF [80]，LOCI [82]和Loop [81]。
>
> 5、MATLAB [235]：MATLAB还支持许多异常值检测算法和函数。算法可以使用MATLAB实现，因为它是用户友好的。
>
> 6、Massive Online Analysis (MOA) tool [143]：MOA是一个开源框架，提供了一个数据流挖掘算法的集合。包括基于距离的孤立点检测算法COD、ACOD、Abstract C、MCOD以及一些评价工具。

#### 3.3 异常检测数据集

离群点检测方法已应用于不同类型的数据，例如**规则和高维数据集[240]，流数据集，网络数据，不确定数据[241]和时间序列数据**。在离群检测文献中，主要考虑两种类型的数据，并需要评估算法的性能。**它们是真实世界的数据集和合成数据集**。现实世界的数据集可以从公开的数据库中获取。一些最流行和最有用的数据库包含用于离群值检测的真实数据集，包括以下内容：

> 1、The UCI repository：UCI存储库有数百个免费的数据集，许多OD方法使用存储库来评估算法的性能。**然而，这些数据集中的大多数都是为分类方法设计的**。**在离群值检测场景中，通常使用的方法是对数据集进行预处理。异常值表示次要类中的对象，其余的被认为是正常的**。
>
> 2、Outlier Detection Datasets (ODDS) [51]：与UCI存储库不同，**ODDS提供对仅适用于离群值检测过程的数据集集合的开放访问。这些数据集分为不同的类型，包括多维数据集，时间序列单变量和多变量数据集，以及时间序列图数据集**。
>
> 3、ELKI离群数据集[50]：ELKI有一系列用于离群值检测的数据集，也有许多用于OD方法评估的数据集。这些数据集用于研究几种OD算法和参数的性能。
>
> 4、Unsupervised Anomaly Detection Dataverse [49]：这些数据集用于通过与标准进行比较来评估无监督离群值检测算法。它是从多个来源获得的，其中大部分数据集来自监督机器学习数据集。

合成数据集通常是在定义的约束和条件下创建的。**与真实世界的数据集相比，合成数据集的复杂性和偏心性都较低，并且显示出OD算法性能的更好有效性**。对于离群值检测过程，由于所采用的大多数数据对于OD方法来说不是特定于目的的，因此监督分类数据的再利用已被广泛采用。在许多研究中，数据被原样处理，而不是被操纵。

在大多数监督分类类型的数据集中，它们需要对离群值检测任务进行一些预处理。在预处理阶段考虑两个重要方面[226]。也就是说，对于语义上显著的离群数据集，离群值是与次要对象相关的类，而正常数据是数据的其余部分。

处理数据集的其他一些问题包括**如何处理数据的下采样，处理重复数据，将分类属性转换为数值类型，规范化以及处理缺失值**。在未来的工作中，**研究如何评估离群点检测方法的数据集以及需要考虑哪些关键属性将是至关重要的**。