## 一、《ADBench: Anomaly Detection Benchmark》

### 1、主要贡献

1、**最全面的AD基准**。ADBench在57个基准数据集上测试了30种检测算法的性能。算法类别包括**（i）最新的无监督AD算法，（ii）SOTA半监督算法，（iii）最新的网络架构，（iv）集成学习方法**。公共AD数据集。在ADBench中，我们收集了4**0多个基准测试数据集[25、42、129、145]**，用于模型评估，为了进行尽职调查，我们**保留异常率低于40%的数据集**。数据集涵盖了医疗保健，音频和语言处理，图像处理和金融等领域。**由于大多数数据集相对较小，因此我们在ADBench中引入了CV和NLP域的10个更复杂的数据集**。

![image-20240907173416676](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173416676.png)

2、**公平和可访问的AD评估**。https://github.com/Minqi824/ADBench上以BSD-2许可证开源了ADBench

### 2、异常检测算法

1、**通过假设异常数据分布的无监督方法**。**如[3，15，129，150，198]**，大致分为浅层和深层（神经网络）方法。前者通常具有更好的可解释性，而后者更好地处理大型、高维数据。

2、**将异常检测视为二进制分类的监督方法**。没有专门的监督异常检测算法，人们经常为此使用**现有的分类器[3，170]，如随机森林[21]和神经网络[89]**。这些方法仅限于检测未知类型的异常[3]。最近的**机器学习书籍[4，54]和scikit-learn [133]可以作为监督ML方法的良好来源**。

3、**有效使用标签的半监督方法**。半监督AD算法可以利用部分标签的监督，同时保持检测不可见类型异常的能力。一些半监督模型仅在正态样本上训练，并且检测偏离在训练过程中学习到的正态表示的异常**[7，8，188]**。在**ADBench中，半监督主要指弱监督下的不完全标签学习**

### 3、现有的表格异常检测数据集和基准

1、现有基准主要评估来自**ODDS库[145]、DAMI库[25]、ADRepository [129]和异常检测荟萃分析基准[42]**的部分数据集。在ADBench中，我们包含了几乎所有公开可用的数据集，并添加了**从CV和NLP领域改编的更大的数据集**，以获得更全面的视图。**现有的基准包括[25, 38, 42, 150, 166]**

### 4、ADBench中的异常类型

我们在公共数据集的基础上，通过注入特定类型的异常来创建合成数据集，以分析AD算法的响应。**我们遵循并丰富了[166]中的方法来生成“真实”的合成数据**;我们的方法支持更多类型的异常生成

> **局部异常是指偏离其局部邻域的异常[22]**。我们**遵循GMM过程[118，166]来生成合成正态样本，然后通过缩放参数α = 5来缩放协方差矩阵= α以生成局部异常**。
>
> **全局异常与正态数据[68]有更大的不同，由均匀分布生成**。
>
> **依赖异常是指不遵循正常数据遵循的依赖结构的样本[117]**，即，**依赖性异常的输入特征被假定为彼此独立**。**我们使用核密度估计（KDE）[61]来估计特征的概率密度函数并生成正常样本。Vine Copula [1]方法用于生成异常样本**
>
> **异常群，也称为群异常[93]，表现出类似的特征**

局部异常（图3a）与正常样本有很好的重叠。全局异常（图3b）更偏离正常样本，并且位于正常聚类的边缘。

### 5、测试模型鲁棒性

我们试图通过在三种噪声和腐败设置下评估AD算法来评估异常检测模型的鲁棒性：
**1、重复异常**。在许多应用中，由于记录错误等原因，某些异常可能会在数据中重复多次[83]。**重复异常的存在也被称为“异常屏蔽”[55、60、100]**，这**对许多AD算法[25]提出了挑战，例如，基于密度的KNN [11，144]**

**2、不相关的特征**。**表格数据可能包含由测量噪声或不一致的测量单位[28，55]引起的不相关特征，其中这些噪声维度可能隐藏异常数据的特征，并因此使检测过程更加困难[128，150]**。

**3、注释错误**。虽然现有研究[131，152]探讨了未标记样本中的异常污染，但我们进一步讨论了标记污染对算法性能的更普遍影响，**其中考虑了正常样本和异常之间的标记翻转[122，202]（高达总标记的50%）**。此设置不影响未受监督的方法，因为它们不使用任何标签。

### 6、实验结果与分析

#### 6.1 实验设置

1、**训练集与测试集比例。7比3的比例，流行的AD库包括PyOD [198]，TODS [84]和PyGOD [102]**

2、超参数设置。我们使用了它们在原始论文中的**默认超参数（HP）设置**

**3、评价指标和统计检验。我们通过两个广泛使用的指标来评价不同的AD方法：**

> **AUCROC（受试者操作特征曲线下的面积）**
>
> **AUCPR（精确度-回忆曲线下的面积）。**
>
> **基于Wilcoxon-Holm方法的临界差异图（CD图）[34，70]用于统计学比较AD方法组（p ≤ 0.05）**

#### 6.2 具有不同监督程度的数据集上的整体模型性能

1、没有一种无监督的方法在统计学上比其他方法更好

2、当标签信息有限时，半监督方法优于监督方法

3、最新的网络架构（如Transformer）和新兴的集成方法在AD中具有竞争力的性能

4、**HBOS、COPOD、ECOD和NB是最快的，因为它们独立处理每个功能。XGBOD、ResNet和FTTransformer的计算量很大**

5、未来方向。注意算法选择，超参数优化和**半监督AD方法**

#### 6.3 不同类型异常下的算法性能

**1、无监督算法的性能高度依赖于其假设和潜在异常类型的对齐**。**局部异常因子（LOF）在统计上优于局部异常的其他无监督方法**。**KNN是全局异常的统计最佳检测器**。没有算法在所有类型的异常上都表现良好

2、**关于异常类型的先验知识的“力量”可能超过部分标签的使用**。对于局部、全局和依赖异常，大多数标签通知方法的性能都比每种类型的最佳无监督方法差。利用异常类型作为有价值的先验知识。即使在没有标签的情况下，了解异常类型在实现高检测性能方面的重要性。

![image-20240907173452258](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173452258.png)

![image-20240907173533060](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173533060.png)

![image-20240907173629307](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173629307.png)

![image-20240907173911408](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173911408.png)

![image-20240907173956387](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907173956387.png)

#### 6.4 算法在噪声和破坏数据下的鲁棒性

**1、无监督方法更容易受到重复异常的影响**。

**2、由于特征选择，不相关的特征对监督方法的影响很小**。例如，像XGBoost这样的集成树可以过滤不相关的特征，此外，监督方法（和一些半监督方法，如DevNet）的鲁棒性能表明，标签信息可以有利于特征选择。

**3、半监督和全监督方法都对轻微的注释错误表现出很大的弹性**。尽管**当注释错误严重时这些方法的检测性能显著降级**，但是它们关于较小注释错误的降级是可接受的。

![image-20240907174157311](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907174157311.png)

## 二、《Generalized Out-of-Distribution Detection: A Survey》

### 1、 Outlier Detection

1、背景：**AD、ND、OSR和OOD中的问题设置检测与训练数据分布不同的未见过的测试样本。相比之下，离群值检测直接处理所有观测值，旨在从污染数据集中选择离群值[12，13，14]**。由于离群值检测不遵循训练测试程序，但可以访问所有观察结果，因此**解决这个问题的方法通常是转导而不是归纳[75]**。

2、定义：离群点检测的目的是检测**由于协变量或语义变化而与给定观测集中其他样本显著不同的样本**。**与所有先前的子任务不同，其内分布是在训练期间定义的，离群值检测的“内分布”是指大多数观察值。由于P（Y）上的语义移位或P（X）上的协变量移位，可能存在离群值**。

3、离群值划分：**要在MNIST上构建离群值检测基准，应选择一个类，以便将属于该类的所有样本视为内点。一小部分来自其他类别的样本被引入作为待检测的离群值。**

4、评价方案：除了**F-scores，AUROC和AUPR**之外，离群检测器的评估还可以通过其支持的主要任务的性能来评估。例如，**如果使用离群值检测器来净化具有噪声标签的数据集，则在经净化的数据集上训练的分类器的性能可以指示离群值检测器的质量**。

### 2、AD、ND和OD检测的方法

#### 2.1 Anomaly Detection & Novelty Detection

**1、基于密度的方法：**

> **基于密度的方法对正态数据（ID）分布进行建模，假设异常测试数据具有较低的可能性，而正常数据具有较高的可能性**。
>
> **参数密度估计假设预定义的分布**[272]。方法涉及多元高斯分布[273，274]、混合高斯分布[275，276]和泊松分布[277]。
>
> **非参数密度估计使用直方图**[279，280，281，282]和核密度估计（KDE）[283，284，285]处理更复杂的场景[278]。
>
> **神经网络**生成高质量的特征，以增强经典的密度估计。自动编码器（AE）[286]和变分自动编码器（VAE）[287]的模型、生成对抗网络（GAN）[288]、基于流的模型[195，289]和表示增强策略
>
> **EBM使用标量能量分数来表达概率密度[290]并为AD提供解决方案[291]**。

**2、基于重建的方法：**

> **这些AD方法利用特征空间中的正常和异常数据或重建误差的模型性能差异。**
>
> **稀疏重建**假设正常样本可以使用有限的基函数集精确重建，而异常具有更大的重建成本和密集表示[297，298，299]。技术包括基于L1范数的内核PCA [300]和低秩嵌入式网络[301]。
>
> **重建误差方法**假设在正常数据上训练的模型将为正常测试样本产生比异常更好的重建。深度模型包括AE [302]，VAE [303]，GAN [304]和U-Net [305]。基于AE/VAE的模型将联合收割机重建误差与AE/VAE模型[302，303]相结合，并使用诸如通过记忆的常态重建[306，307]，适应模型架构[308]和部分/条件重建[192，309，310]等策略。在半监督AD中，CoRA [311]使用重建误差进行异常检测，在内点和离群点上训练两个AE。使用GAN的重建误差方法利用GAN来计算异常检测的重建误差[304]。去噪GAN [194]，类条件GAN [54]和集成[312]等变体进一步提高了性能。基于梯度的方法在重建任务中观察训练梯度和异常之间的不同模式，使用基于梯度的表示来表征异常[313]。

**3、基于距离的方法：**

> **基于距离的方法**通过计算样本和原型之间的距离来检测异常[314]，需要内存中的训练数据。方法包括**K-最近邻[315]和基于原型的方法[316，317]**。

**4、基于分类的方法：**

> AD和单类ND通常被表述为无监督学习问题，但也有一些**监督和半监督方法**。**单类分类（OCC）直接学习与正态数据分布的期望密度水平集相对应的决策边界[318]**。**DeepSVDD [319]将经典OCC引入深度学习社区**。**PU学习[320，321，322，323]被提出用于半监督AD设置**。**自监督学习方法使用借口任务，如对比学习[139]，图像变换预测[324，325]和未来帧预测[326]**，其中异常更有可能在设计的任务中出错。

**5、理论分析：**

> 一些工作中也提供了对AD和一类ND的理论分析。例如，**[58]构建了一个干净的ID集和一个具有相同样本量的ID/OOD混合集，实现了一个PAC式的有限样本保证，用于以最小的虚警数量检测特定部分的异常**。

#### 2.2 Outlier Detection

离群值检测（OD）观察所有样本，以识别与多数分布的显著偏差。

**1、基于密度的OD方法：**

> 包括**高斯分布[327，328]，马氏距离[273]，高斯混合[329]和局部离群值因子（LOF）**[330]。**RANSAC [331]估计数学模型的参数。还可以应用经典密度方法和基于KNN的密度方法**。

**2、基于距离的方法：**

> 离群值可以通过**邻居计数**[332，333]，**DBSCAN聚类**[334]和**基于图形的方法**[335，336，337，338，339，340，341，342，343]来检测。

**3、基于分类的方法：**

> AD方法，如**隔离森林[344]和OC-SVM** [318，319]可以应用于OD。**深度学习模型**可以识别离群值[345]。鲁棒性和特征泛化的技术包括**集成[346]，协同训练[347]和蒸馏[345，348]**。

![image-20240907175554569](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907175554569.png)

## 三、《Empirical study of outlier impact in classification context》

### 1、离群点检测技术

离群点检测技术可以大致分为以下几类：**基于统计/基于分布的算法、基于距离的算法、基于密度的算法和基于聚类的算法**

> (1) **在基于统计的算法中，离群值是与标准分布有很大偏差的观测值**。**统计方法具有明显的缺点，即不适用于统计分布未知的数据集**。
>
> (2) **基于距离的方法来检测离群值，这是最常用和最简单的检测方法**。在这些方法中，离群点被识别为远离其相邻点的点。注意到，**当处理高维数据集时，基于距离的方法计算量大，并且难以检测正常对象边界内的离群值**。
>
> (3) **基于密度的方法，其中离群值被假设为具有比它们的邻居更低的密度**。与基于距离的方法不同，**基于密度的方法（Bai等人，2016; Breunig等人，2000; Tang & He，2017; Xie et al.，2020）比较对象的密度与其邻居的密度**。存在许多经典的基于密度的方法，包括**局部离群值因子（LOF）**（Breunig等人，2000）和**低密度模式（COF）**的离群值检测（Tang等人，2002），尽管给定的数据集可能具有不同程度的聚类密度，但其功能良好。Campos等人（2016）发现，**LOF检测器是使用KNN技术的12个检测器组中最精确的**。**当使用基于密度的方法时，必须选择最佳邻居参数k以获得必要的邻居信息**，当特定项目的邻居分布在密度变化的两个集群之间时，精确地测量它们的密度变得困难。
>
> (4) **基于集群的方法**。**（Chen等人，2024; Kang，2022; Li等人，2022）首先对数据集进行聚类，然后计算每个聚类而不是每个单独对象的离群值程度**。**基于聚类的方法的有效性在很大程度上取决于正常对象的聚类效果。如果聚类结果是不利的，则检测离群点的结果是无效的**。**ROCF聚类算法**是专门设计来检测离群聚类，以提高基于聚类方法的效率。**在Yu和Kang（2023）中，提出了一种基于聚类集成的新奇得分算法**，其中将随机子空间和随机k集成方法生成的多个聚类解决方案相结合以计算新奇得分。在基于聚类的集成方法中，为了实现个体分类器的多样性，创建尽可能多的聚类是很重要的。**由于大量的聚类，每个聚类都有少量的观察结果，导致单个分类器的效率低下**。

### 2、相关工作

> 1、Qin et al.（2019）提出了**使用核密度估计估计局部离群值，称为KELOS**，以高效检测窗口化数据流中的top-n局部离群值。
>
> 2、**Yoon et al.（2020）采用了不同的剪枝策略来检测窗口数据流中的前n个局部离群值**。
>
> 3、近年来提出了一种**基于二元分类器集合的一类分类器（BCE-OC）（Kang，2022）**。
>
> 4、**Chen et al.（2024）还描述了一种基于密度的空间聚类方法（DBSCAN）**。
>
> 5、**为了克服参数敏感性问题以及现有离群值算法难以同时检测聚类和局部离群值的问题，Huang et al.（2023）首先基于样本间距离计算了转弯密度**。然后，根据k-最近邻和逆k-最近邻的计数，计算样本的转弯比。最后，使用每个样本的转向密度和转向比来计算离群转向因子（OTF）。当OTF值较高时，更有可能出现离群值。
>
> 6、**Zhou et al.（2024）提出了一种用于检测离群值的高密度迭代方法**。与其他基于k-近邻的方法相比，**该方法更适合于各种复杂的数据分布**。
>
> 7、**Tran et al.（2020）使用“核心点”数据结构实施了一种新的离群值检测系统**，该数据结构通过多个距离进行索引。
>
> 8、为了克服基于密度的离群点检测方法的局限性，**熊等（2022）提出了邻域加权离群点检测算法（NWOD）**
>
> 9、**Li等人（2022）使用了一个扩展的近邻集，其中包括k-最近近邻以及反向k-最近近邻，以适应复杂的数据分布**。
>
> 10、**Yuan et al.（2018）提出了一种混合数据驱动的离群值检测方法**。
>
> 11、对于异常值的检测，**Zhang等人（2023）提出了一种多源信息融合方法**。
>
> 12、此外，**在Xie et al.（2020）中，提出了LGOD检测模型来检测异常值**，该模型同时考虑了对象的质量和由其邻居产生的局部合力（LRF）。
>
> 13、**在Wang和Mao（2019）中，为了监测工业过程，提出了一种基于单类分类的动态集成离群值检测方法**。他们生成伪离群值，然后将基础分类器的所有输出转换为概率模型
>
> 14、此外，**Baldomero-Naranjo等人（2021）提出了一种基于支持向量机（SVM）的鲁棒分类模型**，该模型**同时检测离群值并从输入数据中选择特征**。
>
> 15、**Wang和Mao（2020）中检测和去除离群值的标准基于两个几何标准，即局部密度和与局部拟合平面的偏差**。作为Yang等人（2021）提出的均值漂移离群值检测（MOD）方法的一部分，计算样本最近邻的均值，以均值漂移方法执行数据集，并计算样本的偏移距离，以估计离群值的程度。
>
> 16、除了上面提到的离群值检测方法之外，**Yang等人（2023 b）提出了基于邻域一致性的搜索方法（KFC）**，**以确定最佳参数k**。**作为基于k-近邻的离群点检测方法的一部分，该方法试图解决最优参数的选择问题**
>
> 17、此外，还提出了不同的**基于图的离群值检测方法**，**例如Wang和Li（2021），Wang等人（2019）提出的工作**，首先构建一个图，然后采用定制的马尔可夫随机游走方法来检测图中的离群值。**在Huang et al.（2017）中，基于相互邻居图的概念，提出了一种称为ROCF的方法，其中通过设置聚类大小间隙来分离正常聚类和离群值**。**在Li et al.（2022）中，提出了一种密度距离决策图，它通过结合全局和局部离群值来同时检测全局、局部和聚类离群值**。利用样本与最近邻样本的密度比来判断局部离群点，利用密度提升距离来识别全局离群点。**基于图的方法特别强大，因为它具有强大的表达能力和捕捉一组数据中的长期相关性的卓越能力。尽管这些方法是有用和有效的，但缺点是它们需要大量的时间**。**Wang et al.（2018）提出了一种新的离群点检测模型，该模型将图表示与每个对象周围的局部邻域信息相结合，以构建局部信息图**。在该模型中，使用随机游走过程计算离群值评分。**此外，Pourhabibi et al.（2020）还概述了基于图的异常检测技术**。

### 3、实验研究

#### 3.1 实验设置

> **F1分数在处理不平衡数据集时非常有用，因为它同时考虑了假阳性和假阴性。与仅使用accuracy相比，此度量提供了对模型性能的更全面的评估。**此外，有10种不同的分类器被训练用于数据分类，包括**线性支持向量机（SVM）、K-最近邻（KNN）、随机森林（RF）、决策树（DT）、线性判别分析（LDA）和逻辑回归（LR）。此外，还使用基于集成的分类算法，诸如梯度提升（GB）、Bagging、AdaBoost和直方图提升梯度分类器（HBGB）**。**我们使用所有上述的分类器及其默认参数，除了在逻辑回归的情况下，我们将迭代次数设置为1000**。**最后，在所有数据集上执行5重交叉验证**。

![image-20240907181435656](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907181435656.png)

#### 3.2 实验结果

> 在所有数据集上的实验结果表明，**所提出的FCM-AD方法能有效提高分类准确率，但需要消耗更多计算资源**。因为**我们没有关于每个样本是否为离群值的真实依据**。在这种情况下，**如果在离群数据上训练模型，则输入数据中的离群值可能导致机器学习算法被不正确地训练**。

![image-20240907181509119](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907181509119.png)

![image-20240907181522609](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907181522609.png)

## 四、《Machine Learning for Anomaly Detection: A Systematic Review》

### 1、摘要和引言

1、本文从**异常检测的应用、ML技术、ML模型的性能度量和异常检测的分类**四个方面对模型进行了分析。我们识别了**29个不同的ML模型，用于识别异常**。最后，**我们在实验中测试了22个不同的数据集**

2、异常分为三大类[1]、[9]、[10]：

> **点异常**：**如果一个数据实例可以被认为是其余数据的异常，则该实例被称为点异常**，并被认为是最简单的异常形式。
>
> **上下文异常**：**如果在特定上下文中数据实例异常，但在另一个上下文中不异常，则称为上下文异常**。在某些情况下，识别上下文很容易，因此应用上下文检测技术是有意义的。
>
> **集体异常**：**如果一组关联的数据实例对于整个数据集是异常的，则称为集体异常**。

3、**统计异常检测技术是用于检测异常的一些最古老的算法**[10]。**统计方法为所提供的数据的普通行为建立统计模型。然后可以执行统计推断测试以检测实例是否属于该模型**。有几种方法用于进行统计异常检测[11]。这包括**基于邻近度的方法、参数方法、非参数方法和半参数方法**。

4、**机器学习（ML）技术越来越多地被用作检测异常的方法之一。**。**该技术被用来建立一个模型，区分普通和异常类**。

> **监督异常检测：**在这个类中，**正常和异常训练数据集都包含标记的实例**。在这个模型中，**方法是建立一个预测模型的异常和正常的类，然后比较这两个模型**。问题如下：**首先，与正常实例相比，训练集中异常的数量要低得多。其次，精确和代表性的标签是具有挑战性的识别，特别是对于异常类**。
>
> **半监督异常检测**：**这里的训练仅包括普通类案例**。因此，**任何不能被归类为普通的东西都被标记为异常**。。**由于它们不需要异常类标签，因此它们比监督方法更常见**。
>
> **无监督异常检测**：在这种情况下，**该方法不需要训练数据集**。因此，**这些方法意味着在测试数据集中，正常实例比异常实例更常见**。然而，**如果该假设失败，则导致该技术的高虚警率**。
>
> **许多半监督技术可以适于通过使用未标记的数据集样本作为训练数据而在无监督模式下操作**。**这种自适应假设测试数据中存在非常少的异常，并且这些异常对于训练期间的模型学习是鲁棒的**。

### 2、相关工作

1、**Albertola等人[1]提供了异常检测技术和应用的广泛调查。详细讨论了机器学习和非机器学习的不同技术**，同一作者介绍了**另一项关于离散序列异常检测主题的调查[10]**。此外，**Hodge和Austin [15]还对机器学习和统计异常检测方法进行了全面研究**。**文中对各方法的优缺点进行了比较**。另一方面，**Agrawal和Agrawal [8]提出了使用数据挖掘技术进行异常检测的综述**。

2、异常检测中最常用的计数分类：

![image-20240903195831062](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903195831062.png)

![image-20240903195752246](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903195752246.png)

### 3、机器学习技术类型

我们确定了28种ML技术，这些技术可分为六类：**分类、集成、优化、规则系统、聚类和回归**。这些ML技术以两种形式使用：**独立模型或混合模型**。表4显示了所收集的研究文章中ML技术的频率。**很多研究者过去常常将一种以上的ML技术结合起来。**。此外，**支持向量机是最常用的技术，无论是独立的还是在混合模型中**。

![image-20240903200952961](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903200952961.png)

**特征选择/提取**已经在文献中被广泛发现，并且它是朝着丢弃不相关数据的重要举措，这**有助于增强和提高所建议的模型的精度和计算效率**。图4展示了正在应用的21种不同的特征选择/提取技术。此外，**我们注意到PCA和CFS是异常检测中最常用的特征选择技术**。

![image-20240903201010569](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903201010569.png)

### 4、机器学习模型的总体估计和准确度

**估计精度是机器学习模型的主要性能指标**。本题重点关注以下四个方面的估计精度：**性能指标、精度值、用于构建的数据集和模型验证方法**。此外，**我们确定了22个不同的数据集**，这些数据集已用于相关文章的实验和许多其他一般数据集。**数据集可以被分类为合成数据、真实的生活数据和虚拟化数据**。此外，48篇研究论文使用**KDDCup 1999**虚拟数据集，**38篇研究论文采用基准数据集**。

![image-20240903201920698](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903201920698.png)

图6显示，**使用最多的性能指标是真阳性率（TPR）**，也称为灵敏度和召回率。**它测量被正确分类的异常**。此外，**116篇论文使用假阳性率（FPR）作为性能指标。该指标测量被错误分类的异常，也可以称为误报率**。此外，**准确度（Acc），精度和F-分数经常被研究人员作为性能指标**。**Acc是正确分类的异常百分比。此外，AUC测量整个ROC曲线下的整个二维面积**。**ROC曲线是用于有效评估入侵检测系统性能的最强指标之一，它是一种说明FPS准确性的图形工具**。另一方面，**精确度通常与F分数和召回率相关，它测量被正确分类为攻击的异常的比率**。此外，我们发现290篇论文中有64篇只使用了一个性能指标，**其中大多数论文只使用了准确性或AUC，这不足以确定ML模型的质量性能**。**另一方面，像A10和A69这样的论文使用7到9个性能指标来表示其ML模型的性能**。此外，**除了性能指标之外，许多论文还提出了计算性能指标，例如CPU利用率、执行时间、训练时间、测试时间和计算时间**。

![image-20240903202553328](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903202553328.png)

### 5、无监督、半监督或监督的异常检测技术的百分比

根据图7，**27%的选定论文应用了无监督异常检测类型，使其成为研究文章中使用最多的技术**。**另一方面，18%的人应用了监督异常检测，而7%的人同时应用了监督和非监督异常检测分类**。相比之下，**5%的研究文章采用了半监督学习。此外，1%的人应用半监督与非监督异常检测**。令人惊讶的是，**42%的研究文章没有提到他们应用的异常检测的分类类型**。

### 6、总结

我们展示了研究人员应用的**29种不同的ML模型**，其中**最常用的是SVM**。此外，我们注意到对**构建混合模型的兴趣****。此外，我们发现**PCA和CFS是21种特征选择/提取技术中最常用的**。在RQ 3中，我们介绍了每篇研究论文应用的性能指标，我们发现**290篇论文中有64篇使用准确性或AUC作为主要性能指标，这是不够有效的**。此外，**我们确定了22个不同的数据集，已被用于相关文章的实验以及许多其他一般的数据集**，**和大多数实验使用真实的生活数据集作为训练或测试数据集的模型**。最后，在RQ 4中，我们统计了所选研究文章中使用的异常检测分类类型。**我们发现27%的选定论文应用了无监督异常检测类型，使其成为研究文章中最常用的方法。其次使用最多的方法是应用监督异常检测，占18%，其次是7%的论文同时应用监督和非监督异常检测分类**。

## 五、《Deep Learning for Anomaly Detection: A Review》

本文对深度异常检测方法的研究进行了全面的分类，包括**3个高级分类和11个细粒度分类**。我们回顾了它们的**关键直觉、目标函数、基本假设、优缺点**。

### 1、本文的贡献点

> 1、分类和制定。我们将当前的深度异常检测方法制定为三个原则框架：**用于通用特征提取的深度学习，正常性的学习表示，以及端到端的异常得分学习**。一个层次分类法的基础上提出了**11个不同的建模角度的方法**进行分类。
>
> 2、综合文献综述。我们回顾了机器学习，数据挖掘，计算机视觉和人工智能，以全面的文献综述研究进展。为了提供深入的介绍，我们描述了**基本假设，目标函数，关键的直觉和它们的能力**，在解决上述一些挑战的所有类别的方法。
>
> 3、源代码和数据集。**我们征集了几乎所有类别的方法的公开源代码和大量具有真实的异常的真实数据集**，以提供一些经验比较基准。

### 2、问题复杂性

与大多数、规则或明显模式的问题和任务不同，**异常检测解决少数、不可预测/不确定和罕见事件，导致所有（深度和浅层）检测方法都存在一些独特的问题复杂性**：

> **不可知**。**异常与许多未知因素有关，突发行为、数据结构和分布未知的实例**。它们在实际发生之前是未知的，例如新的恐怖袭击、欺诈和网络入侵。
>
> **异常类。异常是不规则的**，因此，**一类异常可能表现出与另一类异常完全不同的异常特征**。例如，在视频监控中，异常事件抢劫、交通事故和入室盗窃在视觉上有很大的差异。
>
> **稀有和类不平衡**。异常通常是罕见的数据实例，与通常占数据绝大多数的正常实例形成对比。这导致在大多数应用程序中无法获得大规模标记数据。
>
> **各种类型的异常**。**点异常**是指相对于温度异常的个别情况。**条件异常**，又名上下文异常也指在特定上下文中的个别异常实例，即，数据实例在特定上下文中是异常的，否则是正常的。**群体异常，**又名集体异常是作为整个w.r. t异常的数据实例的子集。其他数据实例;集体异常的各个成员可能不是异常

### 3、现有的深度异常检测方法面临的挑战

> 1、**异常检测召回率低**。许多正常情况被错误地报告为异常，而真正复杂的异常却被遗漏了。当前最先进的方法，特别是无监督方法（例如，[17，84]），仍然经常在真实世界的数据集上产生高误报[20，115]。**如何减少误报和提高检测召回率是最重要但也是最困难的挑战之一，特别是未能发现异常的巨大代价**。
>
> 2、**高维和/或非独立数据中的异常检测**。**异常通常在低维空间中表现出明显的异常特征，而在高维空间中变得隐藏和不可察觉**。**在由原始特征或新构造的特征的小子集所跨越的降低的低维空间中执行异常检测是直接的解决方案**，例如，**在基于子空间[70，77，84，123]和基于特征选择的方法[12，109，111]中**。
>
> 3、**正常/异常的数据有效学习**。由于收集大规模标记异常数据的难度和成本，**完全监督的异常检测通常是不切实际的**，因为它假设具有正常和异常类别的标记训练数据的可用性。**在过去的十年中，主要的研究工作一直集中在无监督的异常检测，不需要任何标记的训练数据**。然而，**无监督方法不具有任何真实异常的先验知识。他们在很大程度上依赖于他们对异常分布的假设。另一方面，通常不难收集标记的正常数据和一些标记的异常数据。在实践中，经常建议尽可能利用这些易于访问的标记数据[2]**。因此，利用这些标记的数据来学习正常/异常的表达表示对于准确的异常检测至关重要。**另一个研究方向是弱监督异常检测，假设我们有一些异常类别的标签，但类别标签是部分/不完整的（即，它们不跨越异常类的整个集合），不精确（即，粗粒度标签），或不准确的（即，某些给定的标签可能是不正确的）**。两个主要的挑战是**如何学习表达正常/异常表示与少量的标记异常数据，以及如何学习检测模型**，被推广到新的异常发现的给定的标记异常数据。
>
> 4、**抗噪声异常检测**。**许多弱/半监督异常检测方法假设标记的训练数据是干净的，这可能容易受到错误地标记为相反类别标签的噪声实例的影响**。在这种情况下，我们可以使用无监督的方法，但这无法利用真正的标记数据。主要的挑战是，噪声的数量可能与数据集有很大的不同，并且噪声实例可能不规则地分布在数据空间中。
>
> 5、**检测复杂异常**。**现有的大多数方法都是针对点异常的，不能用于条件异常和群异常**，因为它们表现出与点异常完全不同的行为。这里的一个主要挑战是**将条件/组异常的概念纳入异常测量/模型**。另一个主要的挑战是，**一些异常只有在考虑两个或更多数据源时才能检测到**。
>
> 6、**异常现象解释**。在许多安全关键领域中，**如果将异常检测模型直接用作黑盒模型，则可能存在一些重大风险。缓解此类风险的一种有效方法是使用异常解释算法，提供有关特定数据实例被标识为异常的原因的直接线索**。然后，**人类专家可以调查并纠正这种偏见**。在一些应用中，提供这样的解释可能与检测准确性同样重要。**大多数异常检测研究只关注检测的准确性，而忽略了对已识别异常的解释能力**。

**深度方法可以实现整个异常检测管道的端到端优化，并且还可以学习专门为异常检测定制的表示。这两种能力对于应对上述六大挑战至关重要，但传统方法不具备。**

### 4、深度异常检测的分类

**从建模的角度将深度异常检测方法分为三个主要类别和11个细粒度类别**。方法分类的概述如图1所示。具体来说，深度异常检测由三个概念范式组成-**用于特征提取的深度学习，学习常态的特征表示和端到端异常得分学习**。

![image-20240903211755055](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903211755055.png)

#### 4.1 用于特征提取的深度学习

1、**这类方法旨在利用深度学习从高维和/或非线性可分离的数据中提取低维特征表示，用于下游异常检测**。特征提取和异常评分是完全脱节的，彼此独立。因此，深度学习组件仅作为降维工作。**与异常检测中流行的降维方法（如主成分分析（PCA）[21，140，180]和随机投影[80，112，123]）相比，深度学习技术在提取语义丰富的特征和非线性特征关系方面表现出更好的能力[14，49]**。深度学习模型提取的特征表示保留了有助于将异常与正常实例区分开的区分信息。

2、**一条研究路线是直接使用流行的预训练深度学习模型，如AlexNet [75]，VGG [143]和ResNet [58]来提取低维特征**。此外，与许多其他任务类似，**从在源数据集上预训练的深度模型中提取的特征表示可以被转移到目标数据集上微调异常检测器**。这一类别中的**另一个研究方向是明确地训练深度特征提取模型，而不是用于下游异常评分的预先训练的模型**[44，65，163，168]。

3、**优势是**(i)大量最先进的（预先训练的）深度模型和现成的异常检测器是现成的。(ii)深度特征提取比常用的线性方法具有更强的降维能力。(iii)由于深层模型和检测方法的公开可用性，该方法易于实现。**缺点是**(i)特征提取和异常评分完全脱节，往往导致异常评分不理想。(ii)预先训练的深度模型通常限于特定类型的数据。

#### 4.2 学习正态性的特征表征

**这类方法在某种程度上将特征学习与异常评分相结合，而不是像上一节那样完全解耦这两个模块**。这些方法通常分为两类：**通用特征学习和异常度量相关特征学习**。

##### 4.2.1 通用特征学习

**这类方法通过优化并非主要针对异常检测设计的通用特征学习目标函数来学习数据实例的表示，但学习的表示仍然可以增强异常检测**，因为它们被迫捕获一些关键的底层数据。此类方法代表性技术有**自动编码器（AE）、生成性对抗网络（GAN）和自监督模型分类。

1、**自动编码器的优点如下**。

> (i**)不良事件的概念是直接的，对不同类型的数据是通用的**。
>
> (ii)可以利用**不同类型的强大AE变体来执行异常检测**。

它们的**缺点**如下。

> (i)**所学习的特征表示可能由于训练数据中的不频繁的规则性和离群值或异常的存在而有偏差**。
>
> (ii)**数据重构的目标函数是针对降维或数据压缩而设计的，而不是异常检测**。结果，所得到的表示是底层规则性的一般概括，其对于检测不规则性不是最佳的。

2、**生成式对抗网络的优点如下**。

> (i)GAN已经证明了在**生成真实实例方面的上级能力，特别是在图像数据上**，使得能够检测到从潜在空间重构较差的异常实例。
>
> (ii)**大量现有的基于GAN的模型和理论[32]可适用于异常检测**。

**缺点**。

> (i)遗传神经网络的训练可能会遇到多种问题，例如**无法收敛和模式崩溃**[99]，这导致了在训练基于遗传神经网络的异常检测模型时存在很大的困难。
>
> (ii)**生成器网络可能会被误导，并生成正态实例流形之外的数据实例**，特别是当给定数据集的真实分布是复杂的或者训练数据包含意外的离群值时。
>
> (iii)**基于GAN的异常评分可能是次优的，因为它们是建立在生成式网络上的，其目的是为数据合成而不是异常检测而设计**。

3、**自监督分类的优点如下**。

> (i)**它们在无监督设置与半监督设置下都能很好地工作**。
>
> (ii)**异常评分的基础是梯度幅度及其更新的一些固有特性**。

**它们的缺点如下**。

> (i)特征变换操作通常与数据相关。**上述变换操作仅适用于图像数据**。
>
> (ii)**虽然分类模型是以端到端的方式训练的，但是基于一致性的异常分数是基于分类分数而不是优化中的集成模块导出的，因此它们可能是次优的**。

##### 4.2.2  异常度量相关特征学习

异常度量相关特征学习的目的是**学习针对一个特定的现有异常度量进行专门优化的特征表示**。此类方法代表性技术有**基于距离的度量，基于单类分类的度量和基于聚类的措施**。

1、**基于距离的度量的优点如下**。

> (i)基于距离的异常是简单明了的，**并且在文献中有丰富的理论支持**。因此，基于深度距离的异常检测方法可以在已有的相关工作中打下坚实的基础。
>
> (ii)**该方法工作在低维表示空间，能够有效地处理传统的基于距离的异常测度所不能处理的高维数据**。
>
> (iii)**他们能够学习专门为自己量身定制的表征**。

**它们的缺点如下**。

> (i)大多数基于距离的异常度量**所涉及的大量计算**可能是将基于距离的异常度量结合到表示学习过程中的障碍。
>
> (ii)它们的能力可能受到**基于距离的异常测量的固有弱点**的限制。

2、**基于单类分类的度量的优点如下**。

> (i)**基于一类分类的异常在文献中有很好的研究**，并且为基于一类分类的深异常方法提供了坚实的基础。
>
> (ii)表示学习和单类分类模型可以被统一以学习定制的和更优的表示。
>
> (iii)在传统的一类模型中，它们将用户从手动选择合适的核函数中解放出来。

**它们的缺点如下**。

> (i)**在正态类内具有复杂分布的数据集中，一类模型可能无效**。
>
> (ii)**检测性能取决于基于单类分类的异常度量**。

3、**基于聚类的措施的优点如下**。

> (i)**大量的深度聚类方法和理论**可以用来支持异常检测的有效性和理论基础。
>
> (ii)与传统的基于聚类的方法相比，**基于深度聚类的方法学习特别优化的表示，这有助于比在原始数据上更容易地发现异常，特别是在处理复杂数据集时**。

它们的**缺点**如下。

> (i)异常检测的性能在很大程度上依赖于聚类结果。
>
> (ii)聚类过程可能由于训练数据中的污染异常而有偏差，这又导致较低效的表示。

#### 4.3 端到端异常评分学习

该研究线旨在**以端到端的方式学习标量异常分数。与依赖于异常度量的特征学习相比，这种方法中的异常评分不依赖于现有的异常度量;它具有直接学习异常评分的神经网络**。下面我们回顾这一类别中的四种主要方法：**排序模型、先验驱动模型、软最大似然模型和端到端一类分类模型**。该框架的关键是将顺序或判别信息纳入异常评分网络。

##### 4.3.1 排序模型

1、**这组方法旨在直接学习排名模型**，以便可以根据与异常的绝对/相对排序关系相关的可观察有序变量对数据实例进行排序。异常评分神经网络是由可观察的有序变量驱动的。假设是**存在一个可观察到的有序变量，可以捕捉到某些数据异常**。

2、**基于模型的深度排序方法的优点如下。**

> (i)异常分数可以直接用适应的损失函数来优化。
>
> (ii)它们通常不受异常定义的限制，因为它们对异常和正常实例之间的有序顺序施加了一个弱假设。
>
> (iii)这种方法可以建立在诸如学习排名等领域的成熟的排名技术和理论的基础上[85，87，158]。

3、**它们的缺点如下。**

> (i)在这些方法中**至少需要某种形式的标记异常**，这可能不适用于这样的标记异常不可用的应用。[117]中的方法是完全无监督的，并且获得了一些有前途的性能，但是与半监督方法相比仍然存在很大的差距。
>
> (ii)由于模型被专门地拟合以检测少数标记的异常，因此它们可能**不能推广到表现出与标记的异常不同的异常特征的看不见的异常**。

##### 4.3.2 先验驱动模型

##### 4.3.3 Softmax Likelihood Models

##### 4.3.4 端到端单类分类

### 5、算法和数据集

#### 5.1 代表性算法

![image-20240905154608876](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154608876.png)

![image-20240905154706461](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154706461.png)

#### 5.2 具有真实异常值的数据集

**异常检测发展的一个主要障碍是缺乏具有真实的异常的真实世界数据集**。许多研究（例如，[3，48，103，132，157，170，175]）因此评估了他们提出的方法在从流行分类数据转换的数据集上的性能。这种方式可能无法反映在现实世界中的异常检测应用的方法的性能。我们在表3中总结了**21个公开可用的具有真实的异常的真实世界数据集的集合**，以促进对这些数据集的性能评估。这些数据集涵盖了以各种数据类型呈现的广泛的流行应用领域。这里**只包括大规模和/或高维复杂数据集**，为深度异常检测提供具有挑战性的测试平台。此外，**在https://git.io/JTs93上提供了广泛使用的异常检测数据集**（包括表3中的一些预处理数据集）的持续更新集合。

![image-20240905154951383](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154951383.png)

## 六、《Outlier Detection: Methods, Models, and Classification》

### 1、异常值定义和分类

1、离群值通常基于以下假设定义[21]：

> **（1）离群值在其特征方面不同于正常值;**
>
> **（2）与正常实例相比，离群值在数据集中是罕见的**。

2、**anomalies表明了一种不同的潜在生成机制。相比之下，Outliers往往强调统计稀有性和偏差，而它们是否由不同的机制产生并没有直接说明**。在统计学和机器学习的某些情况下，**outliers是指那些使模型更难拟合的数据实例**。**在监督学习中，anomalies是更好的术语，因为有可靠的指导来建模异常的生成机制**。相比之下，由于缺乏可靠的指导，**无监督学习方法通常依赖于数据的内在分布或结构，以测量偏离规范的程度，希望发现的离群值代表感兴趣的异常**。

3、基于构成异常模式所涉及的数据实例的数量，存在**（1）点离群值和（2）集体离群值[14]**。点异常值是指与数据集的其余部分有很大偏差的单个数据实例。集体离群值是相对于整个数据集的其余部分出现异常的数据实例的集合。根据比较的范围，**点异常值可进一步分为（1）局部异常值和（2）全局异常值**。局部离群值的检测依赖于特征差异（例如，邻域密度的差异），而全局离群值解决整个数据集的差异。

根据输入数据的类型，离群值可以分为**（1）矢量离群值和（2）图形离群值[24]**。**向量离群点是指向量类多维数据，而图离群点存在于图数据中**。**类向量数据点有多个属性，每个属性都有一个数值或一个分类值**。**图形数据中的异常值可以是点异常值（例如，节点离群值和边缘离群值）或集体离群值（例如，子图异常值）**[24]。

### 2、方法分类和讨论范围

1、我们将方法分为**基本方法和高级方法**，这是基于高级方法是在基本方法的基础上发展起来的。以应对新的挑战。这些挑战包括**高维数据（“维数灾难”）、无界和动态数据流、分布式环境中的大数据以及有效使用非常有限的标记数据**。根据这些方法所使用的基本技术，**基本方法进一步分为基于邻近的方法和基于投影的方法**。为了避免复杂性和混乱，**我们统一了“基于距离”和“基于密度”类别的方法，并将它们置于“基于最近邻”的保护伞下**。这是因为它们都涉及最近邻的概念。然而，**本文中讨论的基于密度的数据流方法都是在LOF [23]之上开发的**。

![image-20240905162152003](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905162152003.png)

### 3 基于邻近度的方法

**基于邻近度的方法基于离群值与附近数据点的关系来识别离群值。一种常见的情况是离群值位于稀疏区域，在给定距离内只有很少的数据点，或者最近的数据点非常远。**

#### 3.1 最近邻方法

有两种主要的方法来定义邻域：**k最近邻（k-NN）和以数据点为中心的预定半径内的邻域**。

![image-20240905162832856](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905162832856.png)

1、Ramaswamy等人[41]的方法使用与第k个最近邻居的距离作为离群值得分。Angiulli等人[41]的方法使用到k-NN的距离之和[42]。Knorr等人[31]依赖于数据点的预定半径内的相邻点的数量。**由于异常程度是在整个数据集的上下文中进行比较的，因此这些方法检测全局离群值**。他们假设数据集不同区域的密度是均匀的。

2、**考虑到不同密度的方法往往优于它们[22]。后一种方法侧重于局部离群值。LOF [23]是一种著名的方法，它首先引入了局部离群值的概念。基于连通性的离群因子（COF）[36]解决了LOF的缺点。Papadimitriou等人[37]基于局部密度的定义提出了局部相关积分（LOCI）。受影响的离群值（INFLO）[38]使用反向最近邻集（k-RNN）与k-NN相结合来计算离群值得分。[39]提出了局部离群值概率（Loop）。Loop试图解决其他方法面临的困境：如何选择合适的离群值阈值来区分离群值和内点**

3、基于子采样，使用**最近邻包络（iNNE）[40]**的隔离创建隔离区域以确定离群值分数。**LeSiNN [16]**是另一种离群值检测方法，也可以使用子采样构建模型。**iNNE和LeSiNN都具有线性时间复杂度，此外，iNNE和LeSiNN都使用集成来确保离群检测器的稳定性**

4、**与基于聚类的方法相比，基于最近邻的方法在离群点分析上具有更精细的粒度的优点。这使得基于最近邻的方法能够区分强离群值和弱离群值，而弱离群值更有可能被视为噪声[22]。由于成对距离的昂贵计算，高的计算复杂度通常作为代价而出现。此外，k的选择对整体性能有着巨大的影响。使用二次采样是将时间复杂度降低到线性的好方法。二次采样还有助于实现上述掩蔽效应。新的问题是如何确定合适的样本大小和集合大小。**

#### 3.2 基于聚类的方法

基于聚类的离群点检测算法通常分为两步：**首先用聚类算法对数据进行分组，然后根据聚类结果分析数据的偏离程度。不属于任何聚类的数据点被认为是离群值**。除了聚类成员（无论是否在聚类中），还有两个其他常用的聚类相关量来构建离群值。**第一个是到聚类中心的距离，假设正常数据点靠近聚类中心，而异常值远离它们。第二个是簇的基数，假设正常数据点的簇是密集和大的，而离群数据点的簇是稀疏和小的。与基于最近邻的离群点检测方法相比，基于聚类的离群点检测方法的一个主要优点是检测效率高**。

![image-20240905164918032](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905164918032.png)

1、**Jiang等人[44]提出了一种离群点检测方法，该方法基于改进的k均值聚类和从聚类中心构建的最小生成树**。**基于聚类的局部离群值因子（CBLOF）[46]是一种基于聚类的离群值检测方法，通过定量测量区分小聚类和大聚类**。**在Amer等人的后期工作中。[47]，证明了简单地去除CBLOF的簇基数可以产生更好的结果**。**CBLOF和LDCOF都具有独立于框架的合并的聚类算法。但正如[47]所建议的，具有固定数量的聚类（如k-means）的算法在性能上是有利的，并且由于潜在的非球形分布，建议高估聚类数量**。**Du等人。[17]设计了一种基于密度峰值聚类算法的局部离群值检测方法[48]，这是一种简单但有效的基于密度的方法，可以检测任意形状的聚类**。

#### 3.3 基于预测的方法

**本节是各种投影技术的方法**（例如，随机投影[50]、LSH [29]等）为了**将原始数据转换到具有降低的维度或复杂度的新空间中，同时仍然保留邻近信息**（例如，成对欧几里德距离、最近邻关系等）在一定程度上是原始数据集。**然后可以在投影空间中执行离群点检测，从而大大改善了执行时间**。表3是本节介绍的各种方法的摘要。它们中的许多非常有效，也适用于高维数据。值得注意的是，**子空间技术也是一种直接投影**。**它们已被广泛用于解决高维数据的挑战**。

![image-20240905165736586](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905165736586.png)

**1、投影索引最近邻（PINN）[51]基于随机投影方案来降低数据维度，随机投影优于其他降维技术（如PCA [57]）的优点是其效率。局部敏感离群值检测（LSOD）[52]利用局部敏感哈希（LSH）[29，53]来创建离群值的初始排名，LSOD集成了许多基于距离的离群值检测的修剪策略，包括PPSN [41]，ANNS [41]和PPSO [61]。Schubert等人提出了另一种基于投影的离群值检测算法[54]。此外，他们提供了一个分布式框架来扩展算法。Loda [55]采用稀疏随机投影线，Loda遵循了集合的精神，并演示了如何将多个弱离群值检测器组合在一起，从而产生非常好的结果**

#### 3.4 基于树的方法

**从广义上讲，树模型的构建也可以被视为一种投影，其中原始数据点被映射到特定的树节点，并且这些树节点包含关于原始数据的邻近信息**。**柳塔尔。[28]开发了Isolation Forest，它是一种无监督的树集成**。**Hariri等人[56]提出了扩展隔离森林来解决隔离森林的缺点**。

### 4、高维离群点检测技术

高维数据实现效率的困难主要归因于两个原因。首先，**由于增加的维度，相似性搜索（诸如k-NN搜索）在计算成本方面变得更昂贵**。其次，**一些用于加速离群值检测的技术，如采样[66，67]，修剪[68]，排名策略[38，69]和有效的索引结构（R树[58]，X树[59]等），不适用**。与这个问题相关的一个常用术语是**“维数灾难”[34，70-72]**。**这种现象是由大量“正常噪声”不相关维度/属性的稀释效应引起的[22]**。**为了提高高维数据离群点检测的效率，Ghoting等人。[73]提出了递归分箱和重投影（RBRP）**。RBRP受到ORCA [68]的启发，ORCA是一种嵌套循环离群值检测方法，其离群值得分基于到第k个最近邻居的距离。

![image-20240905173128567](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905173128567.png)

1、请注意，第3节中提到的**投影索引最近邻（PINN）[51]算法也旨在提高高维离群值检测的效率**。更多的工作在文献中**集中在高维离群检测问题的有效性方面**。Kriegel等人。**[74]引入了一种基于角度的离群值检测方法（ABOD），以解决基于欧几里得距离的算法在面对高维数据集时遇到的质量恶化的问题**。因此这会导致昂贵的**O（n3）时间复杂度**。为了降低时间复杂度，引入了两个近似变体：**FastABOD和LB-ABOD**。FastABOD将离群值得分计算的数据点对的选择限制在数据点的k-NN。**LB-ABOD是ABOD的一个下界近似，其目的是有效地获得具有最高分数的顶级离群值**。

2、许多作品探索**子空间的解决方案**，以处理“维数灾难”的影响。**Kriegel等人。[75]开发了一种离群值检测模式**，该模式基于单个数据点与由一组参考点跨越的轴平行超平面的偏差来评估离群值。**[76]提出了一种测量子空间对比度的方法，并相应地提出了一种称为高对比度子空间（HiCS）的子空间搜索方法**。**Sathe等人。[77]提出了RS-Hash，这是一种基于随机散列的非常有效和准确的子空间离群值检测方法**。

3、**除了上述方法，近年来其他有趣的工作包括：HighDOD [80]，使用动态子空间搜索方法和基于样本的学习过程; LODES [81]，依赖于一种新的基于局部密度的谱嵌入来识别非线性子空间中的离群值; RAMODO [82]使用表示学习来降低维度，并将其与基于随机距离的方法相结合[16]**。

### 5、分布式异常检测技术

**将离群值检测扩展到分布式环境的一个具有挑战性的任务是在保证准确性的同时最大限度地减少通信开销。这个任务对于需要计算数据点之间的成对距离的方法来说尤其困难**。值得注意的是，除了随后介绍的算法之外，**一些专注于分布式k-NN搜索的工作[105-109]可以为基于分布式k-NN的离群点检测算法的开发提供启发**。

![image-20240905175602124](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905175602124.png)

1、**Bhaduri等人。[110]开发了DOoR，这是ORCA方法[68]的分布式解决方案。Angiulli等人。[111]将SolvingSet算法[112]扩展到分布式环境。Bai等人[115]提出了LOF的分布式解决方案。分布式Top-N LOF（DTOLF）[114]为参考文献[116]中提出的Top-N LOF方法提供了分布式解决方案。Tsou等人。[12]提出了一种分布式无监督异常检测框架**。

### 6、基于深度学习的异常检测技术

**通过假设离群值实例更难以由训练的自动编码器重建，利用自动编码器进行离群值检测的一种简单方法是使用重建误差作为离群值得分[124]**。然而，由于在**无监督设置中训练数据可能被离群值污染**，由于其对离群值的敏感性和可能的过拟合，模型的有效性可能会显着减弱。

1、**为了解决当训练数据包含离群值时自动编码器对过拟合的敏感性，Chen等人。[121]提出了一种基于集合的离群值检测方法，该方法将一组自动编码器的结果与连接架构中的多样性相结合**。

2、**鲁棒深度自动编码器（RDA）[18]通过将输入数据分为两个矩阵来解决受污染的训练数据问题，一个包含离群值，另一个由自动编码器有效重建。这个想法受到鲁棒主成分分析的启发[125]**

3、**Schlegl等人[122]设计了AnoGAN，旨在检测图像数据中的异常作为疾病标记**。**另一种基于GAN的异常检测方法是逆向学习异常检测（ALAD）[123]**。类似于AnoGAN [122]的想法，ALAD也依赖于GAN来对正常实例的分布进行建模，并且由此产生的异常分数基于重建误差。

4、**[82]提出了一种基于深度神经网络的框架，称为RAMODO**，用于学习由与目标离群值检测器相关的损失函数指导的离群值检测表示

将深度神经网络应用于离群值检测的主要优势是能够从复杂和高维数据中提取代表性特征，与传统方法相比，它可以提供更准确的结果。然而，**通常需要大的数据量才能让深度神经网络避免过拟合**。此外，**许多基于深度学习的方法对超参数非常敏感**。调整超参数以获得最佳性能可能是一项具有挑战性且耗时的任务

### 7、人在环的异常检测技术

如果标记的数据被适当地利用来调整现有的模型，则原始无监督技术的准确性可以显著提高。**一种典型方法是通过主动学习**[135]：初始模型建立在未标记数据上，基于此，**一些数据实例通过一些查询策略被领域专家标记**。然后用新获取的标签信息更新模型。这种类型的反馈循环可以迭代地进行，直到满足某些标准。

1、**在Görnitz等人的工作中。[136]，异常检测被认为是一个名为支持向量数据描述（SVDD）的优化问题[137]**。**Das等人。[27]提出了一种半监督方法，该方法将专家反馈迭代地结合到称为Loda [55]的集成异常检测方法的模型中**。**Vercruyssen等人[11]描述了一种半监督异常检测方法**。**Siddiqui等人。[139]提出了一种用于异常检测的通用算法，旨在通过结合专家反馈将异常分数与应用程序特定的兴趣度对齐**。

## 七、《Evaluation of Machine Learning Algorithms for Anomaly Detection》

1、我们评估了12种机器学习（ML）算法在网络实践中检测异常行为的能力。该评估是在三个公开的数据集上进行的：**CICIDS-2017，UNSW-NB 15和工业控制系统（ICS）网络攻击数据集**。

**KDD CUP 99 [26]已经过时**，因为网络流量是在1998年生成的，不能反映新的网络结构和攻击动态，**CICIDS2017 [29]和UNSWNB 15 [30]被用来评估我们当前论文中的12种ML算法**。这是因为这些数据集包含了广泛的当前攻击场景，符合现实世界的标准。

评价结果表明，**随机森林（RF）算法在所有数据集上的准确度、精确度、召回率、F1评分和受试者工作特征（ROC）曲线方面均达到最佳性能**。在本研究中，我们评估了六个经典的监督ML算法和六个深度学习算法。所选的经典ML算法有**Logistic回归、朴素贝叶斯、K邻近（KNN）、决策树（Decision Tree）、自适应增强（Adaptive Boosting）和随机森林（RF）**。我们选择的深度学习算法包括**卷积神经网络（CNN）、卷积神经网络和长短时记忆（CNN-LSTM）、长短时记忆（LSTM）、门控递归单元（Gated Recurrent Units，GRU）、简单递归神经网络（Simple Recurrent Neural Network，RNN）和深度神经网络（Deep Neural Network，DNN）**。

![image-20240905193120233](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905193120233.png)

2、使用七个评估矩阵来衡量所选ML算法的性能，即**准确度**，**精确度**，**真阳性率**（TPR），也称为召回率，**假阳性率**（FPR），**F1分数**，**受试者操作特征（ROC）曲线**和**混淆矩阵**。

![image-20240905194109674](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905194109674.png)

## 八、《A critical overview of outlier detection methods》

1、离群值与噪声数据有很大的不同，而噪声是无用的，必须被去除，**离群值可以提供无用和有趣的（例外）信息**。换句话说，**离群值是极端偏离数据集的定义良好的规范或预期行为的给定概念的数据实例**。

### 1、离群值检测算法

#### 1.1 基于统计的检测算法

提出了**参数和非参数方法**，这些方法需要两个阶段来完成离群点检测过程，即**训练阶段和测试阶段**。在训练阶段，数据集中的所有数据实例都基于给定的统计模型进行训练。然而，测试阶段涉及检测数据实例是否适合模型，即离群值检测。**参数方法在我们已经知道数据分布的情况下使用**，在参数方法中，我们可以提到**基于高斯和基于回归的方法**。

##### 3.1.1 基于高斯的方法

**箱形图[3]和均值-方差**是基于高斯的方法中最常用的技术。**乔马湖，加-地等人[4]提出了一种使用箱形图识别单变量和多变量离群值的方法**。

##### 3.1.2 基于回归的方法

为了处理大数据集，Rumseeuw和Driessen [5]提出了一种新的回归方法，称为**LTS回归算法**。。**FAST-LTS方法使用不同的节省时间的方法**：集中步骤（C-步骤），选择性迭代和嵌套扩展。

##### 3.1.3 无参数的方法

**直方图和基于核的方法**是最著名的非参数离群点检测方法。Markus G.和Andreas D.[7]叫做**HBOS算法**。**为每个单个元素构建单变量直方图，然而对于数值元素，可以构建两种类型的直方图：静态箱宽度直方图和动态箱宽度直方图**。**Longin J.L.等[8]提出的方法**可以被认为是一种统计检测方法，也可以被认为是一种基于密度的检测方法，因为它使用非参数核来估计数据实例的密度。

**统计检测方法**在给出概率分布模型时显示出有效的实验结果，但**在应用于大数据集时具有高计算成本和维数灾难**。因此，这些方法不能应用于大型和高维数据集。这些技术的**另一个缺点是它们不适用于分布未知的数据集**。

#### 1.2 基于距离的检测算法

**通过基于各种距离相关度量计算所有数据对象之间的距离来检测离群值。之后，没有足够邻居的对象最有可能是离群值。最近邻方法是最常用的方法。**

1、**解集方法由Fabrizio A.等[9]提出**，为了计算ODP求解集，已经开发了三种算法，**SolvingSet算法，RobustSolvingSet算法和MinimalRobustSolvingSet算法**。**[10]提出了一种称为基于角度的离群值检测ABOD方法的新方法，该方法仍然使用距离，但也考虑所有数据对象的角度方差**。**另一种基于距离的算法LDOF由[11]引入**。**基于距离的方法似乎是有效的，因为它们独立于数据分布，易于实现**。然而，它们**在高维数据集中仍然表现不佳**。**ABOD是唯一讨论过的克服这个问题的技术**。**ABOD不能适当地识别低密度周围区域中的离群值**。

#### 1.3 基于密度的检测算法

我们可以提到**LOF和INFLO作为基于这种技术的众所周知的方法**。**LOF方法需要良好分离的聚类以便良好地执行**，否则它会遭受错误的离群值得分。**[13]提出了另一种基于对称邻域关系的离群点检测方法INFLO**。

#### 1.4 基于聚类的检测算法

**DBSCAN的有效性依赖于Martin E.等人**，直接密度可达性概念（见定义1）、密度可达性概念（见定义2）以及最后密度连通性概念（见定义3）。**[17]提出了一种新的无监督离群点检测和聚类改进的方法，通过发展ODC算法**，该算法通过使用众所周知的K均值的修改版本来检测离群值。**将该算法与FindCBLOF和ORC离群点检测方法进行了比较，以确认其质量。ODC在离群点检测和聚类精度方面表现出更好的性能**。[20]提出了一种基于离群点比内点（正常对象）更难识别的思想的异常检测精确排序方法OF算法。**[21]提出了基于聚类的离群点检测（CLOPD）算法**，该算法也是为了检测医学数据中的异常。[22]**在现有的离群点检测算法中，几乎都存在top-n参数问题**，这意味着算法需要一个参数n来指定离群点的个数。他们开发了**ROCF算法，在算法6中描述，它不需要这个参数**。

### 2、总结

**基于统计的方法对于给定的分布模型可能是有效的，但当该分布未知时，它们不能应用。基于距离的方法克服了这个缺点，并且不依赖于数据分布，但是它们在多变量和高维数据中可能非常昂贵。基于密度的方法更有效，但它们仍然不适合大型数据集和数据流。此外，基于聚类的方法虽然可以处理数据流，但仍然需要太多的参数。**

## 九、《A comprehensive survey of anomaly detection techniques for high dimensional big data》

### 1、相关工作

**Agrawal和Agrawal [9]提供了各种异常检测技术的综述，目的是对各种异常检测方法进行基本了解**。**Albertola等人[11]介绍了用于各种应用的几种异常检测技术的调查。Hodge和Austin [7]通过比较技术的优点和缺点，对离群值检测技术进行了调查**。也可以观察到各种其他调查，例如Gama等人[15]，Gupta等人[16]，Heydari等人[17]，Jindal和Liu [18]，Pathasarathy [19]，Phua等人[20]，Tamboli等人[21]和Spirin等人[22]，这些调查进一步突出了**异常检测或高维数据中的问题**。**Zimek等人。[23]详细介绍了高维数值数据中异常检测的专用算法;他们还强调了维数灾难的重要方面。Parsons等人。[24]对高维数据的各种子空间聚类算法进行了调查，并讨论了可以使用这些算法的一些潜在应用**。目前，**还没有一项调查直接强调了大数据中的异常检测和高维性问题**。

![image-20240906153027280](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906153027280.png)

### 2、高维问题

**如果一个数据集有n个样本和m个维度（或特征），那么这个数据可以被称为m维数据。一般来说，当维数m导致“维数灾难”的影响时，数据集可以被称为高维数据集。**

### 3、解决高维问题的传统模型

**许多算法建立在接近度的概念上，Aggarwal [28]提出，几乎任何主要基于邻近概念的技术都会在高维空间中质量下降，因此需要以更有意义的方式重新定义。**

#### 3.1 基于距离的技术

Angiulli和Pizzuti [30]提出了一种基于距离的异常检测技术，称为“HilOut”，用于检测大型和高维数据集的前n个离群值，该方法扩展性良好。**Koufakou和Georgiopoulos [61]提出了一种异常检测策略，其中通过非常接近线性的分布式版本来实现加速**。他们称这种方法为“快速分布式”

#### 3.2 基于聚类的技术

#### 3.3 基于密度的技术

**[62]介绍了一种用于估计高维数据中的度量的密度估计器，并将其应用于识别数据分布变化的问题**。

#### 3.4 基于分类的技术

一些机器学习技术是基于这样的假设，**即可以通过将数据投影到较低维空间上来实现维度缩减，在该较低维投影之后，学习可能更容易[65，66]**。基于降维策略的技术将数据投影到较低维度的子空间[8]或PCA [7，67，68]上，如在以下部分中所讨论的。

![image-20240906172326849](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906172326849.png)

#### 3.5 解决高维问题的策略

**如上所述，已经提出了许多降维方法，例如PCA，MDS，Karhunen-Loeve变换，局部线性嵌入，拉普拉斯特征映射和扩散映射，以实现降维[51，70-74]**。**这些数据表示的内在维度小于可用的相关维度。已经提出了许多技术来测量内在维度[75-80]**。

1、**Wang等人。[86]提出了一种PCA以及可分离压缩感知**，以识别不同的矩阵。**压缩感知（或压缩采样[CSG]）理论由Candes和Wakin [87]提出**。**使用基于PCA的降维方法的主要缺点是它们可能导致显著的信息损失，PCA识别属性之间的隐藏线性相关性[73]。如果数据集的属性是非线性的或不相关的，PCA可能会导致复杂的，并且可能无法解释的假阳性**。

2、**子空间是数据集维度的子集，其使用的维度空间小于完整的维度空间**。**异常只能在数据的低维子空间或具有缺失属性的数据集中识别[8]**。**同时找到相关的子空间和低维空间。同时发现起着至关重要的作用，因为不同的维度子集与不同的异常相关**。多个子空间的发现是重要的，因为选择单个或仅几个相关子空间可能导致不可预测的结果[28]

3、**Lazervic和Kumar [92]提出了一种模型，该模型使用称为“特征装袋”的评分系统来检测异常**。这导致不相关维度的增加。为了解决这个问题，**Kriegel等人。[23]采用了一种技术来选择信息或相关维度**。**[93]提出了一种名为“OUTERS”的子空间方法**，这是一种通过引入一种新的评分算法来对异质高维数据中的异常进行排名的方法。Zhang等人。**[94]提出了一种基于角度的子空间离群点检测方法**。**Thudumu等人。[41]提出了一种检测离群值的方法**，通过使用Pearson相关系数（PCC）和PCA将高维空间分叉为局部相关和低维子空间。**Koufakou和Georgiopoulos [61]提出的另一种算法称为混合属性数据集的离群值检测（ODMAD）**。他们的结果表明，分布式版本的ODMAD的速度接近线性加速与计算中使用的节点数量**。****混合属性由Ye等人提出。[95]，他们提出了一种离群点检测算法**，通过计算异常子空间结合信息熵来检测高维混合属性数据集中的异常

#### 3.6 高维大数据异常检测带来的独特挑战

解决高维问题的最常见策略是定位最重要的维度（即，特征子集），称为变量选择方法，或者将结合维度组合成一组较小的新变量，称为降维方法[73]。高维问题的挑战如下：

![image-20240906174436695](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906174436695.png)

**Fabien和Kelloer [100]提出通过计算在真实的数据集上评估的高对比度投影的分数来提高传统异常排名的质量**，从而估计子空间的对比度。**Tomasev等人。[102]通过评估频繁出现的点（称为枢纽）来解决高维数据中的聚类问题**。**Radovanović等人[103]使用数据点提供了有用的见解，称为反枢纽**。

#### 3.7 高维大数据中的工具

许多分布式计算框架，如**Apache Hadoop [134]，Apache Storm [135]，Apache Spark [136]，Apache Flink [137]和MXNet [138]**都是为了满足不断增长的大数据需求而开发的。**这些框架中的大多数都有内部机器学习（ML）库，Apache Spark拥有比其他任何框架都强大的ML库[139]**。

1、Koufakou等人[140]提出了一种快速并行异常检测方法。**Leung和Jiang [36]报告了一种解决方案，该方案利用MapReduce挖掘不确定的大数据**。**Jiang等人[141]报告了一种基于树的技术BigSAM**。He等人[32]提出了一种基于KD树的异常识别技术的并行应用。**Apache Spark（Spark）[136]是另一个基于MapReduce的分布式框架**，用于在分布式系统上处理大量数据，然而，**它有一个称为内存计算的功能**[159，160]。**与MapReduce两阶段范式相比，Spark的内存计算模型旨在提高处理批量和实时工作负载的速度和可扩展性**。**Terzi等人[143]提出了一种使用Apache Spark作为分布式框架的无监督方法**。Zhang等人[144]开发了一个基于Apache Storm的框架。Veen等人。[161]专注于使用基于Apache Storm的公共云虚拟机的流媒体分析平台的弹性。

2、**MXNet是一个开源、可扩展、内存高效、高性能的模块化深度学习框架，为C++、Python、Matlab和R等编程语言提供了一系列应用程序编程接口（API）**。**它运行在异构系统上，从移动的设备到分布式GPU集群[162]**。**Abeyrathna等人。[145]提出了一种基于异常提议的方法**，可以使用MXNet框架建立实时火灾检测的有效架构。**Apache Flink [137]提出了另一个开源框架**，结合了其他分布式范例（如MapReduce [163，164]）的可扩展性和编程灵活性。**Toliopoulos等人。[146]进行了基于距离的离群值检测工作**，并使用三个真实世界和一个合成数据集在大规模并行设置中进行了检查。**他们考虑了三个主要的并行流媒体平台，如Apache Storm，Apache Spark和Apache Flink**。**García-Gil等人[139]对两个框架Apache Spark和Apache Flink的可扩展性进行了比较研究**。

3、**Angiulli等人。[33]提出了一种分布式框架**，用于基于对异常检测解析集（数据集的一个小子集）的感知，在海量数据集中识别基于距离的异常**。后来，Angiulli等人[152]提出了一套用于GPU的并行和分布式算法，从而产生了两种基于距离的异常检测算法：BruteForce和SolvingSet**。它们之间的区别在于它们利用GPU架构和内存层次结构的方式，并提供针对CPU版本的改进，包括可扩展性和并行性利用。**松本等人[153]发表了一种使用密度采样对不确定数据进行异常检测的并行算法，通过OpenCL框架在图形处理单元（GPU）和多核中央处理单元（CPU）上建立了实现**。

4、**Lozano和Acufia [154]设计了两种并行算法来识别基于距离的异常**，使用随机化和修剪规则来识别基于密度的局部异常。**他们还构建了Bay和Local Outlier Factor（LOF）程序的并行版本**，这些程序在异常检测和运行时间方面表现出良好的性能。**Bai等人。[34]专注于大型数据的分布式基于密度的异常检测问题**。他们提出了一种基于网格的分区算法，作为一种数据预处理技术，在将数据集分发到分布式环境中的数据节点之前，将数据集划分为网格。**提出了一种分布式LOF计算方法，利用少量网络通信并行发现基于密度的离群点**。**Reilly等人。[155]提出了一种基于PCA的离群值识别方法，该方法在分布式环境中工作，在提取包含离群值的训练集的主成分时表现出鲁棒性**。**Gunter等人[147]探索了在大型分布式系统中识别异常值的各种技术**，并主张采用轻量级方法来实现真实的时间分析。没有找到单一的最佳方法;因此，他们得出结论，由于有效性的变化取决于异常的定义，因此需要各种方法的组合。

5、**Maruhashi等人。[148]提出了一种在具有数百万条边的异构网络中发现模式和异常的技术**，并根据经验证明该技术可扩展到高维数据集。**Shin等人。[149]开发了一种新的灵活框架，可以识别大规模高阶张量中的密集块**，并通过以近乎完美的准确度发现TCP转储中的网络攻击，证明他们的方法在真实的数据中是可扩展的。**Oh等人[44]提供了一种可以处理高维数据的可扩展方法**。特别是，他们还证明了他们的方法在维度方面优于许多基线方法。Hooi等人。**[150]提出了一种可扩展的基于密集子图的异常检测方法，称为FRAUDAR**，不仅可以检测真实的世界图中的各种欺诈攻击，还可以检测大数据中大量先前未检测到的行为。**Jiang等人。[151]提出了一种名为CROSSSPOT的可扩展算法**，该算法对可疑程度进行评分和排名，以在真实世界的大型多模态数据中找到密集的可疑块。

## 十、《A Comparison of Outlier Detection Techniques for High-Dimensional Data》

### 1、评价指标

1、**AUC**。ROC（受试者工作特征）曲线是真阳性率与假阳性率的图表，其中真（假）阳性率表示前m个潜在离群值中离群值（内值）的比例。

2、**Precision（P）**。精度是指真实离群值的数量与离群值候选总数的比率

3、**Average precision (AP)**。Average precision不是仅对单个n值进行评估，而是指所有离群值对象的等级上的精度分数的平均值。

4、**Rank Power (RP)**。秩功率是另一种流行的测量，以评估离群值检测方法的性能。很明显，如果离群值排名算法将真正的离群值排在离群值候选列表的顶部，则该算法将被视为更有效。

5、**相关系数**。如斯皮尔曼等级相似性或Pearson相关性，也可用于评估文献中离群值检测的性能36。这种度量方法通过使用合并权重将更多的重点放在排名靠前的潜在离群值上。

### 2、数据集来源

在离群点检测实验中，通常使用**人工数据集和真实数据集**来验证文献中的性能。**Wang等人37提供了一些在不同情况下具有异常值的合成数据集**。真实世界的数据集通常来自三个来源，如下所示：

> 1、**UCI机器学习库**。这些数据集中的大多数已被提议用于评估分类方法。**对于离群点检测任务，常用的策略是通过将小类中的对象作为离群点，其余的作为正常对象来预处理数据集**。
>
> 2、**ELKI数据集**。ELKI是一个积极开发和维护的“用于开发索引结构支持的KDD应用程序的环境”。最近的版本特别致力于异常值检测。**该平台不仅提供了离群点检测算法，还提供了用于离群点检测评估的多个数据集**。
>
> 3、**空间数据**。空间数据4的集合是由芝加哥大学捐赠的。**尽管最初用于空间分析，但这些空间数据（包括人口普查区域数据和邮政编码业务模式）也可用于离群点检测**。

**在分类中主要使用的数据集需要进行预处理以用于离群值检测任务**。在预处理期间，可以考虑两种情况：

> 1、**对于语义上有意义的离群数据集，与稀有对象相关联的类被视为离群值，其余的被视为正常数据**。
>
> 2、**对于其他数据集，从数据集中随机选择离群值类。特别地，对于只有两个类的数据集，具有次要对象的类通常被视为离群点**。

### 3、实验对比

**我们在9个数据集上对10种流行的离群点检测算法进行了实验比较**。离群点检测算法包括**kNN、kNNW、ODIN、LOF、Loop、COP、SOD、FastABOD、HiCS和高斯均匀混合模型（GMM）**。**其中“N”和“O”分别指所有对象和离群值的数量**。

![image-20240906183347756](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183347756.png)

![image-20240906183523232](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183523232.png)

## 十一、《A comparative evaluation of outlier detection algorithms: Experiments and analyses》

我们的论文扩展了以前的工作[7，33]，**使用了12个公开可用的标记数据集，其中大部分被推荐用于离群值检测[7]，此外还有3个来自旅游行业一家大公司生产环境的新工业数据集**。所选的参数和非参数算法来自各种方法，包括**概率算法，最近邻方法，神经网络，信息论和隔离方法**。在标记数据集上的性能与**ROC曲线下面积和精确度-召回率曲线进行了比较**。为了全面概述这些方法，我们还对每种方法的**训练时间，预测时间，内存使用和鲁棒性**进行了基准测试。

### 1、异常检测方法

#### 1.1 概率方法

> **概率算法通过推断模型参数θ来估计数据集X的概率密度函数。具有最小似然P（X|θ）的数据点被识别为离群值。**在我们的基准测试中使用的第一种算法是**高斯混合模型（GMM）**。**在[3]中，Blei等人描述了Dirichlet过程混合模型（DPMM）**。该算法在文献[8]的KDD 99数据集上进行了入侵检测，其性能优于SVM和KNN算法。**核密度估计器（KDE）**，也称为Parzen窗口估计器，通过为每个数据点分配核函数，然后对核的局部贡献求和来近似数据集的密度函数。**Kim等人在[13]中展示了这个问题，其中作者描述了一种鲁棒核密度估计（RKDE）算法**。**概率主成分分析（PPCA）[29]**是一种潜在变量模型，用于估计数据的主成分。**Quinn等人开发的最小二乘异常检测（LSA）[25]**将多类概率分类器扩展到一类问题。使用ROC曲线下面积将该方法与knn和一类SVM进行比较。

#### 1.2 基于距离的方法

**Mahalanobis距离适用于针对由单个高斯形聚类组成的多变量数据集的异常检测任务[2]**。

#### 1.3 基于邻居的方法

**在[4]中描述的局部离群因子（LOF）**，**lof优于基于角度的离群值检测[16]和单类SVM [26]**。**基于角度的离群值检测（ABOD）[16]**使用在每个输入向量处测量的角度的半径和方差而不是距离来识别离群值。**子空间离群值检测（SOD）[15]**算法为每个点p找到p和它的k个最近邻居之间共享的m个邻居的集合。

#### 1.4 信息论方法

**Kullback-Leibler（KL）发散度在[9]中被用作新奇检测的信息论度量**。

#### 1.5 神经网络

**在[19]中，Margaret等人提出了一种基于重构的非参数神经网络，称为Grow When Required（GWR）网络**。**该方法基于Kohonen网络，也称为自组织映射（SOM）[14]**

#### 1.6 基于域的方法

用于离群数据识别的其他方法依赖于将标称数据与输入空间的其余部分分离的边界的构造，从而估计标称类的域。因此，**落在定界边界之外的任何数据点都被标记为离群值**。**单类SVM [26]是支持向量机（svm）算法在单类问题中的应用**，属于这类算法。该方法在高维空间中计算分离超平面，该分离超平面由在来自高维空间中的输入空间的点之间执行点积的核引起。

#### 1.7 隔离方法

**隔离森林的概念是由Liu在[17]中提出的，它使用随机森林来计算每个数据点的隔离分数**。该模型是通过对属性值执行递归随机拆分来构建的，因此生成的树能够将任何数据点与其余数据隔离开来。**作者指出，他的算法提供了线性时间复杂度，并在现实世界的数据集上证明了离群点检测性能明显优于lof**。

### 2、实验评估

#### 2.1 实验指标

我们使用**受试者工作特征（ROC）曲线**（真阳性率对假阳性率）和**精确度-召回（PR）曲线**

#### 2.2 实验数据集

**我们的评估使用15个数据集，范围从723到20，000个样本，包含6到107个特征**。在这些数据集中，**有12个在UCI [1]或OpenML [30]存储库中公开，而剩下的3个数据集是包含Amadeus公司生产数据的新型专有数据集**。

![image-20240906222707675](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906222707675.png)

#### 2.3 算法实现和参数

<img src="C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906223115710.png" alt="image-20240906223115710" style="zoom: 80%;" />

**本实验中使用的大多数实现都是公开可用的**。表2详细说明了所选的编程语言和初始化参数。**大多数方法具有灵活的参数，并且在没有大量调优的情况下执行得非常好**。**Python的Matlab引擎API和rpy2库允许我们从Python调用Matlab和R代码**。

### 3、总结

**iforest是一个很好的方法，有效地识别离群值，同时显示了良好的可扩展性。ocsvm在这个基准中是一个很好的候选者，但是它也不适合大型数据集**。**SOD表现出良好的离群值检测性能，并以较差的可扩展性为代价有效地处理高维数据集**。**指数族表示的dpmm显示是非常耗时的，而没有实质性地提高检测离群值的高斯为基础的方法，如dpgmm**。**LOF、ABOD、GWR、KL和LSA达到最低性能，而前三种方法也显示出较差的可扩展性**。

## 十二、《On the Evaluation of Outlier Detection and One-Class Classification Methods》

### 1、实验设置

1、我们比较和评估了11种算法：**ABOD，Auto-Encoder，Gaussian Density，GLOSH，kNNglobal，kNNlocal，LOCI，LOF，Linear Programming，Parzen Windows和SVDD**。对于大多数比较算法，我们使用来自http://prlab.tudelft.nl/users/david-tax/ [25]的代码，除了LOF，LOCI，kNNlocal和GLOSH。**在LOF和LOCI的情况下，修改了它们的实现，以确保待分类的新观测不会影响内点类的预计算模型**。由于**KNNlocal在该存储库中不可用**，因此我们使用自己的算法实现。**GLOSH是根据http://lapad-web.icmc.usp.br/上提供的HDBSCAN* 的实施情况进行调整的**。

2、我们使用来自**UCI机器学习库[17]的31个真实世界数据集作为单类分类的预处理**，并在http://prlab.tudelft.nl/users/david-tax/上提供：**Abalone, Arrhythmia, Balance-scale, Ballbearing, Biomed, Breast, Cancer, Colon, Delft1x3, Delft2x2, Delft3x2, Delft5x1, Delft5x3, Diabetes, Ecoli, Glass, Heart, Hepatitis, Housing, Imports, Ionosphere, Iris, Liver, Satellite, Sonar, Spectf, Survival, Vehicle, Vowels, Waveform and Wine**

### 2、总结

**SVDD和kNNglobal是单类分类的首选**，**而我们不推荐kNNlocal**。**这与Janssens等人[13]之前的比较研究相反**，该研究不包括kNNglobal，并报告kNNlocal为最佳表现者。**此外，我们无法确认[13]中报告的LOF的最佳性能，而只能确认SVDD的最佳性能**。

## 十三、《Prediction and outlier detection in classification problems》

提出了一种**平衡共形优化预测集（Balanced and Conformal Optimized Prediction Sets，BCOPS）方法**。该方法将监督学习算法与保形预测相结合，以最小化在样本分布外的平均误分类损失。所构造的预测集具有有限样本覆盖保证，无需分布假设。在适当的假设下，我们证明了我们的方法的渐近一致性和最优性，并在真实的数据上说明了我们的方法。

## 十四、《Supervised outlier detection for classification and regression》

通常情况下，OD模型和分类器或回归器的最佳超参数是连续但独立地获得的。**一个自然的想法是利用这种联合工作来开发目标，不仅要获得监督模型的超参数，还要获得OD模型的超参数**。

![image-20240907103152771](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907103152771.png)

### 1、离群值检测（OD）

1、我们选择并比较了在文献中具有突出作用的**九种不同的离群值检测方法**，使用了**scikit-learn [10]或PyOD [11]中的实现**，这两个库是众所周知的Python库。**所有这些都有一个共同的参数：污染百分比，即，我们认为样本中异常值的比例**。我们将在这里考虑九个代表性的OD模型，即**最小协方差决定性估计[21，22]**，**局部离群因子[23]**，**基于连通性的离群因子[24]**，**k-最近邻离群估计[25，26]**，**隔离森林[27，28]**，**一类支持向量机[29]**，**主成分分析（PCA）OD [30]，[31]**、**子空间异常值检测[32]**和**基于直方图的异常值检测[33]**。

**一个非常好的参考是PyOD库[11]，我们使用了所有上述方法的实现，除了最小协方差行列式和隔离森林，我们使用它们的scikit-learn [10]实现**

### 2、数值实验

#### 2.1 实验设置

如前所述，本工作中应用的OD模型是**mcd，if，knn，lof，ocs，pca，cof，hbos和sod**，**在mcd和if的情况下使用它们的scikit-learn实现，在其他情况下使用它们的PyOD版本**。**回归监督模型将是 Ridge 和 Huber 回归作为线性回归模型，以及具有 ReLU 激活和具有 20 个单元的单个隐藏层的非线性多层感知器回归器**。 **对于分类，将使用逻辑回归，其用于两类问题的标准公式和用于多类问题的多项式版本； 再次使用 ReLU 激活的非线性多层分类器和具有 20 个单元的单个隐藏层**。 **所有分类器和回归器都选择了 scikit-learn 中的实现**。

为了测试不同的模型，**使用了五重嵌套交叉验证（CV）**，其中构建了前五个外层，并且我们循环使用其中四个作为模型超参数化的训练验证子集，其余一个用于测试 。 反过来，模型超参数化又通过训练验证子集上的五倍 CV 来完成。 **通过网格搜索得到最优超参数**。

![image-20240907105002773](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240907105002773.png)

#### 2.2 数据集

我们将使用**八个回归数据集和八个分类数据集**。 更准确地说，将考虑以下数据集：用于回归的 abalone、boston、cal-housing、concrete、cpusmall、mg、winequality_red 和 winequality_white，以及用于分类的 australian、breast_cancer、diabetes、digits、dna、german、satimage 和 snippet。 

#### 2.3 分类结果

表 17 和表 18 分别给出了测试数据集未过滤时五重嵌套 LR 和 MLPC 模型的平均值和标准差。可以看出，**HBOS、LOF 和基本模型在 2 个问题中给出了 LR 的最佳结果，IF、SOD、COF 和 MCD 在 1 个问题中给出了最佳结果，而 KNN 和 OCS 从来都不是任何问题的最佳模型**。 当它在回归中发生时，MLPC的情况发生了变化，其中MCD在四个问题中给出了最大的准确度，LOF在三个问题中给出了最大的准确度，基础模型在两个问题中给出了最大的准确度，SOD，IF，KNN和COF在一个问题中给出了最大的准确度，HBOS和一类SVM在一个问题中没有给出最大的准确度。

### 3、总结和展望

**我们可以得出结论，一般来说，MCD和IF模型通常是一个很好的选择，而PCA，HBOS和LOF也应该考虑计算时间是一个加权因素**。

## 十五、《Robust Statistical Scaling of Outlier Scores: Improving the Quality of Outlier Probabilities for Outliers (Extended Version)》

### 1、数据集和异常检测算法

我们**在21个真实世界的数据集[6]上计算离群值**，由于计算原因排除了KDD和ALOI数据集，使用11种离群值检测算法**：主成分分析[33]，核主成分分析[12]，高斯混合模型[7]，k-最近邻检测器[29]，局部离群因子[5]，隔离森林[18]，基于直方图的离群值检测[9]，轻量级异常在线检测器[27]，基于连接性的离群值因子[35]，基于采样的离群值检测[34]，以及使用经验累积分布函数的无监督离群值检测[17]**。对于所有异常值检测算法，**我们使用Python库PyOD [41]并将超参数设置为默认值**。

## 十六、《Human-in-the-loop Outlier Detection》

### 1、摘要

本文提出了一个基于人工智能的离群点检测方法HOD，该方法能够有效地利用人工智能来发现真实的离群点。在HOD中存在两个主要挑战。**第一种是设计人性化的问题，使得即使人类对离群点检测技术一无所知，人类也可以容易地理解问题。二是最大限度减少提问次数**。

### 2、参与对比的基准

我们将HOD与众所周知的无监督离群值检测方法进行了比较，包括**KNN [40]、LOF [5]、聚类方法[23]和Ensemble方法[3]。以及基于主动学习的方法AI 2 [42]和AAD [14]**。还有基于实体匹配的方法CrowdER和Magellan。

### 3、相关工作

#### 3.1 有监督异常检测方法

**这类技术假设事先有大量标记的离群值和内值可用**。使用这些标记的数据，然后训练分类模型，**该模型将测试对象分类为离群值或内界值**。然而，监督离群点检测存在两个严重的问题。首先，**训练集中的离群值通常比内值少得多。这会导致不平衡的类别分布，从而影响分类准确度[38，43，46]**。其次，**由于离群值的稀有性，难以获得大量的高质量标签，尤其是离群值标签[2，41]**。由于这些问题，监督离群点检测方法在真实的应用中并不普遍。

#### 3.2 无监督异常检测方法

**无监督类中的技术[3，5，6，23，40，52]在真实的世界中被广泛使用，因为它们不需要任何训练数据**。通常，**这些技术基于数据集中的内点通常比异常点更频繁的观察来检测异常点**。然而，**无监督技术的准确性往往很低**。然而，尽管涉及到人类，**但与监督技术不同，我们不需要人类显式地将对象标记为内点或离群点，这通常很难并且非常耗时**。相反，**通过仔细选择要由人类回答的问题**，如图2所示，**我们的HOD能够以最少的人力准确地发现离群值**。

#### 3.3 主动学习方法

给定人力成本预算，主动学习方法从数据集中选择对象，要求人类标记这些对象并迭代地训练分类器，直到预算用完。

（1）**AI2 [42]**：每次AI2选择X个对象供用户标记，**其中X/2个对象来自非监督方法，其他X/2个对象由监督方法（随机森林）提供**。在X个对象被标记后，它重新训练监督模型并选择另一个X个对象，直到预算用完。最后，利用该模型对剩余的未标记数据进行预测。

（2）**AAD [14]**：首先，AAD提取每个对象的特征，并使用监督方法来训练分类器。接下来，基于建模结果，AAD选择一个最有可能成为人类标记的离群值的对象。然后，它迭代地重新训练模型，以调整每个特征的权重，并选择新的离群候选。

尽管主动学习方法有效地减少了人类的标记努力，但它们并没有解决离群点检测中的独特挑战，即，**由于离群点的稀有性，在真实的应用中缺乏地面真值离群点**。