## 一、已有的异常检测器：

1、**无监督**异常检测器：GOAD、DeepSVDD、RCA、RePEN、SLAD、ICL、NeuTraL
2、**有监督**异常检测器：DevNet、DeepSAD、RoSAS、PReNeT

#### 可扩展的异常检测器：

#### （一）ADBench中共计30个异常检测器

1、**ADBench中的无监督检测器**：这些方法不需要训练标签，假设在测试数据集中，正常实例比异常实例更常见。

**浅层的**有主成分分析（**PCA**），单类SVM（**OCSVM**），局部离群因子（**LOF**），基于聚类的局部离群因子（**CBLOF**），基于连接性的离群值因子（**COF**），基于直方图的离群值检测（**HBOS**），K-最近邻（**KNN**），子空间异常值检测（**SOD**），基于Copula的离群值检测器（**COPOD**），基于经验累积分布的离群值检测（**ECOD**），轻量级在线异常检测器（**LODA**），隔离森林（**IForest**）。

**深度的**有深度支持向量数据描述（**DeepSVDD**），深度自动编码高斯混合模型（**DAGMM**）

2、**ADBench中的监督检测器**：正常和异常训练数据集都包含标记的实例，方法是建立一个预测模型的异常和正常的类，然后比较这两个模型。

Naive Bayes（**NB**），支持向量机（**SVM**），多层感知器（**MLP**），随机森林（**RF**），极端梯度提升（**XGBoost**），高效梯度提升决策树（**LightGBM**），Categorical Boosting (**CatBoost**) ，剩余网络（**ResNet**），特征令牌化器+ Transformer（**FT Transformer**）

3、**ADBench中的半监督检测器**：这里的训练仅包括普通类案例。因此，任何不能被归类为普通的东西都被标记为异常。由于它们不需要异常类标签，因此它们比监督方法更常见。

通过对抗性训练进行半监督异常检测（**GANomaly**），深度半监督异常检测（**DeepSAD已实现**），表示基于随机最近邻距离的方法（**REPEN已实现**），Deviation Networks（**DevNet已实现**），基于成对关系预测的有序回归网络（**PReNet已实现**），自动特征编码器（**FEAWAD**），极端梯度提升离群值检测（**XGBOD**）

#### （二）Machine Learning for Anomaly Detection中共计28个异常检测器

我们确定了28种ML技术，这些技术可分为六类：**分类、集成、优化、规则系统、聚类和回归**。这些ML技术以两种形式使用：**独立模型或混合模型**。表4显示了所收集的研究文章中ML技术的频率。**很多研究者过去常常将一种以上的ML技术结合起来。**。此外，**支持向量机是最常用的技术，无论是独立的还是在混合模型中**。

![image-20240903200952961](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903200952961.png)

#### （三）Deep Learning for Anomaly Detection中的异常检测器

**高维和/或非独立数据中的异常检测**：异常通常在低维空间中表现出明显的异常特征，而在高维空间中变得隐藏和不可察觉**。**在**由原始特征或新构造的特征的小子集所跨越的降低的低维空间中执行异常检测是直接的解决方案**，例如，**在基于子空间[70，77，84，123]和基于特征选择的方法[12，109，111]中**。深度异常检测由三个概念范式组成-**用于特征提取的深度学习，学习常态的特征表示和端到端异常得分学习**。

1、**用于特征提取的深度学习**：这类方法旨在利用深度学习从高维和/或非线性可分离的数据中提取低维特征表示，用于下游异常检测。与**异常检测中流行的降维方法（如主成分分析（PCA）[21，140，180]和随机投影[80，112，123]）相比**，深度学习技术在提取语义丰富的特征和非线性特征关系方面表现出更好的能力[14，49]。一条研究路线是**直接使用流行的预训练深度学习模型，如AlexNet [75]，VGG [143]和ResNet [58]来提取低维特征。**另一个研究方向是**明确地训练深度特征提取模型，而不是用于下游异常评分的预先训练的模型**。**优势是有现成的模型可用，缺点是特征提取和异常评分完全脱节，往往导致异常评分不理想**。

2、**学习正态性的特征表征**：**这类方法在某种程度上将特征学习与异常评分相结合，而不是像上一节那样完全解耦这两个模块**。这些方法通常分为两类：**通用特征学习和异常度量相关特征学习**。前者代表性技术有**自动编码器（AE）、生成性对抗网络（GAN）和自监督模型分类**，后者代表性技术有**基于距离的度量，基于单类分类的度量和基于聚类的措施**。

3、**端到端异常评分学习**：该研究线旨在**以端到端的方式学习标量异常分数。与依赖于异常度量的特征学习相比，这种方法中的异常评分不依赖于现有的异常度量;它具有直接学习异常评分的神经网络**。下面我们回顾这一类别中的四种主要方法：**排序模型、先验驱动模型、软最大似然模型和端到端一类分类模型**。

![image-20240905154608876](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154608876.png)

![image-20240905154706461](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154706461.png)

#### （四）Outlier Detection: Methods, Models, and Classification中的异常检测器

#### （1）低维离群点检测技术

1、**基于邻近度的方法**：基于邻近度的方法基于离群值与附近数据点的关系来识别离群值。**一种常见的情况是离群值位于稀疏区域，在给定距离内只有很少的数据点，或者最近的数据点非常远**。有两种主要的方法来定义邻域：**k最近邻（k-NN）和以数据点为中心的预定半径内的邻域**。LOF [23]是一种著名的方法，它首先引入了局部离群值的概念。基于连通性的离群因子（COF）[36]解决了LOF的缺点。Papadimitriou等人[37]基于局部密度的定义提出了局部相关积分（LOCI）。受影响的离群值（INFLO）[38]使用反向最近邻集（k-RNN）与k-NN相结合来计算离群值得分。[39]提出了局部离群值概率（Loop）。基于子采样，使用**最近邻包络（iNNE）[40]**的隔离创建隔离区域以确定离群值分数。**LeSiNN [16]**是另一种离群值检测方法，也可以使用子采样构建模型。**iNNE和LeSiNN都具有线性时间复杂度，此外，iNNE和LeSiNN都使用集成来确保离群检测器的稳定性**。

![image-20240905162832856](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905162832856.png)

2、**基于聚类的方法**：基于聚类的离群点检测算法通常分为两步：**首先用聚类算法对数据进行分组，然后根据聚类结果分析数据的偏离程度。不属于任何聚类的数据点被认为是离群值**。除了聚类成员（无论是否在聚类中），还有两个其他常用的聚类相关量来构建离群值。**第一个是到聚类中心的距离，假设正常数据点靠近聚类中心，而异常值远离它们。第二个是簇的基数，假设正常数据点的簇是密集和大的，而离群数据点的簇是稀疏和小的。与基于最近邻的离群点检测方法相比，基于聚类的离群点检测方法的一个主要优点是检测效率高**。Jiang等人[44]提出了一种离群点检测方法，该方法基于改进的k均值聚类和从聚类中心构建的最小生成树。基于聚类的局部离群值因子（CBLOF）[46]是一种基于聚类的离群值检测方法，通过定量测量区分小聚类和大聚类。在Amer等人的后期工作中。[47]，证明了简单地去除CBLOF的簇基数可以产生更好的结果。CBLOF和LDCOF都具有独立于框架的合并的聚类算法。但正如[47]所建议的，具有固定数量的聚类（如k-means）的算法在性能上是有利的，并且由于潜在的非球形分布，建议高估聚类数量。Du等人。[17]设计了一种基于密度峰值聚类算法的局部离群值检测方法[48]，这是一种简单但有效的基于密度的方法，可以检测任意形状的聚类。

![image-20240905164918032](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905164918032.png)

3、**基于预测的方法**：**本节是各种投影技术的方法**（例如，随机投影[50]、LSH [29]等）为了**将原始数据转换到具有降低的维度或复杂度的新空间中，同时仍然保留邻近信息**。然后可以在投影空间中执行离群点检测，从而大大改善了执行时间。值得注意的是，**子空间技术也是一种直接投影**。**它们已被广泛用于解决高维数据的挑战**。投影索引最近邻（PINN）[51]基于随机投影方案来降低数据维度，随机投影优于其他降维技术（如PCA [57]）的优点是其效率。局部敏感离群值检测（LSOD）[52]利用局部敏感哈希（LSH）[29，53]来创建离群值的初始排名，LSOD集成了许多基于距离的离群值检测的修剪策略，包括PPSN [41]，ANNS [41]和PPSO [61]。Schubert等人提出了另一种基于投影的离群值检测算法[54]。此外，他们提供了一个分布式框架来扩展算法。Loda [55]采用稀疏随机投影线，Loda遵循了集合的精神，并演示了如何将多个弱离群值检测器组合在一起，从而产生非常好的结果**

4、**基于树的方法**：**从广义上讲，树模型的构建也可以被视为一种投影，其中原始数据点被映射到特定的树节点，并且这些树节点包含关于原始数据的邻近信息**。**柳塔尔。[28]开发了Isolation Forest，它是一种无监督的树集成**。**Hariri等人[56]提出了扩展隔离森林来解决隔离森林的缺点**。

![image-20240905165736586](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905165736586.png)

#### （2）高维离群点检测技术

高维数据实现效率的困难主要归因于两个原因。首先，**由于增加的维度，相似性搜索（诸如k-NN搜索）在计算成本方面变得更昂贵**。其次，**一些用于加速离群值检测的技术，如采样[66，67]，修剪[68]，排名策略[38，69]和有效的索引结构（R树[58]，X树[59]等），不适用**。**为了提高高维数据离群点检测的效率，Ghoting等人。[73]提出了递归分箱和重投影（RBRP）**。第3节中提到的**投影索引最近邻（PINN）[51]算法也旨在提高高维离群值检测的效率**。**[74]引入了一种基于角度的离群值检测方法（ABOD），以解决基于欧几里得距离的算法在面对高维数据集时遇到的质量恶化的问题**。为了降低时间复杂度，引入了两个近似变体：**FastABOD和LB-ABOD**。FastABOD将离群值得分计算的数据点对的选择限制在数据点的k-NN。**LB-ABOD是ABOD的一个下界近似，其目的是有效地获得具有最高分数的顶级离群值**。许多作品探索**子空间的解决方案**，**Kriegel等人。[75]**开发了一种离群值检测模式。**[76]提出了一种测量子空间对比度的方法，并相应地提出了一种称为高对比度子空间（HiCS）的子空间搜索方法**。**Sathe等人。[77]提出了RS-Hash，这是一种基于随机散列的非常有效和准确的子空间离群值检测方法****。除了上述方法，近年来其他有趣的工作包括：**HighDOD [80]**，使用动态子空间搜索方法和基于样本的学习过程; LODES [81]，依赖于一种新的基于局部密度的谱嵌入来识别非线性子空间中的离群值; RAMODO [82]使用表示学习来降低维度，并将其与基于随机距离的方法相结合[16]。

![image-20240905173128567](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905173128567.png)

#### （3）分布式异常检测技术

**Bhaduri等人。[110]开发了DOoR，这是ORCA方法[68]的分布式解决方案。Angiulli等人。[111]将SolvingSet算法[112]扩展到分布式环境。Bai等人[115]提出了LOF的分布式解决方案。分布式Top-N LOF（DTOLF）[114]为参考文献[116]中提出的Top-N LOF方法提供了分布式解决方案。Tsou等人。[12]提出了一种分布式无监督异常检测框架**。

![image-20240905175602124](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905175602124.png)

#### （4）基于深度学习的异常检测策略

为了解决当训练数据包含离群值时自动编码器对过拟合的敏感性，**Chen等人。[121]提出了一种基于集合的离群值检测方法**。**鲁棒深度自动编码器（RDA）[18]**通过将输入数据分为两个矩阵来解决受污染的训练数据问题，一个包含离群值，另一个由自动编码器有效重建。**Schlegl等人[122]设计了AnoGAN**，旨在检测图像数据中的异常作为疾病标记**。另一种基于GAN的异常检测方法是逆向学习异常检测（ALAD）[123]**。**[82]提出了一种基于深度神经网络的框架，称为RAMODO**。

![image-20240909184106509](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909184106509.png)

#### （5）人在环的异常检测技术

**一种典型方法是通过主动学习**[135]，基于此，**一些数据实例通过一些查询策略被领域专家标记**。**在Görnitz等人的工作中。[136]，异常检测被认为是一个名为支持向量数据描述（SVDD）的优化问题[137]**。**Das等人。[27]提出了一种半监督方法，该方法将专家反馈迭代地结合到称为Loda [55]的集成异常检测方法的模型中**。**Vercruyssen等人[11]描述了一种半监督异常检测方法**。**Siddiqui等人。[139]提出了一种用于异常检测的通用算法，旨在通过结合专家反馈将异常分数与应用程序特定的兴趣度对齐**。

![image-20240909184210867](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909184210867.png)

#### （五）Evaluation of Machine Learning Algorithms中的异常检测器

1、**经典ML算法**：**Logistic回归、朴素贝叶斯、K邻近（KNN）、决策树（Decision Tree）、自适应增强（Adaptive Boosting）和随机森林（RF）**

2、**深度学习算法**：**卷积神经网络（CNN）、卷积神经网络和长短时记忆（CNN-LSTM）、长短时记忆（LSTM）、门控递归单元（Gated Recurrent Units，GRU）、简单递归神经网络（Simple Recurrent Neural Network，RNN）和深度神经网络（Deep Neural Network，DNN）**

#### （六）A comprehensive survey of anomaly detection 中的异常检测器

1、**解决高维问题的策略**：已经提出了许多降维方法，例如**PCA，MDS，Karhunen-Loeve变换，局部线性嵌入，拉普拉斯特征映射和扩散映射**，以实现降维[51，70-74]**。**这些数据表示的内在维度小于可用的相关维度。已经提出了许多技术来测量内在维度[75-80]。**Wang等人。[86]提出了一种PCA以及可分离压缩感知算法**。Lazervic和Kumar [92]提出了一种模型，该模型使用称为“特征装袋”的评分系统来检测异常。**Kriegel等人。[23]采用了一种技术来选择信息或相关维度**。**[93]提出了一种名为“OUTERS”的子空间方法**。Zhang等人。**[94]提出了一种基于角度的子空间离群点检测方法**。**Thudumu等人。[41]提出了一种检测离群值的方法**。Koufakou和Georgiopoulos [61]提出的另一种算法称为混合属性数据集的离群值检测（ODMAD）。混合属性由Ye等人提出。[95]，他们提出了一种离群点检测算法，通过计算异常子空间结合信息熵来检测高维混合属性数据集中的异常。

2、**高维大数据中的工具（主要是一些并行框架）**

#### （七）Outlier Detection: Methods, Models, and Classification中的异常检测器

10种流行的离群点检测算法包括**kNN、kNNW、ODIN、LOF、Loop、COP、SOD、FastABOD、HiCS和高斯均匀混合模型（GMM）**。

![image-20240906183523232](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183523232.png)

#### （八）A comparative evaluation of outlier detection algorithms中的异常检测器

1、**概率方法**：概率算法通过推断模型参数θ来估计数据集X的概率密度函数。具有最小似然P（X|θ）的数据点被识别为离群值。**在[3]中，Blei等人描述了Dirichlet过程混合模型（DPMM）**。该算法在文献[8]的KDD 99数据集上进行了入侵检测，其性能优于SVM和KNN算法。**Kim等人在[13]中展示了这个问题，其中作者描述了一种鲁棒核密度估计（RKDE）算法**。**概率主成分分析（PPCA）[29]**是一种潜在变量模型，用于估计数据的主成分。**Quinn等人开发的最小二乘异常检测（LSA）[25]**将多类概率分类器扩展到一类问题。

2、**基于邻居的方法**：**在[4]中描述的局部离群因子（LOF）优于基于角度的离群值检测[16]和单类SVM [26]**。**基于角度的离群值检测（ABOD）[16]**使用在每个输入向量处测量的角度的半径和方差而不是距离来识别离群值。**子空间离群值检测（SOD）[15]**算法为每个点p找到p和它的k个最近邻居之间共享的m个邻居的集合。

3、**基于域的方法**：**落在定界边界之外的任何数据点都被标记为离群值**。**单类SVM [26]是支持向量机（svm）算法在单类问题中的应用**，属于这类算法

4、**隔离方法**：**隔离森林的概念是由Liu在[17]中提出的，它使用随机森林来计算每个数据点的隔离分数**。**作者指出，他的算法提供了线性时间复杂度，并在现实世界的数据集上证明了离群点检测性能明显优于lof**。

本实验中使用的大多数实现都是公开可用的。大多数方法具有灵活的参数，并且在没有大量调优的情况下执行得非常好**。**Python的Matlab引擎API和rpy2库允许我们从Python调用Matlab和R代码**。**iforest是一个很好的方法，有效地识别离群值，同时显示了良好的可扩展性。ocsvm在这个基准中是一个很好的候选者，但是它也不适合大型数据集**。**SOD表现出良好的离群值检测性能，并以较差的可扩展性为代价有效地处理高维数据集**。**指数族表示的dpmm显示是非常耗时的，而没有实质性地提高检测离群值的高斯为基础的方法，如dpgmm**。**LOF、ABOD、GWR、KL和LSA达到最低性能，而前三种方法也显示出较差的可扩展性。

#### （九）On the Evaluation of Outlier Detection and One-Class Classification Methods中的异常检测器

我们比较和评估了11种算法：**ABOD，Auto-Encoder，Gaussian Density，GLOSH，kNNglobal，kNNlocal，LOCI，LOF，Linear Programming，Parzen Windows和SVDD**。对于大多数比较算法，我们使用来自http://prlab.tudelft.nl/users/david-tax/ [25]的代码，除了LOF，LOCI，kNNlocal和GLOSH。**在LOF和LOCI的情况下，修改了它们的实现，以确保待分类的新观测不会影响内点类的预计算模型**。由于**KNNlocal在该存储库中不可用**，因此我们使用自己的算法实现。**GLOSH是根据http://lapad-web.icmc.usp.br/上提供的HDBSCAN* 的实施情况进行调整的**。

**SVDD和kNNglobal是单类分类的首选**，**而我们不推荐kNNlocal**。**此外，我们无法确认[13]中报告的LOF的最佳性能，而只能确认SVDD的最佳性能**。

#### （十）Supervised outlier detection for classification and regression的异常检测器

我们选择并比较了在文献中具有突出作用的**九种不同的离群值检测方法**，使用了**scikit-learn [10]或PyOD [11]中的实现**，这两个库是众所周知的Python库。们将在这里考虑九个代表性的OD模型，即**最小协方差决定性估计[21，22]**，**局部离群因子[23]**，**基于连通性的离群因子[24]**，**k-最近邻离群估计[25，26]**，**隔离森林[27，28]**，**一类支持向量机[29]**，**主成分分析（PCA）OD [30]，[31]**、**子空间异常值检测[32]**和**基于直方图的异常值检测[33]**。**一个非常好的参考是PyOD库[11]，我们使用了所有上述方法的实现，除了最小协方差行列式和隔离森林，我们使用它们的scikit-learn [10]实现**。本工作中应用的OD模型是**MCD，IF，KNN，LOF，OCS，PCA，COF，HBOS和SOD**，**在MCD和IF的情况下使用它们的scikit-learn实现，在其他情况下使用它们的PyOD版本**。**我们可以得出结论，一般来说，MCD和IF模型通常是一个很好的选择，而PCA，HBOS和LOF也应该考虑计算时间是一个加权因素**。

#### （十一）Human-in-the-loop Outlier Detection中的异常检测器

本文将HOD与众所周知的无监督离群值检测方法进行了比较，包括**KNN [40]、LOF [5]、聚类方法[23]和Ensemble方法[3]。以及基于主动学习的方法AI 2 [42]和AAD [14]**。还有基于实体匹配的方法**CrowdER和Magellan**。

主动学习方法：给定人力成本预算，主动学习方法从数据集中选择对象，要求人类标记这些对象并迭代地训练分类器，直到预算用完。

（1）**AI2 [42]**：每次AI2选择X个对象供用户标记，**其中X/2个对象来自非监督方法，其他X/2个对象由监督方法（随机森林）提供**。在X个对象被标记后，它重新训练监督模型并选择另一个X个对象，直到预算用完。最后，利用该模型对剩余的未标记数据进行预测。

（2）**AAD [14]**：首先，AAD提取每个对象的特征，并使用监督方法来训练分类器。接下来，基于建模结果，AAD选择一个最有可能成为人类标记的离群值的对象。然后，它迭代地重新训练模型，以调整每个特征的权重，并选择新的离群候选。

#### （十二）Progress in Outlier Detection Techniques: A Survey中的异常检测器

异常检测算法包括**基于统计、距离、密度、聚类、图、集成和学习**的方法。

> 1、基于密度：Breunig等人[8]提出了**局部异常值因子（LOF）**方法；Tang等人[80]提出了称之为**基于连接的离群值因子（COF）**，简化了LOF方法；为了确定哪个阈值分数可以作为LOF中的离群值，Kriegel等人[81]提出了称为**局部离群概率（Loop）**的更稳健的离群值检测方法；Papadimitriou等人[82]提出了一种称为**LOCI的LOcal相关积分及其离群值度量多粒度偏差因子（MDEF）的技术**处理多粒度问题，**以及称为aLOCI的LOCI近似版本**；Ren等人提出了一种具有更好的修剪功能的称为**相对密度因子（RDF）**的方法；Jin等人[75]提出了**INFLuenced Outlierness（INFLO）**，这是另一种类似于LOF的局部离群值检测技术；为了适应高维数据计算，Keller等人[85]提出了一种**高对比度子空间方法（HiCS）**；Campello等人[86]提出称为层次结构的**全局-局部离群值得分（GLOSH）**的算法用于高维计算；Momtaz等人[87]引入了一种新的基于密度的离群值检测技术，该技术通过为每个对象提供称为**动态窗口离群值因子（DWOF）的分数**来检测前n个离群值；Lozano等人[90] -**并行LOF算法（PLOFA）**；Vázquez等人[91]提出了一种新的算法来检测基于低密度数据模型的离群值，**称为稀疏数据观测器（SDO）**；Su等人[93]提出了一种有效的基于密度的方案，该方案基于分散数据的局部OD方法，**称为E2DLOS**。它们不依赖于假设的分布来拟合数据，但对参数设置很敏感，例如确定邻居的大小
>
> 2、基于统计：基于统计的方法通常分为两大类-**参数和非参数方法**。这两种方法的主要区别在于**前者对给定数据的潜在分布模型进行假设**，并从已知数据中估计分布模型的参数。**后一种方法没有任何关于分布模型先验知识的假设**[98]。（1）参数方法两种众所周知的方法是**高斯混合模型**和**回归模型**。**高斯**：Yang等人[101]介绍了一种具有**全局最优基于样本的GMM（高斯混合模型）的无监督离群值检测方法**；Tang等人提出了使用**具有局部保持投影的GMM[102]**。他们结合使用GMM和子空间学习，在能量分解中进行稳健的离群值检测，这项研究解决了以前的方法，LOF [8]和Tang等人的研究空白；**回归**：Park等人[105]提出了另一种基于回归的离群值检测技术；在2017年，Dalatu等人[106]通过分析受试者工作特征（ROC）曲线的误分类率和准确性，对离群值检测的线性和非线性回归模型进行了比较研究，对于离群值检测，**非线性模型（93%的准确度）往往比线性模型（68%的准确度）更适合**；（2）核密度估计（KDE）是一种用于检测离群值的常见非参数方法[107]，**Latecki等人在[108]中提出了一种使用核函数进行离群值检测的无监督方法**；**Gao等人[109]提出了一种更好的方法来解决之前的一些缺点**；作者在[111]中提出了一种**自适应核密度估计器（AKDE）**的近似方法；mrithy等人[113]提出了一种**非参数在线离群值检测算法来检测大数据流中的离群值**。Zhang等人[114]还研究了**使用高斯核的自适应核密度技术**，用于检测非线性系统中的异常。Qin等人[115]**提出了一种新的局部离群值语义，它可以很好地利用KDE来有效地从数据流中检测局部离群值**；多数KDE方法的一个大挫折是它们通常遭受高计算成本和维数灾难，这使得它们在实践中非常不可靠。（3）其他的统计方法有**直方图[116]和其他统计测试[40]，如箱形图，修剪平均值，极端学生化偏差和迪克森类型测试[40]**；Goldstein和Dengel [116]提出了一种**基于直方图的异常值（HBOS）检测算法**，该算法使用静态和动态箱宽直方图来对单变量特征密度进行建模；**Hido等人[95]提出了一种新的统计方法，通过使用定向密度比估计**，用于基于内点的离群点检测问题；Du等人[118]提出了另一种具有统计参数的鲁棒技术来解决局部离群值检测问题，称为**鲁棒局部离群值检测（RLOD）**。统计方法在数学上容易接受和实现，但多数不可靠且不适用高维场景。与PCA方法[103]相比，**Tang等人的方法[102]对离群值和噪声检测问题给出了稳健的改进。在HBOS [116]中，他们的方法显示出良好的计算速度，甚至超过一些基于聚类的算法和其他类型的算法（LOCI，LOF，INFLO），因此使其适合大规模近实时应用。而Hido等人[95]的方法对于大规模数据集更具可扩展性，Du等人[118]的方法具有更稳健的分析**。
>
> 3、基于距离：基于距离的离群值检测方法是**温和的非参数方法，适用于中高维的大型数据集**。与统计技术相比，它们往往具有更强大的基础，**更灵活，计算效率更高**。Knorr和Ng [122]和Ramaswamy等人[123]是最早提出**在大型数据集中检测离群值**的技术的人之一；Angiulli等人[7]与传统的方法稍有不同，**该算法可以从给定的未标记数据集中检测出顶级离群值，并预测未检测到的数据点是否是离群值**；Ghoting等人[124]提出了一种称为**递归分箱和重新投影（RBRP）**的算法，以提高高维数据集的计算速度；Zhang等人。[76]提出了一种基于局部距离的离群值检测方法，**称为基于局部距离的离群值因子（LDOF）**，他们的研究表明，与LOF相比，在邻居大小范围内的性能有所改善；Huang等人[126]提出了一种称为**基于秩的检测算法（RBDA）**的方法来对邻居进行排序；Radovanovi'c等人[129]**提出了一种反向最近邻方法来解决高维数据集中计算离群值的最大挑战之一，即“维数灾难“**；Ren等人[134]提出了Ramaswamy等人的改进版本用于更好的剪枝，技术[123]，**一种基于垂直距离的离群值检测方法**；Vu等人[135]引入了**多规则离群值（MIRO）**，该方法采用了与[134]类似的技术，通过使用修剪技术来加速检测离群值的过程。基于距离的方法大多**不依赖于假设的分布来拟合数据**，它们**在多维空间中的扩展性更好**，因为它们**具有强大的理论基础**，**并且与统计方法相比，它们的计算效率更高**。高**维空间中的邻域和KNN搜索的搜索技术是昂贵的任务**。大多数基于距离的方法的关键缺点之一是它们**无法很好地扩展非常高维的数据集**。
>
> 4、基于聚类：聚类方法与离群值检测过程不同**。**聚类方法的主要目的是识别聚类，而孤立点检测方法的主要目的是检测孤立点。基于聚类的技术的性能高度依赖于聚类算法在捕获正常实例的聚类结构方面的有效性[146]。**分区聚类方法**：属于这一组的算法的一些例子包括PAM [147]，K-Means [148]，K-Means [149]，K-Means [147]等；**层次聚类方法**：它们将对象集划分为不同级别的组，并形成树状结构。要将它们分组到不同的级别，通常需要最大数量的群集。一些例子包括MST [150]、CURE [151]、CHAMELEON [152]；**基于密度的聚类方法**：它们不需要像在划分方法的情况下那样初始给定聚类的数目;例如K-均值。给定集群的半径，他们可以将集群建模为密集区域。密度聚类方法的一些示例包括DBSCAN [153]和DENCLUE [154]；**基于网格的聚类方法**：STING [94]，Wavecluster [155]，DCluster [156]； **高维数据的聚类方法**：CLIQUE [157]，HPStream [158]。Cao等人[9]和Chen等人[159]分别提出了一种**称为DenStream的两阶段算法**；**在另一种技术D-Stream [159]中**，它类似于DenStream，具有在线和离线组件；**Ren等人[161]提出了SDstream**，这是一种使用滑动窗口模型的算法；**Assent等人[162]提出AnyOut**来快速计算和检测流数据中任何时间的离群值；**Elahi等人。[163]，使用k-means，提出了一种基于聚类的离群值检测技术**；作者提出了一种**基于聚类的框架来检测变化数据流中的离群值[165]**，当这种技术与LOF [8]相比时，它具有更少的时间消耗，显示出更高的离群值检测率，以及更低的误报率；在另一项工作中，Bhosale等人提出了一种无监督的离群值检测方案，**该方案使用基于密度和基于分区的方案进行流数据[167]**。它具有比[163]更高的离群值检测率。**Moshtaghi等人[169]使用聚类方法提出了一个模型**，将聚类边界外的对象标记为离群值。与[169]类似，**Moshtaghi等人在另一项工作中提出了eTSAD [170]**，这是一种使用已建立的椭圆模糊规则对流数据进行建模的方法。**Salehi等人[171]提出了一种用于演化数据流的集成技术**。**Chenaghlou等人[172]提出了一种有效的离群点检测算法**，其中提出了活动聚类的概念，以获得更好的时间和存储器有效的离群点检测结果。**Rizk等人[173]提出了一种优化的计算算法**，该算法增强了在大型和小型聚类中搜索离群值的过程。**Chenaghlou等人[174]扩展了他们在[172]中的工作，提出了一种可以实时检测离群值的算法**。该算法不仅能真实的检测离群点，而且能发现聚类的有序演化。基于聚类的方法对于数据流中的离群点检测非常有用，是相对简单和可扩展的，大多数聚类方法都依赖于用户预先指定聚类的个数，划分方法据说对初始化阶段、异常值和噪声高度敏感。
>
> 5、基于集成：基于集成的方法通常用于机器学习，因为与其他相关方法相比，它们具有相对更好的性能。尽管与其他OD方法相比，用于离群值检测的基于集合的技术的报告很少[37]，[38]，[176]-[182]。。近年来，**已经引入了几种技术，包括：（I）Bagging [37]和boosting [184]用于分类问题（ii）隔离森林[192]用于并行技术。(iii)对于顺序方法[185]和极端梯度提升离群值检测（XGBOD）[183]以及混合方法的Bagged Outlier Representation Entrial（BORE）[186]。**Lazarevic等人[37]提出了**第一个已知的集成方法**，用于使用集成方法改进离群值检测；Aggarwal [178]提出了**一项关于离群值集成分析的研究**，该研究最近引起了文献[187]，[236]的极大兴趣；其他随后的研究[38]，[190]，[191]在后来的几年里，专注于使用集合进行离群值检测面临着许多挑战；Schubert等人[191]**使用相似性度量比较了基于评分的离群值排名**；2010年早些时候，**Nguyen等人[38]提出了基于随机子空间的异质检测器包围（HeDES）**，HeDES可以将不同的技术结合在一起，产生不同的离群值和分数类型;例如，实值与二进制值；**Pasillas-Diaz等人[177]考虑了子采样和特征装袋技术**；Zhao等人[227]提出了一种无监督离群值检测器框架，即**离群值集合的检测器分数动态组合（DCSO）**；Zhao等人[228]提出了**并行离群值集成（LSCP）框架中的局部选择性组合**，以解决[227]中的相同问题；Aggarwal等人[229]**离群值集成书对离群值集成方法进行了详细的讨论**。集成方法更稳定，并提供更好的预测模型，适用于高维数据中的离群值分析。与其他数据挖掘问题相比，在检测离群值的上下文中的集成技术开发得很差。此外，选择正确的元检测器是一项艰巨的任务。
>
> 6、基于学习：离群值检测过程中基于学习的方法已应用于机器学习的不同子学科-**主动学习，基于图的学习和深度学习**。（1）主动学习：**Aggarwal等人[6]在离群值检测中使用主动学习的概念来解决给出离群值被标记的明确原因以及促使基于密度估计的OD方法的相对高的计算需求的模糊性**。Gornitz等人[200]提出了另一项工作，其中**应用主动学习策略进行异常检测**；Das等人。[196]，[197]使用主动方法询问人类分析师以获得更好的结果；Das等人[201]然后提出了一种通过集成的主动离群值检测方法，称为**GLocalized Anomaly Detection（GLAD）**。人类分析员发现真实异常值的过程可能是困难的，未来人类分析员需要通过设计和配置有效的异常值检测器来最小化误报的影响的技术。在离群值检测的背景下，主动学习需要坚实的解释和解释，以便在研究界得到很好的理解。（2）子空间学习：大多数离群点通常表示为降维子空间中的罕见邻域活动。**Zimek等人[179]指出，只有具有重要属性的子集才能提供有价值的信息**。在孤立点检测领域，子空间学习在高维问题中得到了广泛的研究和应用。这**些方法主要分为稀疏子空间[195]，[196]和相关子空间[126]，[198]，[202]方法**。**前者将高维数据点投影到稀疏的低维子空间上。然后，稀疏子空间内的这些对象可以被标记为离群值，因为它们具有较低的密度**。这些方法的一个**很大的缺点是从整个高维空间探索稀疏投影的时间消耗**。为了解决这个缺点**，Aggarwal等人。[6]提出了一种方法，提高了探索子空间的有效性**。子空间是通过进化算法实现的。然而，该算法的性能评估是高度依赖于初始种群。**Dutta等人[196]提出了一种实现稀疏空间的方法**。他们应用稀疏编码将对象开发到多个线性变换空间。**Huang等人[126]提出了子空间离群点检测（SOD）**，一种相关子空间方法。**Kriegel等人[17]应用主成分分析来获得相关子空间**，并通过伽马分布计算Mahalanobis距离来检测离群值。**Keller等人[85]设计了一种灵活的OD技术，该技术使用子空间搜索和离群值排名过程**。（3）基于图的学习：**Akoglu等人[34]提出了一个全面的调查基于图的离群检测技术和描述**。其中包括最先进的方法和一些开放的研究挑战和问题，基于图的异常值检测方法至关重要，因为它们显示了数据的相互依赖状态、富有洞察力的表示和强大的机制。Moonesinghe等人[204]提出了**Outrank，这是第一个构建的基于图的离群点检测框架之一**；**Wang等人[205]提出了一种新的方法**，将图的表示与每个对象在其周围环境中的局部信息结合在一起。**Wang等人[206]在另一项研究中提出了另一种OD方**法，该方法从不同的角度捕获不同的局部信息。由于使用基于图的学习方法尚未被广泛接受，因此它是未来离群点检测研究的另一个领域（4）深度学习方法：**深度学习在许多领域得到了更多的关注，包括与离群值检测问题相关的几项研究[35]，[36] [30]，[207]-[209]**。最近，C**halapathy和Chawla [32]在他们的调查中提出了一项针对离群值检测的深度学习方法的全面研究**。他们回顾了深度学习方法如何用于各种异常值检测应用程序并评估其有效性。深度学习可以基于监督、半监督和无监督的方法来学习数据表示。但是，**大多数采用半监督和无监督的方法。这是因为，监督方法缺乏标记训练数据的准备，并且存在类不平衡的问题，这使得它对其他方法来说是次优的**。主动学习中，由于该技术不是被动学习，因此减少了检测离群值的时间消耗；基于图的方法显示了数据的重要的相互依赖状态；深度学习技术有助于提供和展示从数据中学习分层区别特征的更好方法；一些基于学习的技术，如子空间学习，可能是**计算昂贵的，并具有挑战性的发现离群值的相关子空间**。

#### 二、已有的数据集：

dry bean、obesity、wine quality、apple quality、balita、iris、wine、adult（来自UCI/Kaggle数据集）

#### 可扩展的数据集如下：

1、**合成数据集**：可根据**ADBench中的合成方法合成“真实”的合成数据，支持多种类型的异常生成**：**局部异常、全局异常、依赖异常和异常群**。ADBench中57个真实基准数据集（**已补充**）。

2、Generalized Out-of-Distribution中的离群值划分：**要在MNIST上构建离群值检测基准，应选择一个类，以便将属于该类的所有样本视为内点。一小部分来自其他类别的样本被引入作为待检测的离群值。**Generalized Out-of-Distribution中的12个真实数据集，在第5节的当前研究中分析的数据集可以在OpenOOD存储库https://github.com/Jingkang50/OpenOOD中找到（**图像数据集**×）。

3、Machine Learning for Anomaly Detection中的异常分类：**点异常，上下文异常和集体异常**。Machine Learning for Anomaly Detection中22个不同的数据集（**数据集不具有代表性，否掉了**×）。

4、Deep Learning for Anomaly Detection中的异常分类：**点异常，上下文异常和集体异常**。**异常检测发展的一个主要障碍是缺乏具有真实的异常的真实世界数据集**。我们在表3中总结了**21个公开可用的具有真实的异常的真实世界数据集的集合**，以促进对这些数据集的性能评估。这里**只包括大规模和/或高维复杂数据集**。为深度异常检测提供具有挑战性的测试平台。此外，**在https://git.io/JTs93上提供了广泛使用的异常检测数据集**（包括表3中的一些预处理数据集）的持续更新集合（**已补充**）。

![image-20240905154951383](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154951383.png)

5、Outlier Detection: Methods, Models, and Classification中的异常值分类：**（1）点离群值和（2）集体离群值[14]，点异常值可进一步分为（1）局部异常值和（2）全局异常值**。本文认为**离群值在其特征方面不同于正常值，与正常实例相比，离群值在数据集中是罕见的**。**anomalies表明了一种不同的潜在生成机制。相比之下，Outliers往往强调统计稀有性和偏差，而它们是否由不同的机制产生并没有直接说明**。在统计学和机器学习的某些情况下，**outliers是指那些使模型更难拟合的数据实例**。**在监督学习中，anomalies是更好的术语，因为有可靠的指导来建模异常的生成机制**（**无数据集补充**）。

6、Evaluation of Machine Learning Algorithms在**CICIDS-2017，UNSW-NB 15和工业控制系统（ICS）网络攻击数据集**上开展实验（**无数据集补充**）。

7、A Comparison of Outlier Detection Techniques的数据集来源为**人工数据集和真实数据集**。**Wang等人[37]提供了一些在不同情况下具有异常值的合成数据集**。真实世界的数据集通常来自三个来源，如下所示：

> 1、**UCI机器学习库**。这些数据集中的大多数已被提议用于评估分类方法。**对于离群点检测任务，常用的策略是通过将小类中的对象作为离群点，其余的作为正常对象来预处理数据集**（**已补充**）。
>
> 2、**ELKI数据集**。ELKI是一个积极开发和维护的“用于开发索引结构支持的KDD应用程序的环境”。最近的版本特别致力于异常值检测。**该平台不仅提供了离群点检测算法，还提供了用于离群点检测评估的多个数据集（已补充）**。

**在分类中主要使用的数据集需要进行预处理以用于离群值检测任务**。在预处理期间，可以考虑两种情况：

> 1、**对于语义上有意义的离群数据集，与稀有对象相关联的类被视为离群值，其余的被视为正常数据**。
>
> 2、**对于其他数据集，从数据集中随机选择离群值类。特别地，对于只有两个类的数据集，具有次要对象的类通常被视为离群点（已补充）**。

**我们在9个数据集上对10种流行的离群点检测算法进行了实验比较**。离群点检测算法包括**kNN、kNNW、ODIN、LOF、Loop、COP、SOD、FastABOD、HiCS和高斯均匀混合模型（GMM）**。**其中“N”和“O”分别指所有对象和离群值的数量**（**已补充**）。

![image-20240906183347756](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183347756.png)

8、A comparative evaluation of outlier detection algorithms使用15个数据集，范围从723到20，000个样本，包含6到107个特征。在这些数据集中，有12个在UCI [1]或OpenML [30]存储库中公开，而剩下的3个数据集是包含Amadeus公司生产数据的新型专有数据集（**已补充**）。

![image-20240906222707675](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906222707675.png)

9、On the Evaluation of Outlier Detection中我们使用来自**UCI机器学习库[17]的31个真实世界数据集作为单类分类的预处理**，并在http://prlab.tudelft.nl/users/david-tax/上提供：**Abalone, Arrhythmia, Balance-scale, Ballbearing, Biomed, Breast, Cancer, Colon, Delft1x3, Delft2x2, Delft3x2, Delft5x1, Delft5x3, Diabetes, Ecoli, Glass, Heart, Hepatitis, Housing, Imports, Ionosphere, Iris, Liver, Satellite, Sonar, Spectf, Survival, Vehicle, Vowels, Waveform and Wine（不具有代表性×）**

10、Supervised outlier detection for classification and regression使用**八个回归数据集和八个分类数据集**。 更准确地说，将考虑以下数据集：用于回归的 abalone、boston、cal-housing、concrete、cpusmall、mg、winequality_red 和 winequality_white，**以及用于分类的 australian、breast_cancer、diabetes、digits、dna、german、satimage 和 snippet（不具有代表性×）**。

11、Progress in Outlier Detection Techniques: A Survey中

## 三、现有的评价指标：

**accuracy**（分类准确度）、**F1** 分数、**ROC-AUC** 分数、**precision**（分类精确度）、**recall**（召回率）、**Confusion Matrix**（混淆矩阵）、**Precision-Recall Curve** （PR曲线）

Matthews Correlation Coefficient (**MCC**)、**F-beta** Score、**Area Under Precision-Recall Curve** (**PR AUC**)、**Balanced Accuracy**、**G-Mean**、Average Precision (**AP**)

1、ADBench基准使用了**ROC-AUC** 分数、**Area Under Precision-Recall Curve** (**PR AUC**)、**基于Wilcoxon-Holm方法的临界差异图（CD图）**[34，70]用于统计学比较AD方法组（p ≤ 0.05）

2、Generalized Out-of-Distribution中使用了**F-scores，AUROC和AUPR**指标。此外，本工作认为离群检测器的评估还可以**通过其支持的主要任务的性能来评估**。例如，**如果使用离群值检测器来净化具有噪声标签的数据集，则在经净化的数据集上训练的分类器的性能可以指示离群值检测器的质量**。

3、Machine Learning for Anomaly Detection中提到使用最多的性能指标是**真阳性率（即召回率）（TPR）**，它测量被正确分类的异常。此外，116篇论文使用**假阳性率（FPR）**作为性能指标，该指标测量被错误分类的异常。**ROC 曲线** 是以假阳性率（FPR）为横轴，真阳性率（TPR）为纵轴绘制的曲线，**ROC曲线是用于有效评估入侵检测系统性能的最强指标之一**。此外，**准确度（Acc），精度和F-分数经常被研究人员作为性能指标**，Acc是正确分类的异常百分比。**AUC测量整个ROC曲线下的整个二维面积**。精确度通常与F分数和召回率相关，它测量被正确分类为攻击的异常的比率。除了性能指标之外，许多论文还提出了**计算性能指标，例如CPU利用率、执行时间、训练时间、测试时间和计算时间**。

4、Evaluation of Machine Learning Algorithms选用了**准确度、精确度、召回率、F1评分和受试者工作特征（ROC）曲线**这些评价指标。在12个参与对比的算法上**随机森林（RF）算法**达到最佳性能。

5、A Comparison of Outlier Detection Techniques的评价指标为**AUC、Precision（P）、Average precision (AP)、Rank Power (RP)、相关系数**。

6、A comparative evaluation of outlier detection algorithms选择了**ROC曲线下面积**和**精确度-召回率（PR）曲线**。为了全面概述这些方法，我们还对每种方法的**训练时间，预测时间，内存使用和鲁棒性**进行了基准测试。

7、Progress in Outlier Detection Techniques: A Survey中选择了**Precision**、**R-precision**、**Average precision**、**AUC**、**Correlation coefficient**和**Rank power (RP)**这些指标

8、Progress in Outlier Detection Techniques: A Survey中的评估指标：

> 1、Precision：表示**正确离群值数量m除以离群值总数t的比值**。**在特定的应用中，设置t可能是困难的。因此，t通常被指定为地面真实值中离群值的数量**。
>
> 2、R-precision：这是指**正确离群值在识别出的最大数量的地面真实潜在离群值中的比例**。R-精度不包含足够的信息，因为与数据的总大小相比，真实离群值的数量是最小的。
>
> 3、Average precision：**这表示在离群点的等级上的精度分数的平均值。它结合了召回率和精确度**。
>
> 4、Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)：**ROC是示出了真阳性率对假阳性率的曲线图**。**真阳性率或假阳性率表示实际数据中离群值最多的潜在离群值中离群值或内值的数量。AUC显示了离群值检测方法的数值评价性能**。
>
> 5、Correlation coefficient：是相关性的数值度量，即，两个变量之间的统计关系。例如，斯皮尔曼等级相似性或皮尔逊相关性。**更重要的是放在可能的离群值排名在顶部**。
>
> 6、Rank power (RP)：**它将真正的离群值排在顶部，将正常值排在底部**。它全面评估真实离群值的排名。

了解离群值评分的相似性或相关性被认为是构建更好OD方法的非常重要的一步，**AUC完全忽略了分数之间的微小变化，只考虑排名**。**与精确率-召回曲线下区域等技术相比，它对于不平衡的类问题也较差且不完美，而精确率-召回曲线下区域等技术在突出微小的检测变化方面显示出更好的可能性**。然而，尽管存在这些缺点，**AUC，ROC和精确召回仍然作为评估许多离群值检测问题的事实上的标准**。Schubert等人[191]在其研究中给出了一个全局视图，允许评估不同方法的性能。Goldstein等人关键发现是**LOF [8]，INFLO [75]，COF [80]和Loop [81]等局部离群值检测算法不适合检测全局离群值**，因为它们在由全局离群值组成的数据集上表现不佳。**建议对于全局任务应用最近邻技术，而对于局部任务，LOF等局部离群算法比其他基于聚类的方法更适合**。

#### 可扩展的指标如下：

**1、Matthews Correlation Coefficient (MCC): 这个指标综合考虑了真阳性、真阴性、假阳性和假阴性。MCC 的值在 [-1, 1] 范围内，1 表示完美分类，0 表示随机分类，-1 表示完全错误的分类。**
**2、Balanced Accuracy: 这是对分类器准确度的调整，尤其在类别不平衡时。它是各类别召回率的平均值。**
3、Kappa Statistic (Cohen’s Kappa): 这个指标用来测量分类器的预测结果与随机预测结果之间的一致性。它考虑了偶然的一致性。
**4、G-Mean: 这个指标是各类别召回率的几何平均值。它在处理不平衡数据集时非常有用。**
5、Log-Loss (Logarithmic Loss): 这个指标用来评估分类器的概率预测质量，尤其是在概率预测时比准确度更有用。它计算的是预测概率与实际标签之间的差距。
6、Brier Score: 类似于 Log-Loss，用于评估概率预测的准确性，尤其适用于概率模型
7、Youden's J Statistic: 这个指标用于评估分类器的诊断能力。计算公式是：J=Sensitivity+Specificity−1J=Sensitivity+Specificity−1。
**8、F-beta Score: F1 分数是 F-beta 分数的特例，其中 beta=1。F-beta 分数通过调整 beta 参数来平衡精确度和召回率的权重。beta > 1 更关注召回率，beta < 1 更关注精确度。**
**9、Average Precision (AP): 在不同的阈值下计算精确度和召回率的平均值，通常用于评估 PR 曲线下的性能。**
10、Hamming Loss: 计算每个样本的标签预测错误的比例，适用于多标签分类问题。
11、Top-K Accuracy: 在多类别分类问题中，这个指标检查模型是否能将正确类别的概率排在前 K 名中。
12、Cumulative Gain and Lift Charts: 这些图表用于评估模型在不同层级的表现，特别是对于营销和广告中的分类问题。
**13、Area Under Precision-Recall Curve (PR AUC): 计算 PR 曲线下的面积，可以用来衡量模型在处理不平衡数据集时的表现。**
14、Kullback-Leibler Divergence (KL Divergence): 用来衡量模型预测分布与实际分布之间的差异，适用于评估概率预测。

## 四、现有的实验设计角度：

### 4.1 AD算法如何在不同的监督级别下执行

1、**在10%的标记异常下，大多数有标记的算法优于最佳无监督算法CBLOF**（用虚线表示）。

2、**没有一种无监督方法在统计上优于其他方法**。一些基于DL的无监督方法，如DeepSVDD和DAGMM，比浅层方法差得惊人，**没有标签信息的指导，基于DL的无监督算法更难训练**（由于更多的超参数）

3、**当标签信息有限时，半监督方法优于监督方法**。对于大多数半监督方法，仅1%的标记异常就足以超过最佳无监督方法（如图4 b中的虚线所示），而大多数监督方法需要10%的标记异常才能实现。

4、**最新的网络架构，如Transformer和新兴的集成方法，在AD中产生有竞争力的性能**。图4b示出了FTTransformer和集成方法（**如XGB（oost）和CatB（oost）**）在所有标签通知算法中提供令人满意的检测性能，即使这些方法不是专门针对异常检测任务提出的。**这可能归功于它们通过聚合处理不平衡AD数据集的能力**。

5、**HBOS、COPOD、ECOD和NB是最快的**，因为它们独立处理每个功能。**XGBOD、ResNet和FTTransformer的计算量很大**。值得注意的是，**算法选择和超参数优化在无监督AD中很重要，但有限的工作[13，109，194，199，200]已经研究了它们**。我们也可以考虑自我监督[140，158，161，179]和迁移学习[33]来改善表格式AD。

### 4.2 AD算法如何响应不同类型的异常

1、**无监督算法的性能高度依赖于其假设和潜在异常类型的对齐**。**局部异常因子（LOF）在统计上优于局部异常的其他无监督方法**（图5a），并且**使用第k个（全局）最近邻的距离作为异常分数的KNN是全局异常的统计最佳检测器**（图5 b）。同样，没有算法在所有类型的异常上都表现良好; LOF在局部异常上实现了最佳AUCROC（图5a），在依赖性异常上实现了第二好的AUCROC排名（图5c），但在聚类异常上表现不佳（图5d）。

2、**关于异常类型的先验知识的“力量”可能超过部分标签的使用**。对于局部、全局和依赖异常，大多数标签通知方法的性能都比每种类型的最佳无监督方法（对应于LOF、KNN和KNN）差。我们认为，**部分标记的异常不能很好地捕捉特定类型的异常的所有特征，学习这样的决策边界是具有挑战性的**。

3、**可以利用异常类型作为有价值的先验知识**。在理想情况下，可以**通过动态模型选择和组合等框架，基于异常类型的组成来组合联合收割机多个AD算法[197]**。另一个有趣的方向是**使用合成生成的异常来训练离线AD模型，然后将其用于具有可能相似异常类型的真实世界数据集的在线预测**。

### 4.3 AD算法对噪声和损坏数据的鲁棒性如何

**1、无监督方法更容易受到重复异常的影响**。在许多应用中，由于记录错误等原因，某些异常可能会在数据中重复多次[83]。当异常重复6次时，无监督方法的中位数AUCROC为− 16.43%，而半监督方法为−0.05%（图7b），监督方法为0.13%。一种解释是，**无监督方法通常假设基础数据是不平衡的，只有一小部分异常它们依赖于这个假设来检测异常**。

**2、由于特征选择，不相关的特征对监督方法的影响很小**。**表格数据可能包含由测量噪声或不一致的测量单位[28，55]引起的不相关特征，其中这些噪声维度可能隐藏异常数据的特征，并因此使检测过程更加困难[128，150]**。例如，**像XGBoost这样的集成树可以过滤不相关的特征**。此外，监督方法（和一些半监督方法，如DevNet）的鲁棒性能表明，**标签信息可以有利于特征选择**。

**3、半监督和全监督方法都对轻微的注释错误表现出很大的弹性**。虽然现有研究[131，152]探讨了未标记样本中的异常污染，但我们进一步讨论了**标记污染对算法性能的更普遍影响**，**其中考虑了正常样本和异常之间的标记翻转[122，202]（高达总标记的50%）**。此设置不影响未受监督的方法，因为它们不使用任何标签。

4、我们的研究结果表明，**有一个强大的无监督AD算法的改进空间**。**一个直接的补救措施是采用无监督特征选择[30，125，126]来对抗不相关的特征**。此外，标签信息可以作为模型训练的有效指导，以对抗数据噪声，并且它有助于半监督和全监督方法更加鲁棒。**鉴于获取完整标签的困难，我们建议使用半监督方法作为设计更强大的AD算法的骨干**。

## 五、现有的特征选择技术

**特征选择/提取**已经在文献中被广泛发现，并且它是朝着丢弃不相关数据的重要举措，这**有助于增强和提高所建议的模型的精度和计算效率**。图4展示了正在应用的21种不同的特征选择/提取技术。此外，**我们注意到PCA和CFS是异常检测中最常用的特征选择技术**（**已实现，没用**）。

![image-20240903201010569](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903201010569.png)

## 六、附加材料

![image-20240909164409177](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909164409177.png)

**假阳性率（FPR）** 的公式如下：

![image-20240909164437535](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909164437535.png)

**真阳性率（TPR）** 的公式如下：

![image-20240909164538170](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909164538170.png)

1、Evaluation of Machine Learning Algorithms使用七个评估矩阵来衡量所选ML算法的性能，即**准确度**，**精确度**，**真阳性率**（TPR），也称为召回率，**假阳性率**（FPR），**F1分数**，**受试者操作特征（ROC）曲线**和**混淆矩阵**。

![image-20240905194109674](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905194109674.png)

## 七、异常检测器开源库

### 1、ADBench开源库（已下载）

包含开源数据集，合成数据生成器，和开源异常检测算法

### 2、PYOD开源库（已下载）

包含多种开源异常检测算法，PyOD用于检测多变量数据中的离群值。它是一个可扩展的Python工具，已被用于许多研究和商业项目，包括新的深度学习和离群集合模型[60]，[62]，[233]。

在readme文件中附带异常检测学习资料[Anomaly Detection Resources](https://github.com/yzhao062/anomaly-detection-resources)

分布式系统的pyod为[PyOD on databricks](https://www.databricks.com/blog/2023/03/13/unsupervised-outlier-detection-databricks.html).

### 3、NAB开源库（×主要为时间序列）

包含多种开源时间序列真实数据集和新颖的评分机制

### 4、徐宏祚的库（已有）

包含多种开源异常检测算法，合成数据生成器

### 5、Alibi-detect开源库（已下载，有部分异常监测库，不太实用）

包含了多种针对表格，时间序列和漂移检测的异常检测算法

### 6、PyCaret开源库（已下载，有部分异常监测库，主要用于简化代码）

这是一个自动化机器学习库，其中包含异常检测模块。它提供了一个简单的接口来处理各种异常检测任务。

### 7、Scikit-learn，TensorFlow 和 Keras开源库

虽然 **scikit-learn** 主要是一个机器学习库，但它也提供了一些异常检测算法，比如 **Isolation Forest** ，**LOF**和 **One-Class SVM**。**TensorFlow 和 Keras**：这两个深度学习框架可以用于构建和训练复杂的异常检测模型，例如**自编码器（Autoencoders）和变分自编码器（Variational Autoencoders）**。

### 8、ELKI开源库（基于java）

ELKI是一个开源的数据挖掘算法，它提供了一系列数据挖掘算法，包括OD算法。**它允许OD算法的轻松和公平的评估和基准测试。它是用Java实现的**。

### 9、Rapid Miner开源库（已下载，基于java）

该工具的扩展包含许多流行的无监督离群值检测算法，如LOF，COF [80]，LOCI [82]和Loop [81]

### 10、Massive Online Analysis (MOA) tool开源库(基于java)

MOA是一个开源框架，提供了一个数据流挖掘算法的集合。包括基于距离的孤立点检测算法COD、ACOD、Abstract C、MCOD以及一些评价工具。

### 11、TODS开源库（用于时间序列异常检测）

### 12、PyGOD开源库（用于图异常检测）

## 八、数据集开源库

### 1、UCI/Kaggle机器学习库（已下载部分数据集）

UCI存储库有数百个免费的数据集，许多OD方法使用存储库来评估算法的性能。**然而，这些数据集中的大多数都是为分类方法设计的**。**在离群值检测场景中，通常使用的方法是对数据集进行预处理。异常值表示次要类中的对象，其余的被认为是正常的**。

### 2、Outlier Detection Datasets (ODDS) 学习库（已下载，kaggle源好用）

与UCI存储库不同，**ODDS提供对仅适用于离群值检测过程的数据集集合的开放访问。这些数据集分为不同的类型，包括多维数据集，时间序列单变量和多变量数据集，以及时间序列图数据集**。

### 3、ELKI离群数据集（已下载，好用）

**ELKI有一系列用于离群值检测的数据集，也有许多用于OD方法评估的数据集**。这些数据集用于研究几种OD算法和参数的性能

### 4、Unsupervised Anomaly Detection Dataverse（UADD）数据集(已下载，没有属性名，适用于无监督异常检测算法)

**这些数据集用于通过与标准进行比较来评估无监督离群值检测算法**。它是从多个来源获得的，其中**大部分数据集来自监督机器学习数据集**

合成数据集通常是在定义的约束和条件下创建的。**与真实世界的数据集相比，合成数据集的复杂性和偏心性都较低，并且显示出OD算法性能的更好有效性**。对于离群值检测过程，由于所采用的大多数数据对于OD方法来说不是特定于目的的，因此监督分类数据的再利用已被广泛采用。在许多研究中，数据被原样处理，而不是被操纵。处理数据集的其他一些问题包括**如何处理数据的下采样，处理重复数据，将分类属性转换为数值类型，规范化以及处理缺失值**。在未来的工作中，**研究如何评估离群点检测方法的数据集以及需要考虑哪些关键属性将是至关重的**。

合成数据集通常是在定义的约束和条件下创建的。**与真实世界的数据集相比，合成数据集的复杂性和偏心性都较低，并且显示出OD算法性能的更好有效性**。处理数据集的其他一些问题包括**如何处理数据的下采样，处理重复数据，将分类属性转换为数值类型，规范化以及处理缺失值**。在未来的工作中，**研究如何评估离群点检测方法的数据集以及需要考虑哪些关键属性将是至关重要的**。

# 九、实验设计

## （一）ADBench中的实验设计

### 1、实验设计角度

#### 1）角度1：地面实况标签的可用性（监督）

动机：除了未标记的样本之外，**在真实世界的应用中，人们可以访问有限数量的标记的异常**，由领域专家或人工参与技术（如主动学习）识别出的一些异常[5，7，78，189]。

本文设计：我们首先对现有的无监督异常检测方法进行基准测试，然后根据[127，131，205]中的**设置评估具有不同监督级别的半监督和全监督方法，以提供公平的比较**。例如，**标记的异常γl = 10%意味着训练集中10%的异常是已知的，而其他样本保持未标记**。

思考：

> 1、设置基准时考虑无监督，半监督和监督的基准，设置异常比例

#### 2）角度2：异常值类型

动机：广泛的公共数据集可用于基准测试，但**它们通常由不同类型异常的混合物组成**，这使得理解AD算法在特定类型异常方面的优缺点具有挑战性[55，166]。为了更好地理解异常类型的影响，**我们在公共数据集的基础上，通过注入特定类型的异常来创建合成数据集，以分析AD算法的响应**。

本文设计：**在ADBench中，我们通过注入特定类型的异常，从基准数据集创建逼真的合成数据集**。一些现有的工作，**如PyOD [198]，通过假设它们的数据分布来生成完全合成的异常，这无法创建复杂的异常**。我们遵循并丰富了[166]中的方法，以**生成“真实的”合成数据**；**我们的方法支持更多类型的异常生成**。其核心思想是建立一个生成模型（例如，[166]、Sparx [191]和ADBench中使用的高斯混合模型GMM），并丢弃其原始异常，因为我们不知道它们的类型。然后，我们可以生成正常的样本和不同类型的异常的定义的基础上，通过调整生成模型。正常样本的生成在所有设置中都是相同的，如果没有注明的话，我们在下面提供了四种异常类型的生成过程（详细信息也请参见我们的代码库）。

> 1、**局部异常**：局部异常是指偏离其局部邻域的异常[22]。我们遵循GMM过程[118，166]来生成合成正态样本，然后**通过缩放参数α = 5来缩放协方差矩阵= α以生成局部异常**。
>
> 2、**全局异常**：全局异常与正态数据[68]有更大的不同，**由均匀分布生成**，其中边界被定义为输入特征的最小值和最大值，例如，第k个特征Xk和α = 1.1控制异常的异常度。
>
> 3、**依赖异常**：依赖异常是指不遵循正常数据遵循的依赖结构的样本[117]，即，依赖性异常的输入特征被假定为彼此独立。Vine Copula [1]方法用于对原始数据的依赖性结构进行建模，其中通过去除建模的依赖性将生成的异常的概率密度函数设置为完全独立（参见[117]）。我们使用核密度估计（KDE）[61]来估计特征的概率密度函数并生成正常样本。
>
> 4、**异常群**：也称为群异常[93]，表现出类似的特征[42，99]。我们将正常样本的平均特征向量缩放α = 5，即，µ = α

在ADBench中，我们分析了上述所有四种异常类型下的算法性能（§4.3）。

思考：

> 1、四类离群值下Rovas分别能检测出的异常比例？
>
> 2、这四类离群值中ugly outliers修复对分类器分类效果影响的不同？

#### 3）角度3：噪声和损坏数据的模型鲁棒性

动机：在现实世界的应用中，输入数据可能在一定程度上受到噪声和损坏[42，55，60，124]。然而，这一重要观点在现有的基准测试中尚未得到充分研究，我们尝试通过在三种噪声和损坏设置下评估AD算法来理解这一点。

> 1、**重复的异常**。在许多应用中，由于记录错误等原因，某些异常可能会在数据中重复多次[83]。重复异常的存在也被称为“异常屏蔽”[55、60、100]，这对许多AD算法[25]提出了挑战，例如，基于密度的KNN [11，144]。此外，异常频率的变化也会影响检测方法的行为[42]。**因此，我们通过将数据分为训练集和测试集来模拟此设置，然后在两个集中复制异常（特征和标签）多达6次，并观察AD算法如何变化**。
>
> 2、**不相关的特征**。表格数据可能包含由测量噪声或不一致的测量单位[28，55]引起的不相关特征，其中**这些噪声维度可能隐藏异常数据的特征，并因此使检测过程更加困难**[128，150]。**我们添加不相关特征达到总输入特征的50%**（即，通过从随机选择的第k个输入特征Xk的Unif min Xk，max Xk中生成均匀噪声特征，同时保持标签正确，对问题定义中的d）进行分类，并总结算法性能变化。
>
> 3、**注释错误**。虽然现有研究[131，152]探讨了未标记样本中的异常污染，但我们进一步讨论了标记污染对算法性能的更普遍影响，其中**考虑了正常样本和异常之间的标记翻转[122，202]（高达总标记的50%）。请注意，此设置不影响未受监督的方法，因为它们不使用任何标签**。**讨论标注错误是有意义的，因为手动标注或一些自动标注技术在被视为完美的同时总是有噪声**。

### 2、评估指标

1、我们通过两个广泛使用的指标来评价不同的AD方法：**AUCROC（受试者操作特征曲线下的面积）和AUCPR（精确度-回忆曲线下的面积）**。此外，**基于Wilcoxon-Holm方法的临界差异图（CD图）**[34，70]用于统计学比较AD方法组（p ≤ 0.05）。

2、模型训练和推理的时间

### 3、实验结果

#### 1）角度1：地面实况标签的可用性（监督）

1、没有一种无监督方法在统计上优于其他方法

2、当标签信息有限时，半监督方法优于监督方法

3、最新的网络架构（如Transformer）和新兴的集成方法在AD中具有竞争力的性能

#### 2）角度2：异常值类型

1、无监督算法的性能高度依赖于其假设和潜在异常类型的对齐。例如局部异常因子（LOF）在统计上优于局部异常的其他无监督方法，并且使用第k个（全局）最近邻的距离作为异常分数的KNN是全局异常的统计最佳检测器

2、关于异常类型的先验知识的“力量”可能超过部分标签的使用。

#### 3）角度3：噪声和损坏数据的模型鲁棒性

1、**无监督方法更容易受到重复异常的影响**。几乎所有无监督方法都受到重复异常的严重影响。其AUCROC随重复的增加而成比例地恶化。一种解释是，无监督方法通常假设基础数据是不平衡的，只有一小部分异常它们依赖于这个假设来检测异常。随着异常重复次数的增加，底层数据变得更加平衡，并且违反了异常的少数假设，从而导致无监督方法的退化。显然，在标签的帮助下，更平衡的数据集不会显着影响半监督和全监督方法的性能。

2、**由于特征选择，不相关的特征对监督方法的影响很小**。例如，像XGBoost这样的集成树可以过滤不相关的特征。此外，监督方法（和一些半监督方法，如DevNet）的鲁棒性能表明，标签信息可以有利于特征选择。

3、半监督和全监督方法都对轻微的注释错误表现出很大的弹性。

## （二）《Machine Learning for Anomaly Detection: A Systematic Review》中的实验设计

### 1、评估指标

1、按照流行程度从高到低排序：

> True Positive Rate(TPR)、False Positive Rate(FPR)、Accuracy(ACC)、Precision、F-score、AUC、True Negative Rate(TNR)、Error Rate(ER)、CPU Execution Time、Precision-Recall

## （三）《Evaluation of Machine Learning Algorithms for Anomaly Detection》中的实验设计

### 1、评估指标

使用7个评估指标来测量所选ML算法（分类器）的性能：

> 即准确度（accuracy）、精密度（precision）、真阳性率(True Positive Rate/TPR)（也称为召回率）、假阳性率（False Positive Rate/FPR）、F1-得分（F1-Score）、受试者工作特征曲线（ROC）和混淆矩阵（Confusion Matrix）。

## （四）《A Comparison of Outlier Detection Techniques for High-Dimensional Data》中的实验设计

### 1、实验指标

几个常用的测量来评估离群点检测方法的性能：

> 1、AUC：ROC（受试者工作特征）曲线是真阳性率与假阳性率的图表，**其中真（假）阳性率表示前m个潜在离群值中离群值（内值）的比例。ROC曲线可以通过称为ROC AUC的单个值来概括，ROC AUC定义为ROC曲线下面积（AUC）**。通常采用曲线下面积（AUC）对离群点检测算法的性能进行数值评价。
>
> 2、Precision (P)：精确度是指真实离群值的数量与离群值候选者的总数的比率
>
> 3、Average precision (AP)：Average precision不是仅对单个n值进行评估，而是指所有离群值对象的等级上的精度分数的平均值
>
> 4、Rank Power (RP)：秩功率是另一种流行的测量，以评估离群值检测方法的性能。很明显，如果离群值排名算法将真正的离群值排在离群值候选列表的顶部，则该算法将被视为更有效。
>
> 5、Correlation coefficient：相关系数，如斯皮尔曼的秩相似性或皮尔逊相关性，也用于评估文献中离群值检测的性能[36]。这种度量方法通过使用合并权重将更多的重点放在排名靠前的潜在离群值上。

## （五）《A comparative evaluation of outlier detection algorithms: Experiments and analyses》中的实验设计

### 1、实验指标

我们使用**受试者工作特征（ROC）曲线**（真阳性率对假阳性率）和**精确度-召回（PR）曲线**

## （六）《Human-in-the-loop Outlier Detection》中的实验设计

### 1、实验指标

我们评估了人类的努力和离群值检测的精确度（precision）/召回率（recall）。

### 2、实验评估

> 1、与无监督、主动学习、实体匹配检测算法对比
>
> 2、对本文技术的评估
>
> 3、对问题选择的评估
>
> 4、对人类错误的评估

## （七）《COPOD: Copula-Based Outlier Detection》中的实验设计

### 1、实验指标

本文评估了**ROC-AUC**指标和**AVERAGE PRECISION（AP）**指标

## （八）《outlier detection in high dimensional data》中的实验设计

### 1、实验设计角度

#### 1）角度1：不同的异常比例

**本文算法使用的关键参数是污染率，即数据中异常的假定比例。每种算法都根据给定的污染率将数据中的一些点标记为离群值**。由于在实践中，真正的污染率是未知的，我们测试的方法在一个范围内的污染值。

### 2、实验指标

在离群点检测中，假设异常实例的比例远远小于正常实例。因此，**我们使用精确度和召回率作为算法性能的衡量标准**。更准确地说，**我们通过F1分数将联合收割机的精确度和召回率合并为一个值**。

## （九）《ECOD:Unsupervised Outlier Detection Using Empirical Cumulative Distribution Functions》中的实验设计

### 1、实验设计角度

#### 1）角度1：ECOD的有效性

探索不同尾部概率的使用如何影响ECOD的性能。

#### 2）角度2：ECOD与基准算法在AUC和AP评测指标上的差异

#### 3）角度3：ECOD的运行效率和可扩展性

**运行效率偏向算法计算速度，可扩展性偏向于特征维度扩展对算法带来的影响**。

### 2、实验指标

在每个实验中，60%的数据用于训练，剩余的40%用于测试。**使用受试者工作特征下的面积（ROC）和平均精度（AP），通过取10个独立试验的平均评分来评价性能**。这两种度量在离群点挖掘研究中得到了广泛的应用[52]、[53]、[54]、[55]。**我们报告了原始比较结果和临界差异（CD）图，以显示统计学差异[56]，[57]**，其中通过Wilcoxon符号秩检验和霍尔姆's校正可视化了统计学比较。

### （十）《A robust SVM-based approach with feature selection and outliers detection for classification problems》中的实验设计

### 1、实验设计角度

#### 1）角度1：将本文提出算法与基准算法在实验指标上进行比较

#### 2）角度2：通过施加不同的异常值和扰动比例，验证本文算法和基准算法的性能变化

#### 3）角度3：时间消耗的对比

### 2、实验指标

为了比较分类器，我们使用了公认的分类性能指标：**准确度（ACC）和曲线下面积（AUC）**。

![image-20240919143526310](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240919143526310.png)

其中TP是真阳性，TN是真阴性，FP是假阳性，FN是假阴性。

![image-20240919143555887](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240919143555887.png)

**评测方法**：我们遵循十重交叉验证程序（TFCV）来获得这些指标。它包括将数据集随机划分为10个子集。在每次迭代中，这些子集中的九个构成训练集，剩余的分区是测试集。分类器的性能由独立的测试集进行评估。

## （十一）《Robust Variational Autoencoders for Outlier Detection and Repair of Mixed-Type Data》中的实验设计

### 1、实验设计角度

#### 1）角度1：向数据集中人为加入元组异常和单元格异常

对于每个数据集，随机选择一个单元格子集进行破坏，遵循两步过程：a）随机选择数据中的一定百分比的行进行破坏; b）对于这些选择的行中的每一行，随机破坏20%的特征，在每个选择行中破坏不同的特征集。

#### 2）角度2：向数据集中加入不同比例的异常

**对于连续特征，在标准化数据之前执行噪声处理**。探讨了四种不同的噪声分布：**高斯噪声、拉普拉斯噪声、对数正态噪声、两个高斯噪声分量的混合**

**对于分类特征，噪声过程基于潜在的边缘（离散）分布**。我们通过从tempered categorical distribution（在重要性抽样中也称为幂启发式）中采样（并排除当前的干净类别），将单元格值替换为脏值

### 2、实验指标

在OD实验中，我们使用**平均精度（AVPR）**，根据每种方法的离群值得分计算。**AVPR是精确率-召回率曲线下面积的度量，因此越高越好**。

在修复实验中，根据特征类型需要不同的度量。对**于连续特征，我们计算估计值与原始地面真值之间的标准化均方误差（SMSE）**，该标准化均方误差由地面真值的经验方差归一化

**对于分类特征，我们计算基础真值的独热表示与每个类别估计的概率之间的Brier得分**。