## 一、已有的异常检测器：

1、**无监督**异常检测器：GOAD、DeepSVDD、RCA、RePEN、SLAD、ICL、NeuTraL
2、**有监督**异常检测器：DevNet、DeepSAD、RoSAS、PReNeT

#### 可扩展的异常检测器：

#### （一）ADBench中共计30个异常检测器

1、**ADBench中的无监督检测器**：这些方法不需要训练标签，假设在测试数据集中，正常实例比异常实例更常见。

**浅层的**有主成分分析（**PCA**），单类SVM（**OCSVM**），局部离群因子（**LOF**），基于聚类的局部离群因子（**CBLOF**），基于连接性的离群值因子（**COF**），基于直方图的离群值检测（**HBOS**），K-最近邻（**KNN**），子空间异常值检测（**SOD**），基于Copula的离群值检测器（**COPOD**），基于经验累积分布的离群值检测（**ECOD**），轻量级在线异常检测器（**LODA**），隔离森林（**IForest**）。

**深度的**有深度支持向量数据描述（**DeepSVDD**），深度自动编码高斯混合模型（**DAGMM**）

2、**ADBench中的监督检测器**：正常和异常训练数据集都包含标记的实例，方法是建立一个预测模型的异常和正常的类，然后比较这两个模型。

Naive Bayes（**NB**），支持向量机（**SVM**），多层感知器（**MLP**），随机森林（**RF**），极端梯度提升（**XGBoost**），高效梯度提升决策树（**LightGBM**），Categorical Boosting (**CatBoost**) ，剩余网络（**ResNet**），特征令牌化器+ Transformer（**FT Transformer**）

3、**ADBench中的半监督检测器**：这里的训练仅包括普通类案例。因此，任何不能被归类为普通的东西都被标记为异常。由于它们不需要异常类标签，因此它们比监督方法更常见。

通过对抗性训练进行半监督异常检测（**GANomaly**），深度半监督异常检测（**DeepSAD已实现**），表示基于随机最近邻距离的方法（**REPEN已实现**），Deviation Networks（**DevNet已实现**），基于成对关系预测的有序回归网络（**PReNet已实现**），自动特征编码器（**FEAWAD**），极端梯度提升离群值检测（**XGBOD**）

#### （二）Machine Learning for Anomaly Detection中共计28个异常检测器

我们确定了28种ML技术，这些技术可分为六类：**分类、集成、优化、规则系统、聚类和回归**。这些ML技术以两种形式使用：**独立模型或混合模型**。表4显示了所收集的研究文章中ML技术的频率。**很多研究者过去常常将一种以上的ML技术结合起来。**。此外，**支持向量机是最常用的技术，无论是独立的还是在混合模型中**。

![image-20240903200952961](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903200952961.png)

#### （三）Deep Learning for Anomaly Detection中的异常检测器

**高维和/或非独立数据中的异常检测**：异常通常在低维空间中表现出明显的异常特征，而在高维空间中变得隐藏和不可察觉**。**在**由原始特征或新构造的特征的小子集所跨越的降低的低维空间中执行异常检测是直接的解决方案**，例如，**在基于子空间[70，77，84，123]和基于特征选择的方法[12，109，111]中**。深度异常检测由三个概念范式组成-**用于特征提取的深度学习，学习常态的特征表示和端到端异常得分学习**。

1、**用于特征提取的深度学习**：这类方法旨在利用深度学习从高维和/或非线性可分离的数据中提取低维特征表示，用于下游异常检测。与**异常检测中流行的降维方法（如主成分分析（PCA）[21，140，180]和随机投影[80，112，123]）相比**，深度学习技术在提取语义丰富的特征和非线性特征关系方面表现出更好的能力[14，49]。一条研究路线是**直接使用流行的预训练深度学习模型，如AlexNet [75]，VGG [143]和ResNet [58]来提取低维特征。**另一个研究方向是**明确地训练深度特征提取模型，而不是用于下游异常评分的预先训练的模型**。**优势是有现成的模型可用，缺点是特征提取和异常评分完全脱节，往往导致异常评分不理想**。

2、**学习正态性的特征表征**：**这类方法在某种程度上将特征学习与异常评分相结合，而不是像上一节那样完全解耦这两个模块**。这些方法通常分为两类：**通用特征学习和异常度量相关特征学习**。前者代表性技术有**自动编码器（AE）、生成性对抗网络（GAN）和自监督模型分类**，后者代表性技术有**基于距离的度量，基于单类分类的度量和基于聚类的措施**。

3、**端到端异常评分学习**：该研究线旨在**以端到端的方式学习标量异常分数。与依赖于异常度量的特征学习相比，这种方法中的异常评分不依赖于现有的异常度量;它具有直接学习异常评分的神经网络**。下面我们回顾这一类别中的四种主要方法：**排序模型、先验驱动模型、软最大似然模型和端到端一类分类模型**。

![image-20240905154608876](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154608876.png)

![image-20240905154706461](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154706461.png)

#### （四）Outlier Detection: Methods, Models, and Classification中的异常检测器

#### （1）低维离群点检测技术

1、**基于邻近度的方法**：基于邻近度的方法基于离群值与附近数据点的关系来识别离群值。**一种常见的情况是离群值位于稀疏区域，在给定距离内只有很少的数据点，或者最近的数据点非常远**。有两种主要的方法来定义邻域：**k最近邻（k-NN）和以数据点为中心的预定半径内的邻域**。LOF [23]是一种著名的方法，它首先引入了局部离群值的概念。基于连通性的离群因子（COF）[36]解决了LOF的缺点。Papadimitriou等人[37]基于局部密度的定义提出了局部相关积分（LOCI）。受影响的离群值（INFLO）[38]使用反向最近邻集（k-RNN）与k-NN相结合来计算离群值得分。[39]提出了局部离群值概率（Loop）。基于子采样，使用**最近邻包络（iNNE）[40]**的隔离创建隔离区域以确定离群值分数。**LeSiNN [16]**是另一种离群值检测方法，也可以使用子采样构建模型。**iNNE和LeSiNN都具有线性时间复杂度，此外，iNNE和LeSiNN都使用集成来确保离群检测器的稳定性**。

![image-20240905162832856](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905162832856.png)

2、**基于聚类的方法**：基于聚类的离群点检测算法通常分为两步：**首先用聚类算法对数据进行分组，然后根据聚类结果分析数据的偏离程度。不属于任何聚类的数据点被认为是离群值**。除了聚类成员（无论是否在聚类中），还有两个其他常用的聚类相关量来构建离群值。**第一个是到聚类中心的距离，假设正常数据点靠近聚类中心，而异常值远离它们。第二个是簇的基数，假设正常数据点的簇是密集和大的，而离群数据点的簇是稀疏和小的。与基于最近邻的离群点检测方法相比，基于聚类的离群点检测方法的一个主要优点是检测效率高**。Jiang等人[44]提出了一种离群点检测方法，该方法基于改进的k均值聚类和从聚类中心构建的最小生成树。基于聚类的局部离群值因子（CBLOF）[46]是一种基于聚类的离群值检测方法，通过定量测量区分小聚类和大聚类。在Amer等人的后期工作中。[47]，证明了简单地去除CBLOF的簇基数可以产生更好的结果。CBLOF和LDCOF都具有独立于框架的合并的聚类算法。但正如[47]所建议的，具有固定数量的聚类（如k-means）的算法在性能上是有利的，并且由于潜在的非球形分布，建议高估聚类数量。Du等人。[17]设计了一种基于密度峰值聚类算法的局部离群值检测方法[48]，这是一种简单但有效的基于密度的方法，可以检测任意形状的聚类。

![image-20240905164918032](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905164918032.png)

3、**基于预测的方法**：**本节是各种投影技术的方法**（例如，随机投影[50]、LSH [29]等）为了**将原始数据转换到具有降低的维度或复杂度的新空间中，同时仍然保留邻近信息**。然后可以在投影空间中执行离群点检测，从而大大改善了执行时间。值得注意的是，**子空间技术也是一种直接投影**。**它们已被广泛用于解决高维数据的挑战**。投影索引最近邻（PINN）[51]基于随机投影方案来降低数据维度，随机投影优于其他降维技术（如PCA [57]）的优点是其效率。局部敏感离群值检测（LSOD）[52]利用局部敏感哈希（LSH）[29，53]来创建离群值的初始排名，LSOD集成了许多基于距离的离群值检测的修剪策略，包括PPSN [41]，ANNS [41]和PPSO [61]。Schubert等人提出了另一种基于投影的离群值检测算法[54]。此外，他们提供了一个分布式框架来扩展算法。Loda [55]采用稀疏随机投影线，Loda遵循了集合的精神，并演示了如何将多个弱离群值检测器组合在一起，从而产生非常好的结果**

4、**基于树的方法**：**从广义上讲，树模型的构建也可以被视为一种投影，其中原始数据点被映射到特定的树节点，并且这些树节点包含关于原始数据的邻近信息**。**柳塔尔。[28]开发了Isolation Forest，它是一种无监督的树集成**。**Hariri等人[56]提出了扩展隔离森林来解决隔离森林的缺点**。

![image-20240905165736586](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905165736586.png)

#### （2）高维离群点检测技术

高维数据实现效率的困难主要归因于两个原因。首先，**由于增加的维度，相似性搜索（诸如k-NN搜索）在计算成本方面变得更昂贵**。其次，**一些用于加速离群值检测的技术，如采样[66，67]，修剪[68]，排名策略[38，69]和有效的索引结构（R树[58]，X树[59]等），不适用**。**为了提高高维数据离群点检测的效率，Ghoting等人。[73]提出了递归分箱和重投影（RBRP）**。第3节中提到的**投影索引最近邻（PINN）[51]算法也旨在提高高维离群值检测的效率**。**[74]引入了一种基于角度的离群值检测方法（ABOD），以解决基于欧几里得距离的算法在面对高维数据集时遇到的质量恶化的问题**。为了降低时间复杂度，引入了两个近似变体：**FastABOD和LB-ABOD**。FastABOD将离群值得分计算的数据点对的选择限制在数据点的k-NN。**LB-ABOD是ABOD的一个下界近似，其目的是有效地获得具有最高分数的顶级离群值**。许多作品探索**子空间的解决方案**，**Kriegel等人。[75]**开发了一种离群值检测模式。**[76]提出了一种测量子空间对比度的方法，并相应地提出了一种称为高对比度子空间（HiCS）的子空间搜索方法**。**Sathe等人。[77]提出了RS-Hash，这是一种基于随机散列的非常有效和准确的子空间离群值检测方法****。除了上述方法，近年来其他有趣的工作包括：**HighDOD [80]**，使用动态子空间搜索方法和基于样本的学习过程; LODES [81]，依赖于一种新的基于局部密度的谱嵌入来识别非线性子空间中的离群值; RAMODO [82]使用表示学习来降低维度，并将其与基于随机距离的方法相结合[16]。

![image-20240905173128567](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905173128567.png)

#### （3）分布式异常检测技术

**Bhaduri等人。[110]开发了DOoR，这是ORCA方法[68]的分布式解决方案。Angiulli等人。[111]将SolvingSet算法[112]扩展到分布式环境。Bai等人[115]提出了LOF的分布式解决方案。分布式Top-N LOF（DTOLF）[114]为参考文献[116]中提出的Top-N LOF方法提供了分布式解决方案。Tsou等人。[12]提出了一种分布式无监督异常检测框架**。

![image-20240905175602124](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905175602124.png)

#### （4）基于深度学习的异常检测策略

为了解决当训练数据包含离群值时自动编码器对过拟合的敏感性，**Chen等人。[121]提出了一种基于集合的离群值检测方法**。**鲁棒深度自动编码器（RDA）[18]**通过将输入数据分为两个矩阵来解决受污染的训练数据问题，一个包含离群值，另一个由自动编码器有效重建。**Schlegl等人[122]设计了AnoGAN**，旨在检测图像数据中的异常作为疾病标记**。另一种基于GAN的异常检测方法是逆向学习异常检测（ALAD）[123]**。**[82]提出了一种基于深度神经网络的框架，称为RAMODO**。

![image-20240909184106509](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909184106509.png)

#### （5）人在环的异常检测技术

**一种典型方法是通过主动学习**[135]，基于此，**一些数据实例通过一些查询策略被领域专家标记**。**在Görnitz等人的工作中。[136]，异常检测被认为是一个名为支持向量数据描述（SVDD）的优化问题[137]**。**Das等人。[27]提出了一种半监督方法，该方法将专家反馈迭代地结合到称为Loda [55]的集成异常检测方法的模型中**。**Vercruyssen等人[11]描述了一种半监督异常检测方法**。**Siddiqui等人。[139]提出了一种用于异常检测的通用算法，旨在通过结合专家反馈将异常分数与应用程序特定的兴趣度对齐**。

![image-20240909184210867](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909184210867.png)

#### （五）Evaluation of Machine Learning Algorithms中的异常检测器

1、**经典ML算法**：**Logistic回归、朴素贝叶斯、K邻近（KNN）、决策树（Decision Tree）、自适应增强（Adaptive Boosting）和随机森林（RF）**

2、**深度学习算法**：**卷积神经网络（CNN）、卷积神经网络和长短时记忆（CNN-LSTM）、长短时记忆（LSTM）、门控递归单元（Gated Recurrent Units，GRU）、简单递归神经网络（Simple Recurrent Neural Network，RNN）和深度神经网络（Deep Neural Network，DNN）**

#### （六）A comprehensive survey of anomaly detection 中的异常检测器

1、**解决高维问题的策略**：已经提出了许多降维方法，例如**PCA，MDS，Karhunen-Loeve变换，局部线性嵌入，拉普拉斯特征映射和扩散映射**，以实现降维[51，70-74]**。**这些数据表示的内在维度小于可用的相关维度。已经提出了许多技术来测量内在维度[75-80]。**Wang等人。[86]提出了一种PCA以及可分离压缩感知算法**。Lazervic和Kumar [92]提出了一种模型，该模型使用称为“特征装袋”的评分系统来检测异常。**Kriegel等人。[23]采用了一种技术来选择信息或相关维度**。**[93]提出了一种名为“OUTERS”的子空间方法**。Zhang等人。**[94]提出了一种基于角度的子空间离群点检测方法**。**Thudumu等人。[41]提出了一种检测离群值的方法**。Koufakou和Georgiopoulos [61]提出的另一种算法称为混合属性数据集的离群值检测（ODMAD）。混合属性由Ye等人提出。[95]，他们提出了一种离群点检测算法，通过计算异常子空间结合信息熵来检测高维混合属性数据集中的异常。

2、**高维大数据中的工具（主要是一些并行框架）**

#### （七）Outlier Detection: Methods, Models, and Classification中的异常检测器

10种流行的离群点检测算法包括**kNN、kNNW、ODIN、LOF、Loop、COP、SOD、FastABOD、HiCS和高斯均匀混合模型（GMM）**。

![image-20240906183523232](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183523232.png)

#### （八）A comparative evaluation of outlier detection algorithms中的异常检测器

1、**概率方法**：概率算法通过推断模型参数θ来估计数据集X的概率密度函数。具有最小似然P（X|θ）的数据点被识别为离群值。**在[3]中，Blei等人描述了Dirichlet过程混合模型（DPMM）**。该算法在文献[8]的KDD 99数据集上进行了入侵检测，其性能优于SVM和KNN算法。**Kim等人在[13]中展示了这个问题，其中作者描述了一种鲁棒核密度估计（RKDE）算法**。**概率主成分分析（PPCA）[29]**是一种潜在变量模型，用于估计数据的主成分。**Quinn等人开发的最小二乘异常检测（LSA）[25]**将多类概率分类器扩展到一类问题。

2、**基于邻居的方法**：**在[4]中描述的局部离群因子（LOF）优于基于角度的离群值检测[16]和单类SVM [26]**。**基于角度的离群值检测（ABOD）[16]**使用在每个输入向量处测量的角度的半径和方差而不是距离来识别离群值。**子空间离群值检测（SOD）[15]**算法为每个点p找到p和它的k个最近邻居之间共享的m个邻居的集合。

3、**基于域的方法**：**落在定界边界之外的任何数据点都被标记为离群值**。**单类SVM [26]是支持向量机（svm）算法在单类问题中的应用**，属于这类算法

4、**隔离方法**：**隔离森林的概念是由Liu在[17]中提出的，它使用随机森林来计算每个数据点的隔离分数**。**作者指出，他的算法提供了线性时间复杂度，并在现实世界的数据集上证明了离群点检测性能明显优于lof**。

本实验中使用的大多数实现都是公开可用的。大多数方法具有灵活的参数，并且在没有大量调优的情况下执行得非常好**。**Python的Matlab引擎API和rpy2库允许我们从Python调用Matlab和R代码**。**iforest是一个很好的方法，有效地识别离群值，同时显示了良好的可扩展性。ocsvm在这个基准中是一个很好的候选者，但是它也不适合大型数据集**。**SOD表现出良好的离群值检测性能，并以较差的可扩展性为代价有效地处理高维数据集**。**指数族表示的dpmm显示是非常耗时的，而没有实质性地提高检测离群值的高斯为基础的方法，如dpgmm**。**LOF、ABOD、GWR、KL和LSA达到最低性能，而前三种方法也显示出较差的可扩展性。

#### （九）On the Evaluation of Outlier Detection and One-Class Classification Methods中的异常检测器

我们比较和评估了11种算法：**ABOD，Auto-Encoder，Gaussian Density，GLOSH，kNNglobal，kNNlocal，LOCI，LOF，Linear Programming，Parzen Windows和SVDD**。对于大多数比较算法，我们使用来自http://prlab.tudelft.nl/users/david-tax/ [25]的代码，除了LOF，LOCI，kNNlocal和GLOSH。**在LOF和LOCI的情况下，修改了它们的实现，以确保待分类的新观测不会影响内点类的预计算模型**。由于**KNNlocal在该存储库中不可用**，因此我们使用自己的算法实现。**GLOSH是根据http://lapad-web.icmc.usp.br/上提供的HDBSCAN* 的实施情况进行调整的**。

**SVDD和kNNglobal是单类分类的首选**，**而我们不推荐kNNlocal**。**此外，我们无法确认[13]中报告的LOF的最佳性能，而只能确认SVDD的最佳性能**。

#### （十）Supervised outlier detection for classification and regression的异常检测器

我们选择并比较了在文献中具有突出作用的**九种不同的离群值检测方法**，使用了**scikit-learn [10]或PyOD [11]中的实现**，这两个库是众所周知的Python库。们将在这里考虑九个代表性的OD模型，即**最小协方差决定性估计[21，22]**，**局部离群因子[23]**，**基于连通性的离群因子[24]**，**k-最近邻离群估计[25，26]**，**隔离森林[27，28]**，**一类支持向量机[29]**，**主成分分析（PCA）OD [30]，[31]**、**子空间异常值检测[32]**和**基于直方图的异常值检测[33]**。**一个非常好的参考是PyOD库[11]，我们使用了所有上述方法的实现，除了最小协方差行列式和隔离森林，我们使用它们的scikit-learn [10]实现**。本工作中应用的OD模型是**MCD，IF，KNN，LOF，OCS，PCA，COF，HBOS和SOD**，**在MCD和IF的情况下使用它们的scikit-learn实现，在其他情况下使用它们的PyOD版本**。**我们可以得出结论，一般来说，MCD和IF模型通常是一个很好的选择，而PCA，HBOS和LOF也应该考虑计算时间是一个加权因素**。

#### （十一）Human-in-the-loop Outlier Detection中的异常检测器

本文将HOD与众所周知的无监督离群值检测方法进行了比较，包括**KNN [40]、LOF [5]、聚类方法[23]和Ensemble方法[3]。以及基于主动学习的方法AI 2 [42]和AAD [14]**。还有基于实体匹配的方法**CrowdER和Magellan**。

主动学习方法：给定人力成本预算，主动学习方法从数据集中选择对象，要求人类标记这些对象并迭代地训练分类器，直到预算用完。

（1）**AI2 [42]**：每次AI2选择X个对象供用户标记，**其中X/2个对象来自非监督方法，其他X/2个对象由监督方法（随机森林）提供**。在X个对象被标记后，它重新训练监督模型并选择另一个X个对象，直到预算用完。最后，利用该模型对剩余的未标记数据进行预测。

（2）**AAD [14]**：首先，AAD提取每个对象的特征，并使用监督方法来训练分类器。接下来，基于建模结果，AAD选择一个最有可能成为人类标记的离群值的对象。然后，它迭代地重新训练模型，以调整每个特征的权重，并选择新的离群候选。

#### 二、已有的数据集：

dry bean、obesity、wine quality、apple quality、balita、iris、wine、adult（来自UCI/Kaggle数据集）

#### 可扩展的数据集如下：

1、**合成数据集**：可根据**ADBench中的合成方法合成“真实”的合成数据，支持多种类型的异常生成**：**局部异常、全局异常、依赖异常和异常群**。ADBench中57个真实基准数据集（**已补充**）。

2、Generalized Out-of-Distribution中的离群值划分：**要在MNIST上构建离群值检测基准，应选择一个类，以便将属于该类的所有样本视为内点。一小部分来自其他类别的样本被引入作为待检测的离群值。**Generalized Out-of-Distribution中的12个真实数据集，在第5节的当前研究中分析的数据集可以在OpenOOD存储库https://github.com/Jingkang50/OpenOOD中找到（**图像数据集**×）。

3、Machine Learning for Anomaly Detection中的异常分类：**点异常，上下文异常和集体异常**。Machine Learning for Anomaly Detection中22个不同的数据集（**数据集不具有代表性，否掉了**×）。

4、Deep Learning for Anomaly Detection中的异常分类：**点异常，上下文异常和集体异常**。**异常检测发展的一个主要障碍是缺乏具有真实的异常的真实世界数据集**。我们在表3中总结了**21个公开可用的具有真实的异常的真实世界数据集的集合**，以促进对这些数据集的性能评估。这里**只包括大规模和/或高维复杂数据集**。为深度异常检测提供具有挑战性的测试平台。此外，**在https://git.io/JTs93上提供了广泛使用的异常检测数据集**（包括表3中的一些预处理数据集）的持续更新集合（**已补充**）。

![image-20240905154951383](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905154951383.png)

5、Outlier Detection: Methods, Models, and Classification中的异常值分类：**（1）点离群值和（2）集体离群值[14]，点异常值可进一步分为（1）局部异常值和（2）全局异常值**。本文认为**离群值在其特征方面不同于正常值，与正常实例相比，离群值在数据集中是罕见的**。**anomalies表明了一种不同的潜在生成机制。相比之下，Outliers往往强调统计稀有性和偏差，而它们是否由不同的机制产生并没有直接说明**。在统计学和机器学习的某些情况下，**outliers是指那些使模型更难拟合的数据实例**。**在监督学习中，anomalies是更好的术语，因为有可靠的指导来建模异常的生成机制**（**无数据集补充**）。

6、Evaluation of Machine Learning Algorithms在**CICIDS-2017，UNSW-NB 15和工业控制系统（ICS）网络攻击数据集**上开展实验（**无数据集补充**）。

7、A Comparison of Outlier Detection Techniques的数据集来源为**人工数据集和真实数据集**。**Wang等人[37]提供了一些在不同情况下具有异常值的合成数据集**。真实世界的数据集通常来自三个来源，如下所示：

> 1、**UCI机器学习库**。这些数据集中的大多数已被提议用于评估分类方法。**对于离群点检测任务，常用的策略是通过将小类中的对象作为离群点，其余的作为正常对象来预处理数据集**（**已补充**）。
>
> 2、**ELKI数据集**。ELKI是一个积极开发和维护的“用于开发索引结构支持的KDD应用程序的环境”。最近的版本特别致力于异常值检测。**该平台不仅提供了离群点检测算法，还提供了用于离群点检测评估的多个数据集（已补充）**。

**在分类中主要使用的数据集需要进行预处理以用于离群值检测任务**。在预处理期间，可以考虑两种情况：

> 1、**对于语义上有意义的离群数据集，与稀有对象相关联的类被视为离群值，其余的被视为正常数据**。
>
> 2、**对于其他数据集，从数据集中随机选择离群值类。特别地，对于只有两个类的数据集，具有次要对象的类通常被视为离群点**。

**我们在9个数据集上对10种流行的离群点检测算法进行了实验比较**。离群点检测算法包括**kNN、kNNW、ODIN、LOF、Loop、COP、SOD、FastABOD、HiCS和高斯均匀混合模型（GMM）**。**其中“N”和“O”分别指所有对象和离群值的数量**。

![image-20240906183347756](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906183347756.png)

8、A comparative evaluation of outlier detection algorithms使用15个数据集，范围从723到20，000个样本，包含6到107个特征。在这些数据集中，有12个在UCI [1]或OpenML [30]存储库中公开，而剩下的3个数据集是包含Amadeus公司生产数据的新型专有数据集。

![image-20240906222707675](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240906222707675.png)

9、On the Evaluation of Outlier Detection中我们使用来自**UCI机器学习库[17]的31个真实世界数据集作为单类分类的预处理**，并在http://prlab.tudelft.nl/users/david-tax/上提供：**Abalone, Arrhythmia, Balance-scale, Ballbearing, Biomed, Breast, Cancer, Colon, Delft1x3, Delft2x2, Delft3x2, Delft5x1, Delft5x3, Diabetes, Ecoli, Glass, Heart, Hepatitis, Housing, Imports, Ionosphere, Iris, Liver, Satellite, Sonar, Spectf, Survival, Vehicle, Vowels, Waveform and Wine**

10、Supervised outlier detection for classification and regression使用**八个回归数据集和八个分类数据集**。 更准确地说，将考虑以下数据集：用于回归的 abalone、boston、cal-housing、concrete、cpusmall、mg、winequality_red 和 winequality_white，**以及用于分类的 australian、breast_cancer、diabetes、digits、dna、german、satimage 和 snippet**。

## 三、现有的评价指标：

**accuracy**（分类准确度）、**F1** 分数、**ROC-AUC** 分数、**precision**（分类精确度）、**recall**（召回率）、**Confusion Matrix**（混淆矩阵）、**Precision-Recall Curve** （PR曲线）

Matthews Correlation Coefficient (**MCC**)、**F-beta** Score、**Area Under Precision-Recall Curve** (**PR AUC**)、**Balanced Accuracy**、**G-Mean**、Average Precision (**AP**)

1、ADBench基准使用了**ROC-AUC** 分数、**Area Under Precision-Recall Curve** (**PR AUC**)、**基于Wilcoxon-Holm方法的临界差异图（CD图）**[34，70]用于统计学比较AD方法组（p ≤ 0.05）

2、Generalized Out-of-Distribution中使用了**F-scores，AUROC和AUPR**指标。此外，本工作认为离群检测器的评估还可以**通过其支持的主要任务的性能来评估**。例如，**如果使用离群值检测器来净化具有噪声标签的数据集，则在经净化的数据集上训练的分类器的性能可以指示离群值检测器的质量**。

3、Machine Learning for Anomaly Detection中提到使用最多的性能指标是**真阳性率（即召回率）（TPR）**，它测量被正确分类的异常。此外，116篇论文使用**假阳性率（FPR）**作为性能指标，该指标测量被错误分类的异常。**ROC 曲线** 是以假阳性率（FPR）为横轴，真阳性率（TPR）为纵轴绘制的曲线，**ROC曲线是用于有效评估入侵检测系统性能的最强指标之一**。此外，**准确度（Acc），精度和F-分数经常被研究人员作为性能指标**，Acc是正确分类的异常百分比。**AUC测量整个ROC曲线下的整个二维面积**。精确度通常与F分数和召回率相关，它测量被正确分类为攻击的异常的比率。除了性能指标之外，许多论文还提出了**计算性能指标，例如CPU利用率、执行时间、训练时间、测试时间和计算时间**。

4、Evaluation of Machine Learning Algorithms选用了**准确度、精确度、召回率、F1评分和受试者工作特征（ROC）曲线**这些评价指标。在12个参与对比的算法上**随机森林（RF）算法**达到最佳性能。

5、A Comparison of Outlier Detection Techniques的评价指标为**AUC、Precision（P）、Average precision (AP)、Rank Power (RP)、相关系数**。

6、A comparative evaluation of outlier detection algorithms选择了**ROC曲线下面积**和**精确度-召回率（PR）曲线**。为了全面概述这些方法，我们还对每种方法的**训练时间，预测时间，内存使用和鲁棒性**进行了基准测试。

7、Progress in Outlier Detection Techniques: A Survey中选择了**Precision**、**R-precision**、**Average precision**、**AUC**、**Correlation coefficient**和**Rank power (RP)**这些指标

#### 可扩展的指标如下：

**1、Matthews Correlation Coefficient (MCC): 这个指标综合考虑了真阳性、真阴性、假阳性和假阴性。MCC 的值在 [-1, 1] 范围内，1 表示完美分类，0 表示随机分类，-1 表示完全错误的分类。**
**2、Balanced Accuracy: 这是对分类器准确度的调整，尤其在类别不平衡时。它是各类别召回率的平均值。**
3、Kappa Statistic (Cohen’s Kappa): 这个指标用来测量分类器的预测结果与随机预测结果之间的一致性。它考虑了偶然的一致性。
**4、G-Mean: 这个指标是各类别召回率的几何平均值。它在处理不平衡数据集时非常有用。**
5、Log-Loss (Logarithmic Loss): 这个指标用来评估分类器的概率预测质量，尤其是在概率预测时比准确度更有用。它计算的是预测概率与实际标签之间的差距。
6、Brier Score: 类似于 Log-Loss，用于评估概率预测的准确性，尤其适用于概率模型
7、Youden's J Statistic: 这个指标用于评估分类器的诊断能力。计算公式是：J=Sensitivity+Specificity−1J=Sensitivity+Specificity−1。
**8、F-beta Score: F1 分数是 F-beta 分数的特例，其中 beta=1。F-beta 分数通过调整 beta 参数来平衡精确度和召回率的权重。beta > 1 更关注召回率，beta < 1 更关注精确度。**
**9、Average Precision (AP): 在不同的阈值下计算精确度和召回率的平均值，通常用于评估 PR 曲线下的性能。**
10、Hamming Loss: 计算每个样本的标签预测错误的比例，适用于多标签分类问题。
11、Top-K Accuracy: 在多类别分类问题中，这个指标检查模型是否能将正确类别的概率排在前 K 名中。
12、Cumulative Gain and Lift Charts: 这些图表用于评估模型在不同层级的表现，特别是对于营销和广告中的分类问题。
**13、Area Under Precision-Recall Curve (PR AUC): 计算 PR 曲线下的面积，可以用来衡量模型在处理不平衡数据集时的表现。**
14、Kullback-Leibler Divergence (KL Divergence): 用来衡量模型预测分布与实际分布之间的差异，适用于评估概率预测。

## 四、现有的实验设计角度：

### 4.1 AD算法如何在不同的监督级别下执行

1、**在10%的标记异常下，大多数有标记的算法优于最佳无监督算法CBLOF**（用虚线表示）。

2、**没有一种无监督方法在统计上优于其他方法**。一些基于DL的无监督方法，如DeepSVDD和DAGMM，比浅层方法差得惊人，**没有标签信息的指导，基于DL的无监督算法更难训练**（由于更多的超参数）

3、**当标签信息有限时，半监督方法优于监督方法**。对于大多数半监督方法，仅1%的标记异常就足以超过最佳无监督方法（如图4 b中的虚线所示），而大多数监督方法需要10%的标记异常才能实现。

4、**最新的网络架构，如Transformer和新兴的集成方法，在AD中产生有竞争力的性能**。图4b示出了FTTransformer和集成方法（**如XGB（oost）和CatB（oost）**）在所有标签通知算法中提供令人满意的检测性能，即使这些方法不是专门针对异常检测任务提出的。**这可能归功于它们通过聚合处理不平衡AD数据集的能力**。

5、**HBOS、COPOD、ECOD和NB是最快的**，因为它们独立处理每个功能。**XGBOD、ResNet和FTTransformer的计算量很大**。值得注意的是，**算法选择和超参数优化在无监督AD中很重要，但有限的工作[13，109，194，199，200]已经研究了它们**。我们也可以考虑自我监督[140，158，161，179]和迁移学习[33]来改善表格式AD。

### 4.2 AD算法如何响应不同类型的异常

1、**无监督算法的性能高度依赖于其假设和潜在异常类型的对齐**。**局部异常因子（LOF）在统计上优于局部异常的其他无监督方法**（图5a），并且**使用第k个（全局）最近邻的距离作为异常分数的KNN是全局异常的统计最佳检测器**（图5 b）。同样，没有算法在所有类型的异常上都表现良好; LOF在局部异常上实现了最佳AUCROC（图5a），在依赖性异常上实现了第二好的AUCROC排名（图5c），但在聚类异常上表现不佳（图5d）。

2、**关于异常类型的先验知识的“力量”可能超过部分标签的使用**。对于局部、全局和依赖异常，大多数标签通知方法的性能都比每种类型的最佳无监督方法（对应于LOF、KNN和KNN）差。我们认为，**部分标记的异常不能很好地捕捉特定类型的异常的所有特征，学习这样的决策边界是具有挑战性的**。

3、**可以利用异常类型作为有价值的先验知识**。在理想情况下，可以**通过动态模型选择和组合等框架，基于异常类型的组成来组合联合收割机多个AD算法[197]**。另一个有趣的方向是**使用合成生成的异常来训练离线AD模型，然后将其用于具有可能相似异常类型的真实世界数据集的在线预测**。

### 4.3 AD算法对噪声和损坏数据的鲁棒性如何

**1、无监督方法更容易受到重复异常的影响**。在许多应用中，由于记录错误等原因，某些异常可能会在数据中重复多次[83]。当异常重复6次时，无监督方法的中位数AUCROC为− 16.43%，而半监督方法为−0.05%（图7b），监督方法为0.13%。一种解释是，**无监督方法通常假设基础数据是不平衡的，只有一小部分异常它们依赖于这个假设来检测异常**。

**2、由于特征选择，不相关的特征对监督方法的影响很小**。**表格数据可能包含由测量噪声或不一致的测量单位[28，55]引起的不相关特征，其中这些噪声维度可能隐藏异常数据的特征，并因此使检测过程更加困难[128，150]**。例如，**像XGBoost这样的集成树可以过滤不相关的特征**。此外，监督方法（和一些半监督方法，如DevNet）的鲁棒性能表明，**标签信息可以有利于特征选择**。

**3、半监督和全监督方法都对轻微的注释错误表现出很大的弹性**。虽然现有研究[131，152]探讨了未标记样本中的异常污染，但我们进一步讨论了**标记污染对算法性能的更普遍影响**，**其中考虑了正常样本和异常之间的标记翻转[122，202]（高达总标记的50%）**。此设置不影响未受监督的方法，因为它们不使用任何标签。

4、我们的研究结果表明，**有一个强大的无监督AD算法的改进空间**。**一个直接的补救措施是采用无监督特征选择[30，125，126]来对抗不相关的特征**。此外，标签信息可以作为模型训练的有效指导，以对抗数据噪声，并且它有助于半监督和全监督方法更加鲁棒。**鉴于获取完整标签的困难，我们建议使用半监督方法作为设计更强大的AD算法的骨干**。

## 五、现有的特征选择技术

**特征选择/提取**已经在文献中被广泛发现，并且它是朝着丢弃不相关数据的重要举措，这**有助于增强和提高所建议的模型的精度和计算效率**。图4展示了正在应用的21种不同的特征选择/提取技术。此外，**我们注意到PCA和CFS是异常检测中最常用的特征选择技术**。

![image-20240903201010569](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240903201010569.png)

## 六、附加材料

![image-20240909164409177](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909164409177.png)

**假阳性率（FPR）** 的公式如下：

![image-20240909164437535](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909164437535.png)

**真阳性率（TPR）** 的公式如下：

![image-20240909164538170](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240909164538170.png)

1、Evaluation of Machine Learning Algorithms使用七个评估矩阵来衡量所选ML算法的性能，即**准确度**，**精确度**，**真阳性率**（TPR），也称为召回率，**假阳性率**（FPR），**F1分数**，**受试者操作特征（ROC）曲线**和**混淆矩阵**。

![image-20240905194109674](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20240905194109674.png)

## 七、异常检测器开源库

### 1、ADBench开源库（已下载）

包含开源数据集，合成数据生成器，和开源异常检测算法

### 2、PYOD开源库（已下载）

包含多种开源异常检测算法，PyOD用于检测多变量数据中的离群值。它是一个可扩展的Python工具，已被用于许多研究和商业项目，包括新的深度学习和离群集合模型[60]，[62]，[233]。

### 3、NAB开源库（×主要为时间序列）

包含多种开源时间序列真实数据集和新颖的评分机制

### 4、徐宏祚的库（已有）

包含多种开源异常检测算法，合成数据生成器

### 5、Alibi-detect开源库（已下载）

包含了多种针对表格，时间序列和漂移检测的异常检测算法

### 6、PyCaret开源库（已下载）

这是一个自动化机器学习库，其中包含异常检测模块。它提供了一个简单的接口来处理各种异常检测任务。

### 7、Scikit-learn，TensorFlow 和 Keras开源库

虽然 **scikit-learn** 主要是一个机器学习库，但它也提供了一些异常检测算法，比如 **Isolation Forest** ，**LOF**和 **One-Class SVM**。**TensorFlow 和 Keras**：这两个深度学习框架可以用于构建和训练复杂的异常检测模型，例如**自编码器（Autoencoders）和变分自编码器（Variational Autoencoders）**。

### 8、ELKI开源库（基于java）

ELKI是一个开源的数据挖掘算法，它提供了一系列数据挖掘算法，包括OD算法。**它允许OD算法的轻松和公平的评估和基准测试。它是用Java实现的**。

### 9、Rapid Miner开源库（已下载）

该工具的扩展包含许多流行的无监督离群值检测算法，如LOF，COF [80]，LOCI [82]和Loop [81]

### 10、Massive Online Analysis (MOA) tool开源库(基于java)

MOA是一个开源框架，提供了一个数据流挖掘算法的集合。包括基于距离的孤立点检测算法COD、ACOD、Abstract C、MCOD以及一些评价工具。

## 八、数据集开源库

### 1、UCI/Kaggle机器学习库（已下载部分数据集）

UCI存储库有数百个免费的数据集，许多OD方法使用存储库来评估算法的性能。**然而，这些数据集中的大多数都是为分类方法设计的**。**在离群值检测场景中，通常使用的方法是对数据集进行预处理。异常值表示次要类中的对象，其余的被认为是正常的**。

### 2、Outlier Detection Datasets (ODDS) 学习库（已下载，kaggle源好用）

与UCI存储库不同，**ODDS提供对仅适用于离群值检测过程的数据集集合的开放访问。这些数据集分为不同的类型，包括多维数据集，时间序列单变量和多变量数据集，以及时间序列图数据集**。

### 3、ELKI离群数据集（已下载，好用）

**ELKI有一系列用于离群值检测的数据集，也有许多用于OD方法评估的数据集**。这些数据集用于研究几种OD算法和参数的性能

### 4、Unsupervised Anomaly Detection Dataverse（UADD）数据集(已下载，没有属性名，适用于无监督异常检测算法)

**这些数据集用于通过与标准进行比较来评估无监督离群值检测算法**。它是从多个来源获得的，其中**大部分数据集来自监督机器学习数据集**

合成数据集通常是在定义的约束和条件下创建的。**与真实世界的数据集相比，合成数据集的复杂性和偏心性都较低，并且显示出OD算法性能的更好有效性**。对于离群值检测过程，由于所采用的大多数数据对于OD方法来说不是特定于目的的，因此监督分类数据的再利用已被广泛采用。在许多研究中，数据被原样处理，而不是被操纵。处理数据集的其他一些问题包括**如何处理数据的下采样，处理重复数据，将分类属性转换为数值类型，规范化以及处理缺失值**。在未来的工作中，**研究如何评估离群点检测方法的数据集以及需要考虑哪些关键属性将是至关重的**。