"""
ä¸‰ç§èšåˆå‡½æ•°ç¤ºä¾‹
"""
from sklearn.datasets import make_classification
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

# æ„é€ æ•°æ®é›†
X, y = make_classification(n_samples=500, n_features=20, random_state=42)
columns = [f'feature{i+1}' for i in range(20)]  # åˆ›å»ºç‰¹å¾åˆ—åç§°
data = {col: X[:, i] for i, col in enumerate(columns)}
data['label'] = y  # æ·»åŠ æ ‡ç­¾åˆ—
df = pd.DataFrame(data)

"""outlier(ğ·, ğ‘…, ğ‘¡.ğ´, ğœƒ)å®ç°ï¼Œå…ƒç»„ç´¢å¼•ä»0å¼€å§‹"""
threshold = 0.1
select_feature = 'feature3'
mean_feature_value = df[select_feature].mean()
std_feature_value = df[select_feature].std()
# è®¡ç®—feature_3å€¼ä¸å…¶ä»–å…ƒç»„çš„å·®å¼‚
diff_feature = abs(df[select_feature].values.reshape(-1, 1) - df[select_feature].values)
diff_feature[np.diag_indices(len(df))] = threshold  # å°†å¯¹è§’çº¿å…ƒç´ ï¼ˆä¸è‡ªèº«æ¯”è¾ƒï¼‰è®¾ä¸ºthreshold
# æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å…ƒç»„
satisfying_indices = np.where((diff_feature >= threshold).all(axis=1))[0]
print("ç¬¦åˆæ¡ä»¶çš„å…ƒç»„ç´¢å¼•ä¸ºï¼š", satisfying_indices)

"""imbalanced(ğ·, ğ‘…, ğ‘¡.ğ´, ğ›¿)å®ç°ï¼Œåˆ†ç»„æŒ‰ç…§ä¸åŒé—´éš”åŒºé—´åˆ’åˆ†"""
# è®¾ç½®åˆ†ç»„çš„é—´éš”
interval = 0.01
# åˆå§‹åŒ–MinMaxScaler
scaler = MinMaxScaler()
# å¯¹DataFrameçš„å„ä¸ªåˆ—è¿›è¡Œå½’ä¸€åŒ–
normalized_df = df.copy()  # å¤åˆ¶ä¸€ä¸ªæ–°çš„DataFrameï¼Œä»¥ä¿ç•™åŸå§‹æ•°æ®
normalized_df[df.columns] = scaler.fit_transform(df[df.columns])
# å¯¹æ¯åˆ—æ•°æ®è¿›è¡Œåˆ†ç»„
bins = np.arange(0, 1.01, interval)  # ç”Ÿæˆ0-1ä¹‹é—´100ä¸ªé—´éš”çš„æ•°ç»„
# ç»Ÿè®¡æ¯åˆ—æ•°æ®å æ®äº†å¤šå°‘ä¸ªé—´éš”
for column in normalized_df.columns:
    digitized = np.digitize(normalized_df[column], bins)
    unique_bins = np.unique(digitized)
    print(f"åˆ— '{column}' å æ®äº† {len(unique_bins)} ä¸ªé—´éš”")

"""SDomain(ğ·, ğ‘…, ğ´, ğœ)çš„å®ç°ï¼Œåˆ¤æ–­å±æ€§çš„æ´»åŠ¨åŸŸæ˜¯å¦å¾ˆå°"""
domain_df = df.copy()
# å››èˆäº”å…¥ä¿å­˜ä¸¤ä½å°æ•°
rounded_df = domain_df.round(2)
# ç»Ÿè®¡æ¯åˆ—çš„ä¸åŒå…ƒç´ æ•°é‡
unique_counts = rounded_df.nunique().sort_values()
print(unique_counts)