## 一、摘要

**现有的问题**：现有的方法无法有效地帮助用户识别离群值的根本原因，因为它们只精确定位数据属性，而没有考虑同一子空间中的离群值可能具有不同的原因。

## 二、引言

1、**动机**：为了将离群值转化为可操作的见解，用户通常期望离群值检测系统产生**人类可理解的信息**来解释检测到的离群值。此外，离群值检测经常返回**大量离群值候选**，这就提出了如何最好地呈现结果的问题。

2、**现有的最先进的基准**：

> 1）Scorpion [69]为**聚合查询中的异常提供了有意义的解释**
>
> 2）Cape [47]旨在**解释聚合查询中的离群值，但使用抵消离群值的对象**，这两项工作都没有解决总结离群值的问题
>
> 3）Macrobase [17]通过**挖掘异常值与一些不用于检测异常的外部属性**（如传感器位置、发生时间、软件版本等）之间的关联来解释异常值
>
> 4）LookOut [36]**确定了一些属性对来解释检测到的离群值**。这些属性对如果用于检测离群值，将产生与检测所有属性上的离群值相似的结果，因此可能是使离群值“异常”的关键因素。

直观地说，我们可以调整LookOut来总结检测到的离群值，例如，如果离群值可以由同一组属性识别，则将它们分组在一起。然而，在属性级别总结和解释离群值是有问题的。**即使可以通过分析同一组属性来捕获一些离群值，它们也可能是由完全不同的问题引起的，因此不一定具有相似的属性**。

因此，在此粗粒度属性级别解释和总结离群值不足以帮助用户快速识别导致检测到离群值的关键因素。因此，在这项工作中**，我们提出了一个细粒度的方法，考虑到属性的值**。也就是说，**除了一组属性之外，它还向用户揭示了这些属性应该满足的条件，以使离群值突出**。以这种细粒度总结和解释离群值是具有挑战性的，因为**考虑数据对象的值将导致搜索空间过大**，与属性及其不同值的数量呈指数关系。另一方面，**这种总结和解释仍然必须易于为人类所理解**。

3、**本文主要方法**：

在本文中，我们提出了STAIR，它有效地产生了一组细粒度的人类可理解的抽象，每个抽象描述了一组检测结果的共同属性。这允许用户仅通过检查一小组可解释的抽象来有效地验证大量离群值检测结果并诊断导致潜在离群值的关键因素。

> 1）基于规则的离群值汇总和解释：STAIR采用经典的决策树分类来学习一组紧凑的人类可理解的规则来总结和解释离群点检测结果；
>
> 2）异常值汇总和解释感知目标：决策树算法的目标是最大化分类准确性。以这种方式学习的规则不一定具有离群值总结和解释所需的属性。这是因为在处理高度复杂的数据集时，为了最大限度地减少分类错误，决策树通常必须是具有许多分支的深树，因此会产生许多人类难以理解的复杂规则。为了解决上述问题，我们提出了一个新的优化目标定制离群总结和解释。它的目标是产生尽可能简单的最少数量的规则，同时仍然确保分类准确性；
>
> 3）规则生成算法。然后，我们设计了一个优化算法来生成摘要和解释感知规则。类似于经典的决策树算法[29]，STAIR通过迭代地分割决策节点来产生规则集。
>
> 4）局部异常值总结和解释。为了解决一个单一的决策树与少量的简单规则是不足以满足精度要求时，处理高维，高度复杂的数据集，我们提出了一个本地化的STAIR方法，称为L-STAIR。

4、**本文贡献**：

> 1）据我们所知，**STAIR是第一种用人类可解释的规则总结离群点检测结果的方法**，它通常适用于总结任何二元分类模型的预测结果；
>
> 2）我们定义了一个离群值汇总和解释感知的优化目标，**其目标是以最小的复杂性产生最少数量的规则，同时仍然保证分类精度**；
>
> 3）**我们设计了一个规则生成方法，在每次迭代中优化STAIR目标是最佳的**；
>
> 4）我们提出了一种局部化的STAIR方法，该方法联合划分数据并为每个局部分区产生规则，从而**将STAIR扩展到高维，高度复杂的数据**；
>
> 5）我们使用10个数据集进行的广泛实验研究表明，与**7种解释离群值和机器学习预测的基于规则的方法**相比，**STAIR显著降低了总结离群值检测结果所需的复杂性和规则数量**

## 三、决策树符号定义

略

## 四、基于规则的总结和解释

规则将整个数据集分为三个不同的分区。规则R1覆盖了D中的所有内点，而规则R2和规则R3都表示离群点。

规则有效地总结和解释数据中的离群值和内值。其优点是双重的。首先，**每个规则覆盖一组内点或离群点**。因此，**用户现在只需评估少量规则**，而不是逐个穷举地评估大量离群值或内值，从而节省了大量的人力。其次，**规则是人类可解释的，帮助用户轻松理解为什么对象被认为是离群值或内点，并确定离群值的根本原因**。

## 五、规则生成的优化目标

### 5.1 经典决策树的不足

**决策树算法的目标产生的规则，最大限度地提高分类精度。以这种方式学习的规则在用于离群值汇总和解释时不一定具有所需的属性**，原因如下：

> 1、首先，**它们可能产生包含许多属性的规则**，因此对于人类来说太复杂而无法评估。
>
> 2、为了最大化分类精度，**它们可以产生许多规则**。然而，为了减少人工评估工作，理想情况下，我们希望产生尽可能少的规则。

### 5.2 摘要和解释感知目标

为了解决上述问题，我们设计了一个自定义的离群值总结和解释的优化目标。它的目标是产生尽可能简单的最小数量的规则，同时仍然保证分类精度。该目标由两个子目标组成，即**长度目标**和**熵目标**。

![image-20241003224530169](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20241003224530169.png)

熵目标。为了最大化衍生模型的分类精度，我们采用了经典决策树算法[29]中基于熵的优化目标，即ID3和C4.5。

![image-20241003224848593](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20241003224848593.png)

我们的总结和解释意识的目标（方程7)最大化分类准确度，同时最小化规则的总长度。

![image-20241003225026866](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20241003225026866.png)

为了解决S(R)迭代几次后收敛这个问题，我们在长度目标中引入了一个稳定器M。稳定器可有效减轻快速增加长度目标的影响。直观地说，在极端的情况下，设置一个无限大的值，总的规则长度的增加是可以忽略不计的目标。M是在我们的目标函数Eq中的可学习参数。

![image-20241003225402215](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20241003225402215.png)

## 六、阶梯：规则生成方法

本节介绍我们的摘要和解释感知规则生成方法（STAIR）。类似于经典的决策树算法[29]，STAIR通过迭代地分割决策节点来产生规则集。我们证明，在每次迭代中，STAIR对于最大化等式中的目标是最佳的。
STAIR的流程如下：

> 1、在方程式中初始化稳定器为零;
>
> 2、增大M的值；
>
> 3、找到一个可以增加等式7中目标的节点进行分裂，转到步骤2；

简而言之，STAIR迭代地增加了M的值并拆分了节点。接下来，我们首先表明，M的值对STAIR的性能是至关重要的，然后介绍了一种方法来计算STAIR在每次迭代的最佳值M。

### 6.1 M的值影响最优划分

我们表明，在最大化等式7中，可以产生有效分割的最小的M是最优的。

### 6.2 计算最优的M

为了解决如何找到最优的M的问题，我们介绍了一种方法，使用边界稳定器的概念，直接计算的最佳的M。

![image-20241003231539376](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20241003231539376.png)

### 6.3 STAIR学习算法

![image-20241003233708124](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20241003233708124.png)

## 七、本地化STAIR：数据分区和规则生成

虽然在一般情况下，STAIR在产生摘要和解释友好的规则方面比经典的决策树算法表现得更好，但其性能在高维、高度复杂的数据集上迅速下降。这是因为只有少量简单规则的单个决策树不足以对这些数据集的复杂分布特性进行建模。为此，提出了一种局部化的STAIR方法，称为L-STAIR。**L-STAIR将整个数据集划分为多个分区，并为每个分区学习树模型**。考虑到数据的局部性，L-STAIR生成了数据分区，**每个分区中的数据具有相似的统计特性，而不同分区中的数据具有不同的统计特性**。

L-STAIR可以通过两个不相交的步骤产生本地化规则：（1）使用现有的聚类算法（如k-means [37]或基于密度的聚类[30]）对数据进行分区;（2）直接将STAIR逐个应用于每个数据分区。然而，这种两步解决方案在满足我们的目标方面是次优的，这是因为数据划分和规则生成的问题高度依赖于彼此。LSTAIR联合解决了数据划分和规则生成这两个子问题。

最终L-STAIR目标：

![image-20241003232855909](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20241003232855909.png)

### 7.1 L-STAIR学习算法

![image-20241003233219214](C:\Users\kenis\AppData\Roaming\Typora\typora-user-images\image-20241003233219214.png)

### 7.2 动态调整分区数量

L-STAIR并不依赖于一个合适的学习器来实现良好的性能确定分区数量n，因为L-STAIR允许用户初始设置一个小的学习器n，然后在学习过程中动态地调整它。

**产生新的分区**：L-STAIR将通过拆分一些过于复杂的分区来产生新的分区，这些分区无法用简单的规则进行总结和解释。

**移除分区**：L-STAIR将冗余分区识别为与其他分区具有较大相似性的那些分区，使得将它们合并到其他分区中不会降低分区目标。

## 八、实验研究

### 8.1 研究目标

1、在给定的F1阈值的情况下，STAIR和L-STAIR与其他方法相比，在总规则长度方面如何？

2、当产生具有相似复杂度的规则时，STAIR和L-STAIR与其他方法相比，在F1得分方面如何？

3、参数𝐿m和𝐹1m对STAIR的性能有何影响？

4、分区数目n对L-STAIR的性能有什么影响?

5、L-STAIR在保持数据局部性方面有多好？

6、STAIR如何动态调整我们的总结和解释感知优化目标中引入的稳定器M的值？

7、STAIR在多类分类中的表现如何？

8、这些规则真的具有可解释性吗？

### 8.2 基于规则的基准算法

1、**ID3**：经典的决策树算法。为了找到满足准确度阈值的最简单的决策树，我们从一棵小树（深度为3）开始，迭代地增加其深度，直到得到的树可以产生大于阈值的F1分数

2、**CART**：CART使用后处理来修剪学习的决策树。其目标是在保持准确性的前提下，最大限度地降低决策树的复杂度。我们首先使用ID 3构建一个尽可能准确的决策树，然后继续修剪，直到它正好高于F-1得分阈值。

3、**RIPPERk**：RIPPERk采用深度优先搜索，在每次迭代时从数据集中生成一条规则。该算法通过比较各属性的信息增益来增加规则前件，并利用剪枝技术避免过拟合。我们继续运行该算法，直到获得的规则达到大于阈值的F1分数。

4、**CORELS**：CORELS是一种迭代方法，它将训练数据集作为输入，并产生一组规则作为输出，这些规则可用于解释实例。我们在每次迭代中计算F1分数，直到F1分数大于准确度要求。

5、**FRL**：FRL还将训练数据集作为输入，并学习由一组if-then-elseif规则列表组成的二元分类模型。具体来说，在每个规则中，对应于“elseif”子句的“then”子句指定结果（“1”）的概率，其呈现单调递减的趋势。这样，首先显示更重要的子句。类似地，我们在每次迭代中计算F1分数，直到F1分数超过F1分数。

6、**Explanation Table**：Explanation Table以原始数据集为输入，输出一个具有相同属性的解释表，其中每一行都可以被视为解释一个二进制属性的规则。具体来说，规则中包含了不同属性的值，值可以是“\*”，表示对应的属性可以取任何值。我们还在每次迭代中计算F1分数，直到F1分数大于F1阈值。所获得的解释表中的非"\*”值的数量表示总规则长度。

7、**HiCS** ：HiCS侧重于计算属性子集的对比度，具有最高对比度的子集被认为对识别离群值贡献最大。与我们的工作不同，HiCS不产生规则来解释和总结离群值。为了与我们的工作相比较，我们在识别的属性集上应用决策树算法（ID3）来生成一棵树，该树的得分大于F1阈值。

使用LOF作为离群点检测算法

## 九、相关工作

### 9.1 异常值总结和解释

Scorpion，Cape通过移除或者抵消解释异常值

Macrobase [17]使用关联规则挖掘将离群值与外部属性（如传感器位置或发生时间）相关联

BEAM[50]和RefOut [40]，这些方法侧重于解释单个离群值，而不是总结离群值。

LookOut [36]识别对检测到的异常值贡献最大的属性对，而HiCS [39]通过计算每个子空间的对比度来检测高维数据中的异常值。然而，这些方法提供了粗粒度的解释，不足以让用户快速识别检测到的离群值背后的关键因素。

### 9.2 可解释机器学习模型

一些作品[28，53，60]的目标是解释机器学习模型，如**LIME [57]，Anchor[58]，LORE [35]**，它们通过学习每个预测周围的局部线性模型来解释单个预测。然而，**为每个单独对象生成解释的计算成本限制了LIME等方法的可扩展性，尤其是在大型数据集上**。一些其他方法[15，35，44，58，62]以类似的方式解释分类结果。

此外，一些技术，包括基于梯度的[63，66]和基于注意力的[16]方法，侧重于特定类型的深度学习模型，因此难以用于离群点汇总场景。Lakkaraju等人[42]提出构建一个比深度学习模型更易于解释的预测模型。方法[48，51，67]致力于扩充数据，以产生具有更好解释性的模型。

我们的工作重点是解释和总结任何离群点检测方法产生的结果。也存在使用规则来解释数据管理任务的著作。例如，Singh等人[64，65]致力于利用一般布尔公式自动生成可解释且简明的实体匹配规则。AIME [32，33]关注的是从考虑了结构信息的知识图中提取规则。

### 9.3 异常检测算法

**HOD** [22]提出利用人类来提高文本数据中的离群值检测性能。此外，**STAIR**通常适用于不同类型的数据，包括数值、分类和文本数据，而不是专注于文本数据

### 9.4 数据清理的错误汇总

在数据清理中，存在各种使用深度学习来清理数据的方法。例如，**Deng等人。[26，27]提出了一种创新的方法，通过利用早期丢失信号来迭代地检测错误标记的数据实例，这在准确性方面实现了最先进的性能**。**Chai et al. [23]在一个小的核心集上清理数据，这可以导致在完整的训练数据上具有竞争力的模型性能，从而实现数据高效的训练过程和具有成本效益的清理工作**。**Miao等人率先开发了精确控制的插补加速机制[45，46，70]，该机制具有良好的处理大规模缺失数据的能力**。虽然上述方法可以取得很好的效果，但可能缺乏可解释性，这可以被视为STAIR的一个未来的工作。