"""
1ã€ID3ç®—æ³•ï¼šå…¶æ ¸å¿ƒæ˜¯åœ¨å†³ç­–æ ‘çš„å„çº§èŠ‚ç‚¹ä¸Šï¼Œä½¿ç”¨ä¿¡æ¯å¢ç›Šæ–¹æ³•çš„é€‰æ‹©æ ‡å‡†ï¼Œæ¥å¸®åŠ©ç¡®å®šç”Ÿäº§æ¯ä¸ªèŠ‚ç‚¹æ—¶æ‰€å¯¹åº”é‡‡ç”¨çš„åˆé€‚å±æ€§ï¼Œä¸èƒ½è‡ªåŠ¨åˆ†ç®±ï¼Œä¸èƒ½å‰ªæï¼›
2ã€C4.5ç®—æ³•ï¼šç›¸å¯¹äºID3æ”¹è¿›æ˜¯ä½¿ç”¨ä¿¡æ¯å¢ç›Šç‡æ¥é€‰æ‹©èŠ‚ç‚¹å±æ€§ã€‚å…‹æœID3ç‚¹ä¸è¶³ï¼š ID3åªé€‚ç”¨äºç¦»æ•£çš„æè¿°å±æ€§ï¼ŒC4.5å¯ä»¥å¤„ç†è¿ç»­å’Œç¦»æ•£å±æ€§ï¼›å¯ä»¥å‰ªæï¼›
3ã€CARTç®—æ³•ï¼šé€šè¿‡æ„å»ºæ ‘ã€ä¿®å‰ªæ ‘ã€è¯„ä¼°æ ‘æ¥æ„å»ºä¸€ä¸ªäºŒå‰æ ‘ã€‚é€šè¿‡æ§åˆ¶æ ‘çš„ç»“æ„æ¥æ§åˆ¶æ¨¡å‹ã€‚å½“ç»ˆèŠ‚ç‚¹æ˜¯è¿ç»­å˜é‡æ˜¯â€”â€”å›å½’æ ‘ï¼Œå½“ç»ˆèŠ‚ç‚¹æ˜¯åˆ†ç±»å˜é‡æ˜¯â€”â€”åˆ†ç±»æ ‘ï¼›
4ã€Scikit-learnä¸­çš„å†³ç­–æ ‘æ¨¡å‹ï¼ˆä¾‹å¦‚DecisionTreeClassifierï¼‰é»˜è®¤ä½¿ç”¨åŸºå°¼ç³»æ•°ï¼ˆGini impurityï¼‰ä½œä¸ºåˆ†è£‚æ ‡å‡†,
å†³ç­–æ ‘åœ¨è®­ç»ƒæ—¶å¹¶ä¸ç›´æ¥ä¼˜åŒ–æŸå¤±å‡½æ•°ï¼Œè€Œæ˜¯æ ¹æ®ç»™å®šçš„åˆ†è£‚æ ‡å‡†é€’å½’åœ°æ„å»ºæ ‘ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢æ¡ä»¶ä¸ºæ­¢;
5ã€å†³ç­–æ ‘åœ¨è®­ç»ƒæ—¶æ˜¯é€šè¿‡é€’å½’åœ°é€‰æ‹©æœ€ä½³çš„ç‰¹å¾å’Œåˆ‡åˆ†ç‚¹æ¥æ„å»ºæ ‘çš„èŠ‚ç‚¹ï¼Œä¸æ¶‰åŠå…¸å‹æ„ä¹‰ä¸Šçš„è¿­ä»£æ›´æ–°å‚æ•°ã€‚
"""
# unsupervised methods
from deepod.models import REPEN, SLAD, ICL, NeuTraL, DeepSAD
from deepod.models.tabular import GOAD
from deepod.models.tabular import RCA
from deepod.models.tabular import DeepSVDD
import torch
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import matplotlib
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
import numpy as np
from sklearn.metrics import hinge_loss
from sklearn.feature_selection import mutual_info_regression
from sklearn.linear_model import Lasso
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LinearRegression
from sklearn.feature_selection import RFE
from xgboost import XGBClassifier, plot_importance
from sklearn.inspection import permutation_importance
from lime.lime_tabular import LimeTabularExplainer
import shap
from distfit import distfit
from fitter import Fitter
import scipy.stats as stats
import re
from sklearn.datasets import make_multilabel_classification
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import log_loss

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.width', None)
np.set_printoptions(threshold=np.inf)

import os
os.environ["PATH"] += os.pathsep + 'E:/graphviz/bin/'

def one_hot_encode(y, num_classes):
    y = y.astype(int)
    return np.eye(num_classes)[y]

epochs = 1
device = 'cuda' if torch.cuda.is_available() else 'cpu'
n_trans = 64
random_state = 42
# æŒ‡å®šè¦æ£€æµ‹çš„æ ‡ç­¾åˆ—ç±»åˆ«ä¸ºtarget_classæ—¶ï¼Œæ ·æœ¬ä¸­å‡ºç°çš„å¼‚å¸¸å€¼
target_class = 0

# SECTION kaggle datasetsä¸Šçš„æ•°æ®é¢„å¤„ç†
# SUBSECTION dry_beanæ•°æ®é›†
file_path = "../UCI_datasets/dry+bean+dataset/DryBeanDataset/Dry_Bean_Dataset.xlsx"
data = pd.read_excel(file_path)
enc = LabelEncoder()
data['Class'] = enc.fit_transform(data['Class'])
X = data.values[:,0:16]
y = data.values[:,16]
# å¯¹ä¸åŒç»´åº¦è¿›è¡Œæ ‡å‡†åŒ–
X = StandardScaler().fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)
class_names = enc.classes_
feature_names = data.columns.values.tolist()
categorical_features = [0, 6]
categorical_names = {}
for feature in categorical_features:
    le = LabelEncoder()
    le.fit(data.iloc[:, feature])
    data.iloc[:, feature] = le.transform(data.iloc[:, feature])
    categorical_names[feature] = le.classes_

# SECTION Mğ‘œ (ğ‘¡, D),é’ˆå¯¹å…ƒç»„å¼‚å¸¸çš„å¼‚å¸¸æ£€æµ‹å™¨
# SUBSECTION  GOADå¼‚å¸¸æ£€æµ‹å™¨
clf = GOAD(epochs=epochs, device=device, n_trans=n_trans)
clf.fit(X_train, y=None)

# SECTION å€ŸåŠ©å¼‚å¸¸æ£€æµ‹å™¨ï¼Œåœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œå¼‚å¸¸å€¼æ£€æµ‹
train_scores = clf.decision_function(X_train)
train_pred_labels, train_confidence = clf.predict(X_train, return_confidence=True)
print("è®­ç»ƒé›†ä¸­å¼‚å¸¸å€¼åˆ¤å®šé˜ˆå€¼ä¸ºï¼š", clf.threshold_)
train_outliers_index = []
print("è®­ç»ƒé›†æ ·æœ¬æ•°ï¼š", len(X_train))
for i in range(len(X_train)):
    if train_pred_labels[i] == 1:
        train_outliers_index.append(i)
print("è®­ç»ƒé›†ä¸­å¼‚å¸¸å€¼ç´¢å¼•ï¼š", train_outliers_index)
print("è®­ç»ƒé›†ä¸­çš„å¼‚å¸¸å€¼æ•°é‡ï¼š", len(train_outliers_index))

# SECTION Scikit-learnä¸­çš„å†³ç­–æ ‘æ¨¡å‹ï¼ˆä¾‹å¦‚DecisionTreeClassifierï¼‰é»˜è®¤ä½¿ç”¨åŸºå°¼ç³»æ•°ï¼ˆGini impurityï¼‰ä½œä¸ºåˆ†è£‚æ ‡å‡†,
#  å†³ç­–æ ‘åœ¨è®­ç»ƒæ—¶å¹¶ä¸ç›´æ¥ä¼˜åŒ–æŸå¤±å‡½æ•°ï¼Œè€Œæ˜¯æ ¹æ®ç»™å®šçš„åˆ†è£‚æ ‡å‡†é€’å½’åœ°æ„å»ºæ ‘ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢æ¡ä»¶ä¸ºæ­¢
from sklearn.metrics import classification_report, confusion_matrix
cart_classifier = DecisionTreeClassifier()
# cart_classifier = DecisionTreeClassifier(criterion='entropy', random_state=random_state)
# cart_classifier = DecisionTreeClassifier(max_depth=5, min_samples_leaf=10, min_samples_split=20)
cart_classifier.fit(X_train, y_train)
y_pred = cart_classifier.predict(X_test)
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
wrong_classified_indices = np.where(y_train != cart_classifier.predict(X_train))[0]
X_train_outliers = X_train[train_outliers_index]
y_train_outliers_numpy = y_train[train_outliers_index]
y_train_outliers = pd.Series(y_train_outliers_numpy)
print("*" * 100)
print("åŸå§‹è®­ç»ƒé›†ä¸­CARTå†³ç­–æ ‘åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train, cart_classifier.predict(X_train))))
print("åŸå§‹æµ‹è¯•é›†ä¸­CARTå†³ç­–æ ‘åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, cart_classifier.predict(X_test))))
if not y_train_outliers.empty:
    print("è®­ç»ƒé›†ä¸­å¼‚å¸¸å€¼çš„CARTå†³ç­–æ ‘åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train_outliers, cart_classifier.predict(X_train_outliers))))
print("*" * 100)
# è®­ç»ƒé›†ä¸­åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬ä¸‹æ ‡ç´¢å¼•
corr_indices = np.where(y_train == cart_classifier.predict(X_train))[0]
# è®­ç»ƒé›†ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬ä¸‹æ ‡ç´¢å¼•
wrong_indices = np.where(y_train != cart_classifier.predict(X_train))[0]
# è®­ç»ƒé›†ä¸­å¼‚å¸¸å€¼ä¸­åˆ†ç±»æ­£ç¡®çš„æ ·æœ¬ä¸‹æ ‡ç´¢å¼•
common_indices = np.where(y_train_outliers == cart_classifier.predict(X_train_outliers))[0]
# è®­ç»ƒé›†ä¸­å¼‚å¸¸å€¼ä¸­åˆ†ç±»é”™è¯¯çš„æ ·æœ¬ä¸‹æ ‡ç´¢å¼•
diff_indices = np.where(y_train_outliers != cart_classifier.predict(X_train_outliers))[0]

# section å†³ç­–æ ‘å¯è§†åŒ–
from sklearn.tree import export_graphviz
from io import StringIO
from IPython.display import Image
import pydotplus

# å°†å†³ç­–æ ‘å¯¼å‡ºä¸ºDOTæ ¼å¼
dot_data = StringIO()
export_graphviz(cart_classifier, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True)

# ä½¿ç”¨pydotplusç”Ÿæˆå†³ç­–æ ‘å›¾å½¢
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.set_size('"8,8!"')
graph.set_dpi(300)
# å¯è§†åŒ–å†³ç­–æ ‘
graph.write_svg("decision_tree.svg")
print("å†³ç­–æ ‘å›¾å½¢å·²ç”Ÿæˆå¹¶ä¿å­˜ä¸º decision_tree.svg")

# SECTION åŸå§‹æ•°æ®ä¸­çš„å†³ç­–æ ‘åˆ†ç±»å‡†ç¡®åº¦
print("*" * 100)
print("åŸå§‹è®­ç»ƒé›†ä¸­å†³ç­–æ ‘çš„åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train, cart_classifier.predict(X_train))))
print("åŸå§‹æµ‹è¯•é›†ä¸­å†³ç­–æ ‘çš„åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, cart_classifier.predict(X_test))))
print("*" * 100)

# SECTION èˆå¼ƒæ‰å†³ç­–æ ‘ä¸­åˆ†ç±»é”™è¯¯çš„ï¼Œä¸”è¢«åˆ¤å®šä¸ºå¼‚å¸¸å€¼çš„æ ·æœ¬ï¼Œé‡æ–°åœ¨å¤„ç†åçš„è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒå†³ç­–æ ‘
# ç”Ÿæˆå¸ƒå°”ç´¢å¼•ï¼Œä¸ºè¦åˆ é™¤çš„è¡Œåˆ›å»ºå¸ƒå°”å€¼æ•°ç»„
mask = np.ones(len(X_train), dtype=bool)
mask[diff_indices] = False
# ä½¿ç”¨å¸ƒå°”ç´¢å¼•åˆ é™¤é‚£äº›æ—¢è¢«åˆ¤å®šä¸ºå¼‚å¸¸å€¼ï¼Œåˆè¢«å†³ç­–æ ‘åˆ†ç±»é”™è¯¯çš„æ ·æœ¬
X_train_split = X_train[mask]
y_train_split = y_train[mask]
# é‡æ–°è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹
cart_split = DecisionTreeClassifier()
cart_split.fit(X_train_split, y_train_split)
print("*" * 100)
print("å»é™¤å†³ç­–æ ‘åˆ†ç±»é”™è¯¯ä¸”è¢«åˆ¤å®šä¸ºå¼‚å¸¸çš„è®­ç»ƒæ ·æœ¬åï¼Œåœ¨è®­ç»ƒé›†ä¸Šå†³ç­–æ ‘çš„åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train_split, cart_split.predict(X_train_split))))
print("å»é™¤å†³ç­–æ ‘åˆ†ç±»é”™è¯¯ä¸”è¢«åˆ¤å®šä¸ºå¼‚å¸¸çš„è®­ç»ƒæ ·æœ¬åï¼Œåœ¨æµ‹è¯•é›†ä¸Šå†³ç­–æ ‘çš„åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, cart_split.predict(X_test))))
print("*" * 100)

# SECTION èˆå¼ƒæ‰å†³ç­–æ ‘è®­ç»ƒæ•°æ®ä¸­åˆ†ç±»é”™è¯¯çš„è®­ç»ƒæ ·æœ¬ï¼Œé‡æ–°åœ¨å¤„ç†åçš„è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒå†³ç­–æ ‘
mask_cross = np.ones(len(X_train), dtype=bool)
mask_cross[wrong_indices] = False
X_train_cross = X_train[mask_cross]
y_train_cross = y_train[mask_cross]
cart_cross = DecisionTreeClassifier()
cart_cross.fit(X_train_cross, y_train_cross)
print("*" * 100)
print("å»é™¤å†³ç­–æ ‘è®­ç»ƒæ•°æ®ä¸­åˆ†ç±»é”™è¯¯çš„è®­ç»ƒæ ·æœ¬ï¼Œåœ¨è®­ç»ƒé›†ä¸Šå†³ç­–æ ‘çš„åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train_cross, cart_cross.predict(X_train_cross))))
print("å»é™¤å†³ç­–æ ‘è®­ç»ƒæ•°æ®ä¸­åˆ†ç±»é”™è¯¯çš„è®­ç»ƒæ ·æœ¬ï¼Œåœ¨æµ‹è¯•é›†ä¸Šå†³ç­–æ ‘çš„åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, cart_cross.predict(X_test))))
print("*" * 100)

# SECTION èˆå¼ƒæ‰å†³ç­–æ ‘è®­ç»ƒæ•°æ®ä¸­è¢«åˆ¤å®šä¸ºå¼‚å¸¸å€¼çš„æ ·æœ¬ï¼Œé‡æ–°åœ¨å¤„ç†åçš„è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒå†³ç­–æ ‘
mask_o = np.ones(len(X_train), dtype=bool)
mask_o[train_outliers_index] = False
X_train_o = X_train[mask_o]
y_train_o = y_train[mask_o]
cart_o = DecisionTreeClassifier()
cart_o.fit(X_train_o, y_train_o)
print("*" * 100)
print("å»é™¤å†³ç­–æ ‘è®­ç»ƒæ•°æ®ä¸­è¢«åˆ¤å®šä¸ºå¼‚å¸¸çš„æ ·æœ¬åï¼Œåœ¨è®­ç»ƒé›†å†³ç­–æ ‘çš„åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_train_o, cart_o.predict(X_train_o))))
print("å»é™¤å†³ç­–æ ‘è®­ç»ƒæ•°æ®ä¸­è¢«åˆ¤å®šä¸ºå¼‚å¸¸çš„æ ·æœ¬åï¼Œåœ¨æµ‹è¯•é›†å†³ç­–æ ‘çš„åˆ†ç±»å‡†ç¡®åº¦ï¼š" + str(accuracy_score(y_test, cart_o.predict(X_test))))
print("*" * 100)

# section è®¡ç®—è®­ç»ƒæ ·æœ¬çš„è¿­ä»£æŸå¤±ï¼Œå†³ç­–æ ‘ä¸æ¶‰åŠæ˜¾ç¤ºçš„è®­ç»ƒè¿‡ç¨‹ï¼Œæ²¡æœ‰è¿­ä»£æŸå¤±è¿™ä¸€æ¦‚å¿µ